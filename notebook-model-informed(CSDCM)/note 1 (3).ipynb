{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the viscoelastic model\n",
    "A = 200  # Elastic stiffness matrix in MPa\n",
    "Q = 10   # Kernel decay rate\n",
    "D = 50   # Damping coefficient in MPaÂ·s\n",
    "dt = 0.01  # Time step\n",
    "\n",
    "# Time array\n",
    "total_time = 3  # Total time for custom strain path (3 seconds)\n",
    "time = np.arange(0, total_time, dt)  # Time array\n",
    "\n",
    "# Define custom strain points and corresponding time points\n",
    "custom_strain_points = [0, 0.05, -0.05, 0.1, -0.1, 0.15, -0.15, 0]\n",
    "custom_time_points = np.linspace(0, total_time, len(custom_strain_points))\n",
    "\n",
    "# Interpolate to create the strain path\n",
    "strain = np.interp(time, custom_time_points, custom_strain_points)\n",
    "\n",
    "# Strain rate (dE/dt) using numerical differentiation\n",
    "strain_rate = np.gradient(strain, dt)\n",
    "\n",
    "# Initialize stress array for storing computed stress values\n",
    "stress = np.zeros_like(time)\n",
    "\n",
    "# Compute stress using the convolution integral\n",
    "for i in range(1, len(time)):\n",
    "    # Elastic stress component\n",
    "    elastic_stress = A * strain[i]\n",
    "    \n",
    "    # Viscoelastic stress component\n",
    "    viscoelastic_stress = 0\n",
    "    for j in range(i):\n",
    "        kernel = np.exp(-Q * (time[i] - time[j]))  # Decaying kernel\n",
    "        viscoelastic_stress += kernel * D * strain_rate[j] * dt  # Convolution for viscoelastic contribution\n",
    "    \n",
    "    # Total stress is the sum of elastic and viscoelastic components\n",
    "    stress[i] = elastic_stress + viscoelastic_stress\n",
    "\n",
    "# Plot the strain-time curve\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(time, strain, label=\"Strain vs Time\", color='b', linewidth=2)\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Strain\")\n",
    "plt.title(\"Strain-Time Curve (Custom Path in 3 Seconds)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the stress-strain curve\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(strain, stress, label=\"Stress vs Strain\", color='r', linewidth=2)\n",
    "plt.xlabel(\"Strain\")\n",
    "plt.ylabel(\"Stress (MPa)\")\n",
    "plt.title(\"Stress-Strain Curve (Viscoelastic Material)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Convert to torch tensors for training\n",
    "strain_tensor = torch.tensor(strain, dtype=torch.float32).unsqueeze(1)  # Shape (N, 1)\n",
    "stress_tensor = torch.tensor(stress, dtype=torch.float32).unsqueeze(1)  # Shape (N, 1)\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = TensorDataset(strain_tensor, stress_tensor)\n",
    "data_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PotentialW(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PotentialW, self).__init__()\n",
    "        # Define the neural network layers for learning W (N_theta)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1, 64),  # Input: strain (E)\n",
    "            nn.Softplus(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.Softplus(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, strain):\n",
    "        # Compute the neural network output N_theta(E)\n",
    "        N_theta = self.fc(strain)\n",
    "        \n",
    "        # Compute the gradient of N_theta with respect to strain at E = 0\n",
    "        # This is necessary to enforce consistency\n",
    "        strain_zero = torch.zeros_like(strain)  # Zero strain for consistency condition\n",
    "        N_theta_grad_at_zero = torch.autograd.functional.jacobian(lambda x: self.fc(x), strain_zero).squeeze()\n",
    "        \n",
    "        # Implement W(E) = N_theta(E) - N_theta_grad_at_zero * E\n",
    "        W_theta = N_theta - N_theta_grad_at_zero * strain\n",
    "        \n",
    "        return W_theta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PotentialV(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PotentialV, self).__init__()\n",
    "        # Define the neural network layers for learning V (M_Phi)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1, 64),  # Input will be delta = C1 * E + C2 * alpha\n",
    "            nn.Softplus(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.Softplus(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "        # Initialize C1 and C2 as learnable parameters (4th-order tensors)\n",
    "        self.C1 = nn.Parameter(torch.tensor([1.0]), requires_grad=True)\n",
    "        self.C2 = nn.Parameter(torch.tensor([1.0]), requires_grad=True)\n",
    "    \n",
    "    def forward(self, strain, alpha):\n",
    "        # Compute delta = C1 * E + C2 * alpha\n",
    "        delta = self.C1 * strain + self.C2 * alpha\n",
    "        \n",
    "        # Compute the neural network output M_Phi(delta)\n",
    "        M_Phi = self.fc(delta)\n",
    "        \n",
    "        # Compute the gradient of M_Phi with respect to delta at delta = 0\n",
    "        delta_zero = torch.zeros_like(delta)  # Zero delta for consistency condition\n",
    "        M_Phi_grad_at_zero = torch.autograd.functional.jacobian(lambda x: self.fc(x), delta_zero).squeeze()\n",
    "        \n",
    "        # Implement V(E, alpha) = M_Phi(delta) - M_Phi_grad_at_zero * delta\n",
    "        V_Phi = M_Phi - M_Phi_grad_at_zero * delta\n",
    "        \n",
    "        return V_Phi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PotentialG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PotentialG, self).__init__()\n",
    "        # Define the neural network layers for learning G (D_r)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1, 64),  # Input: beta (internal stress)\n",
    "            nn.Softplus(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.Softplus(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, beta, strain):\n",
    "        # Compute the neural network output D_r(beta, E)\n",
    "        D_r = self.fc(beta)\n",
    "        \n",
    "        # Compute the gradient of D_r with respect to beta at beta = 0\n",
    "        beta_zero = torch.zeros_like(beta)  # Zero beta for consistency condition\n",
    "        D_r_grad_at_zero = torch.autograd.functional.jacobian(lambda x: self.fc(x), beta_zero).squeeze()\n",
    "        \n",
    "        # Implement G(beta, E) = D_r(beta, E) - D_r_grad_at_zero * beta\n",
    "        G_sigma = D_r - D_r_grad_at_zero * beta\n",
    "        \n",
    "        return G_sigma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd.functional as F\n",
    "\n",
    "# Updated compute functions using equations 26, 27, 28\n",
    "def compute_total_stress(W_model, V_model, strain, alpha):\n",
    "    # Compute elastic contribution (dW/dE)\n",
    "    W_theta = W_model(strain)\n",
    "    \n",
    "    # Compute viscoelastic contribution (dV/dE) with strain and internal variable alpha\n",
    "    V_phi = V_model(strain, alpha)\n",
    "    \n",
    "    # Total stress is the sum of elastic and viscoelastic contributions\n",
    "    total_stress = W_theta + V_phi\n",
    "    return total_stress\n",
    "\n",
    "def evolve_alpha(G_model, beta, strain):\n",
    "    # Compute alpha evolution as per equation (27)\n",
    "    alpha_evolution = G_model(beta, strain)\n",
    "    return alpha_evolution\n",
    "\n",
    "def compute_internal_stress(V_model, strain, alpha):\n",
    "    # Compute the internal stress beta from V (as per equation (28))\n",
    "    beta = -torch.autograd.functional.jacobian(lambda a: V_model(strain, a), alpha).squeeze()\n",
    "    return beta\n",
    "\n",
    "# Let's define the class structure for learning the nonlinear viscoelasticity\n",
    "class PotentialW(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PotentialW, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1, 64),  # Adjust input size\n",
    "            nn.Softplus(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.Softplus(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, strain):\n",
    "        strain = strain.view(-1, 1)  # Ensure strain has correct shape (batch_size, 1)\n",
    "        N_theta = self.fc(strain)\n",
    "        return N_theta\n",
    "\n",
    "class PotentialV(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PotentialV, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1, 64),  # Adjust input size for delta\n",
    "            nn.Softplus(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.Softplus(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "        self.C1 = nn.Parameter(torch.tensor([1.0]), requires_grad=True)\n",
    "        self.C2 = nn.Parameter(torch.tensor([1.0]), requires_grad=True)\n",
    "\n",
    "    def forward(self, strain, alpha):\n",
    "        delta = self.C1 * strain + self.C2 * alpha\n",
    "        delta = delta.view(-1, 1)  # Ensure correct shape (batch_size, 1)\n",
    "        M_phi = self.fc(delta)\n",
    "        return M_phi\n",
    "\n",
    "class PotentialG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PotentialG, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1, 64),  # Adjust input size for beta\n",
    "            nn.Softplus(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.Softplus(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, beta, strain):\n",
    "        beta = beta.view(-1, 1)  # Ensure correct shape (batch_size, 1)\n",
    "        D_r = self.fc(beta)\n",
    "        return D_r\n",
    "\n",
    "# Define the complete viscoelastic model class\n",
    "class ViscoelasticModel(nn.Module):\n",
    "    def __init__(self, W_model, V_model, G_model):\n",
    "        super(ViscoelasticModel, self).__init__()\n",
    "        self.W_model = W_model\n",
    "        self.V_model = V_model\n",
    "        self.G_model = G_model\n",
    "\n",
    "    def forward(self, strain, alpha):\n",
    "        # Step 1: Compute internal stress beta using equation (28)\n",
    "        beta = compute_internal_stress(self.V_model, strain, alpha)\n",
    "\n",
    "        # Step 2: Evolve alpha using equation (27)\n",
    "        alpha_evolution = evolve_alpha(self.G_model, beta, strain)\n",
    "\n",
    "        # Step 3: Compute total stress using equation (26)\n",
    "        total_stress = compute_total_stress(self.W_model, self.V_model, strain, alpha)\n",
    "\n",
    "        return total_stress, alpha_evolution\n",
    "\n",
    "# Instantiate the models\n",
    "W_model = PotentialW()\n",
    "V_model = PotentialV()\n",
    "G_model = PotentialG()\n",
    "\n",
    "# Instantiate the viscoelastic model\n",
    "viscoelastic_model = ViscoelasticModel(W_model, V_model, G_model)\n",
    "\n",
    "# Example data\n",
    "strain = torch.linspace(0, 0.1, 100).unsqueeze(1)  # Sample strain data\n",
    "alpha = torch.zeros_like(strain)  # Initialize alpha (internal variable) as zeros\n",
    "\n",
    "# Forward pass through the model\n",
    "total_stress, updated_alpha = viscoelastic_model(strain, alpha)\n",
    "\n",
    "# Print total stress and updated internal variable alpha\n",
    "print(\"Total Stress:\\n\", total_stress)\n",
    "print(\"Updated Alpha:\\n\", updated_alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "viscoelastic_model = ViscoelasticModel(W_model, V_model, G_model)\n",
    "\n",
    "# Define loss function (Mean Squared Error) and optimizer\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.Adam([\n",
    "    {'params': W_model.parameters()},\n",
    "    {'params': V_model.parameters()},\n",
    "    {'params': G_model.parameters()}\n",
    "], lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "epochs = 1000\n",
    "delta_t = 0.01  # Time step size for forward Euler integration\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    alpha = torch.zeros_like(strain_tensor)  # Initialize alpha to zero at the start\n",
    "    \n",
    "    # Loop through the data loader batches\n",
    "    for batch_idx, (strain_batch, true_stress_batch) in enumerate(data_loader):\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass: compute predicted stress and update alpha\n",
    "        predicted_stress, alpha_next = viscoelastic_model(strain_batch, alpha)\n",
    "\n",
    "        # Forward Euler step for updating alpha\n",
    "        alpha = alpha_next + delta_t * alpha_next\n",
    "\n",
    "        # Compute the loss (MSE between predicted stress and true stress)\n",
    "        loss = loss_function(predicted_stress, true_stress_batch)\n",
    "\n",
    "        # Backward pass: compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the model parameters\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print loss for monitoring every 100 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch}/{epochs}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
