{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction of FFNN based on normalized training space\n",
    "Upon stabilization and convergence of the model training loss curve to a non small number, normalization becomes imperative to homogenize the training space. Here, the training procedure is reiterated on a normalized training space employing two methods, namely min-max and Z-score normalization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import save_model\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "making home directory if it doesn't exist to save the data in local disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = Path().home()\n",
    "ml_data = home_dir / 'ml_data'\n",
    "if not ml_data.exists():\n",
    "    ml_data.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the training space and normalizing \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data which is already generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Design_space = np.load(ml_data / 'Design_space2.npy')\n",
    "moment_capacity = np.load(ml_data / 'Mu2.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization of input data for training a neural network is a crucial preprocessing step that ensures stable and efficient training. It involves scaling the input features to a similar range, typically between 0 and 1 or with zero mean and unit variance. This helps prevent certain features from dominating the learning process and can accelerate convergence during training. Here's how we can normalize input data for training the neural network using min-max normalization and Z-score normalization:\n",
    "1. Min-Max Normalization: Min-max normalization scales the input features to a fixed range, typically between 0 and 1.\n",
    "$$\n",
    "x_{\\text {norm }}=\\frac{x-\\min (x)}{\\max (x)-\\min (x)}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max Normalization\n",
    "Design_space_normalized_min_max = (Design_space - np.min(Design_space, axis=0)) / (np.max(Design_space, axis=0) - np.min(Design_space, axis=0))\n",
    "moment_capacity_normalized_min_max = (moment_capacity - np.min(moment_capacity, axis=0)) / (np.max(moment_capacity, axis=0) - np.min(moment_capacity, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Z-score Normalization: Z-score normalization (also known as standardization) scales the input features to have a mean of 0 and a standard deviation of 1 .\n",
    "$$\n",
    "x_{\\text {norm }}=\\frac{x-\\operatorname{mean}(x)}{\\operatorname{std}(x)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-score Normalization:\n",
    "Design_space_normalized_z_score = (Design_space - np.mean(Design_space, axis=0)) / np.std(Design_space, axis=0)\n",
    "moment_capacity_normalized_z_score = (moment_capacity - np.mean(moment_capacity, axis=0)) / np.std(moment_capacity, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the neural network model with arbitrary hyperparameters (64,32) and ReLU activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(1,)),  # Input layer with 1 neuron\n",
    "    Dense(32, activation='relu'),  # Hidden layer with 32 neurons\n",
    "    Dense(3)  # Output layer with 3 neurons\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')  # Using mean squared error loss and Adam optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the FFNN based on normalized data, plotting Model Training Loss curve and saving Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(moment_capacity_normalized_min_max, Design_space_normalized_min_max, epochs=100, batch_size=16, verbose=0)\n",
    "model.save('trained_model_normalized.h5')\n",
    "# Plot training loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the trained FFNN on the nodes within the training space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('trained_model_normalized.h5')\n",
    "\n",
    "# picking 7 row from the data\n",
    "step_size = moment_capacity_normalized_min_max.shape[0]//7\n",
    "\n",
    "# selected actual design parameters associated with moment capacity .\n",
    "selected_actual_params= Design_space_normalized_min_max[::step_size]\n",
    "moment_capacity_test = moment_capacity_normalized_min_max[::step_size] # New input data for prediction\n",
    "print(selected_actual_params)\n",
    "print(moment_capacity_test)\n",
    "\n",
    "# Predict on new data\n",
    "moment_capacity_test = moment_capacity_test\n",
    "\n",
    "Designe_pred = model.predict(moment_capacity_test)\n",
    "print(Designe_pred)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the accuracy of FFNN predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate the absolute errors for each predicted parameter\n",
    "errors_width = 100*np.abs(selected_actual_params[:, 0] - Designe_pred[:, 0])/selected_actual_params[:, 0]\n",
    "errors_height = 100*np.abs(selected_actual_params[:, 1] - Designe_pred[:, 1])/selected_actual_params[:, 1]\n",
    "errors_reinforcement =100*np.abs(selected_actual_params[:, 2] - Designe_pred[:, 2])/selected_actual_params[:, 2]\n",
    "\n",
    "# Plot the absolute errors for each predicted parameter\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Width\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(moment_capacity_test, errors_width, color='blue')\n",
    "plt.xlabel('Moment Capacity')\n",
    "plt.ylabel('Relative Error for Width')\n",
    "plt.title('Relative Error for Width')\n",
    "\n",
    "# Height\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(moment_capacity_test, errors_height, color='red')\n",
    "plt.xlabel('Moment Capacity')\n",
    "plt.ylabel('Relative Error for Height')\n",
    "plt.title('Relative Error for Height')\n",
    "\n",
    "# Reinforcement ratio\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(moment_capacity_test, errors_reinforcement, color='green')\n",
    "plt.xlabel('Moment Capacity')\n",
    "plt.ylabel('Relative Error for Reinforcement Ratio')\n",
    "plt.title('Relative Error for Reinforcement Ratio')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
