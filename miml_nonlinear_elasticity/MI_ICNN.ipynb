{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from torch.utils.data import DataLoader, TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_modulus = 200  \n",
    "C1, C2 = 500, 600\n",
    "noise_level = 1  \n",
    "def generate_nonlinear_elastic_data(epsilon_values, E, C1, C2, noise_level):\n",
    "    sigma = E * epsilon_values + C1 * epsilon_values ** 2 + C2 * epsilon_values ** 3\n",
    "    noise = noise_level * np.random.randn(*epsilon_values.shape)\n",
    "    return sigma + noise\n",
    "epsilon_train = np.linspace(0, 0.3, 100).reshape(-1, 1).astype(np.float32)\n",
    "sigma_train = generate_nonlinear_elastic_data(epsilon_train, E_modulus, C1, C2, noise_level).astype(np.float32)\n",
    "epsilon_train_tensor = torch.tensor(epsilon_train)\n",
    "sigma_train_tensor = torch.tensor(sigma_train)\n",
    "std_train_stress = torch.std(sigma_train_tensor).item()\n",
    "# Normalize the data using min-max normalization\n",
    "x_data = epsilon_train_tensor.numpy()\n",
    "y_data = sigma_train_tensor.numpy()\n",
    "x_min, x_max = x_data.min(), x_data.max()\n",
    "y_min, y_max = y_data.min(), y_data.max()\n",
    "x_data = (x_data - x_min) / (x_max - x_min)\n",
    "y_data = (y_data - y_min) / (y_max - y_min)\n",
    "x_tensor = torch.tensor(x_data, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y_data, dtype=torch.float32)\n",
    "# Create DataLoader for shuffling\n",
    "dataset = TensorDataset(x_tensor, y_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define SoftplusSquared Activation function\n",
    "class SoftplusSquared(nn.Module):\n",
    "    def __init__(self, beta=1):\n",
    "        super(SoftplusSquared, self).__init__()\n",
    "        self.beta = nn.Parameter(torch.tensor(float(beta)))  # Make beta a trainable parameter\n",
    "    def forward(self, x):\n",
    "        return (1 / (2 * self.beta ** 4)) * (torch.log10(1+torch.exp(self.beta ** 2 * x))) ** 2\n",
    "\n",
    "class ConstrainedLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, alpha=1):\n",
    "        super(ConstrainedLinear, self).__init__()\n",
    "        self.raw_weights = nn.Parameter(torch.randn(out_features, in_features))  # Trainable weights\n",
    "        self.alpha = nn.Parameter(torch.tensor(float(alpha)))  # Trainable parameter\n",
    "    def forward(self, x):\n",
    "        # Constrain weights to be positive using numerically stable softplus\n",
    "        positive_weights = (1 / (self.alpha ** 2)) * torch.log10(1+torch.exp(self.alpha ** 2 * self.raw_weights))\n",
    "        return F.linear(x, positive_weights)\n",
    "\n",
    "# Define neural network model\n",
    "class ICNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(ICNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, 20)\n",
    "        self.constrained_layer1 = ConstrainedLinear(20, 10)\n",
    "        self.constrained_layer2 = ConstrainedLinear(10, 10)\n",
    "        self.constrained_layer3 = ConstrainedLinear(10, 1)\n",
    "        self.A = nn.Parameter(torch.randn(input_dim, input_dim))  # Trainable A\n",
    "        self.shortcut_layer2 = nn.Linear(input_dim, 10, bias=False)\n",
    "        self.shortcut_layer3 = nn.Linear(input_dim, 10, bias=False)\n",
    "        self.activation = SoftplusSquared()\n",
    "    def forward(self, x):\n",
    "        x0 = x  # Original input (batch_size, input_dim)\n",
    "        shortcut2 = self.shortcut_layer2(x)  \n",
    "        shortcut3 = self.shortcut_layer3(x)  \n",
    "        x = self.activation(self.layer1(x))  \n",
    "        x = self.activation(self.constrained_layer1(x) + shortcut2) \n",
    "        x = self.activation(self.constrained_layer2(x) + shortcut3)\n",
    "       #  Quadratic term computation: f(x0) = x0^T A^T A x0\n",
    "        quadratic_term = torch.matmul(x0, self.A.T)  # Compute x0^T * A^T  # Compute x^T * A^T\n",
    "        quadratic_term = torch.matmul(quadratic_term, self.A)  # Compute x0^T * A^T * A  # Compute x^T * A^T * A\n",
    "        quadratic_output = torch.sum(quadratic_term * x0, dim=1, keepdim=True)  # Compute final quadratic term involving x0  # Compute x^T * A^T * A * x0\n",
    "        x = self.constrained_layer3(x) + quadratic_output\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def custom_loss_energy_to_stress_with_fixed_std(model, inputs, targets, std_train_stress):\n",
    "    inputs.requires_grad = True\n",
    "    energy_outputs = model(inputs)  # Predicted energy (W)\n",
    "    # Compute stress as the derivative of energy with respect to strain\n",
    "    stress_outputs = torch.autograd.grad(\n",
    "        outputs=energy_outputs, \n",
    "        inputs=inputs,\n",
    "        grad_outputs=torch.ones_like(energy_outputs),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True\n",
    "    )[0]  \n",
    "    # Compute the stress at reference input (epsilon = 0)\n",
    "    reference_input = torch.zeros_like(inputs, requires_grad=True)  # Set requires_grad=True\n",
    "    reference_energy_output = model(reference_input)\n",
    "    reference_stress = torch.autograd.grad(\n",
    "        outputs=reference_energy_output, \n",
    "        inputs=reference_input,\n",
    "        grad_outputs=torch.ones_like(reference_energy_output),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True\n",
    "    )[0]\n",
    "    normalized_error = (stress_outputs - reference_stress - targets) / std_train_stress\n",
    "    loss = torch.sum(normalized_error ** 2)  # Mean of squared normalized error\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Instantiate the model, define loss and optimizer\n",
    "input_dim=1\n",
    "model = ICNN(input_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop with gradient clipping\n",
    "epochs = 5000\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for batch_x, batch_y in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        # loss = criterion(outputs, batch_y)\n",
    "        loss = custom_loss_energy_to_stress_with_fixed_std(model, batch_x, batch_y, std_train_stress)\n",
    "        loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "model.eval()\n",
    "y_pred = model(x_tensor).detach().numpy()\n",
    "x_data = x_data * (x_max - x_min) + x_min\n",
    "y_data = y_data * (y_max - y_min) + y_min\n",
    "y_pred = y_pred * (y_max - y_min) + y_min\n",
    "epsilon_out_of_range = np.linspace(0.3, 0.5, 50).reshape(-1, 1).astype(np.float32)\n",
    "epsilon_out_of_range_normalized = (epsilon_out_of_range - x_min) / (x_max - x_min)\n",
    "epsilon_out_of_range_tensor = torch.tensor(epsilon_out_of_range_normalized, dtype=torch.float32)\n",
    "sigma_out_of_range_pred = model(epsilon_out_of_range_tensor).detach().numpy()\n",
    "sigma_out_of_range_pred = sigma_out_of_range_pred * (y_max - y_min) + y_min\n",
    "sigma_out_of_range_analytical = (\n",
    "    E_modulus * epsilon_out_of_range\n",
    "    + C1 * epsilon_out_of_range ** 2\n",
    "    + C2 * epsilon_out_of_range ** 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x_data, y_data, label='True Data (Training Range)', color='blue', s=10)\n",
    "plt.plot(x_data, y_pred, label='Model Prediction (Training Range)', color='red')\n",
    "plt.scatter(epsilon_out_of_range, sigma_out_of_range_analytical, label='True Data (Out of Range)', color='green', s=10)\n",
    "plt.plot(epsilon_out_of_range, sigma_out_of_range_pred, label='Model Prediction (Out of Range)', color='orange')\n",
    "plt.plot(x_data, y_pred-y_data, color='magenta')\n",
    "# plt.legend()\n",
    "plt.xlabel('Strain (ε)')\n",
    "plt.ylabel('Stress (σ)')\n",
    "plt.title('Model Prediction vs True Data (Including Out of Range)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
