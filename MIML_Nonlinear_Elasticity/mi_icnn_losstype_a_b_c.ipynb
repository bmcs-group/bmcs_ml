{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import StepLR ,ReduceLROnPlateau\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_modulus = 200  \n",
    "C1, C2 = 400, 600\n",
    "noise_level = 0  \n",
    "def generate_nonlinear_elastic_data(epsilon_values, E, C1, C2, noise_level):\n",
    "    sigma = E * epsilon_values + C1 * epsilon_values ** 2 + C2 * epsilon_values ** 3\n",
    "    noise = noise_level * np.random.randn(*epsilon_values.shape)\n",
    "    return sigma + noise\n",
    "epsilon_train = np.linspace(0, 0.3, 100).reshape(-1, 1).astype(np.float32)\n",
    "sigma_train = generate_nonlinear_elastic_data(epsilon_train, E_modulus, C1, C2, noise_level).astype(np.float32)\n",
    "epsilon_train_tensor = torch.tensor(epsilon_train)\n",
    "sigma_train_tensor = torch.tensor(sigma_train)\n",
    "std_train_stress = torch.std(sigma_train_tensor).item()\n",
    "# Normalize the data using min-max normalization\n",
    "x_data = epsilon_train_tensor.numpy()\n",
    "y_data = sigma_train_tensor.numpy()\n",
    "x_min, x_max = x_data.min(), x_data.max()\n",
    "y_min, y_max = y_data.min(), y_data.max()\n",
    "x_data = (x_data - x_min) / (x_max - x_min)\n",
    "y_data = (y_data - y_min) / (y_max - y_min)\n",
    "x_tensor = torch.tensor(x_data, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y_data, dtype=torch.float32)\n",
    "# Create DataLoader for shuffling\n",
    "dataset = TensorDataset(x_tensor, y_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to denormalize data\n",
    "def denormalize(data, data_min, data_max):\n",
    "    return data * (data_max - data_min) + data_min\n",
    "\n",
    "# Adjust denormalization for energy\n",
    "def denormalize_energy(energy, x_min, x_max, y_min, y_max):\n",
    "    x_scale = x_max - x_min\n",
    "    y_scale = y_max - y_min\n",
    "    return energy * (x_scale * y_scale)\n",
    "\n",
    "# Load models\n",
    "models = {\n",
    "    \"MI_ICNN_Loss Type A\": torch.load(\"trained_model_losstype_a_10K.pth\"),\n",
    "    \"MI_ICNN_Loss Type B\": torch.load(\"trained_model_losstype_b_10K.pth\"),\n",
    "    \"MI_ICNN_Loss Type C\": torch.load(\"trained_model_losstype_c_10K.pth\"),\n",
    "}\n",
    "for model in models.values():\n",
    "    model.eval()\n",
    "\n",
    "# Load black-box model\n",
    "model_bb = torch.load(\"black_box_nn.pth\")\n",
    "model_bb.eval()\n",
    "\n",
    "# Initialize lists for results\n",
    "results = {key: {\"pred_energy\": [], \"pred_stress\": []} for key in models}\n",
    "real_results = {\"strain\": [], \"real_energy\": [], \"real_stress\": []}\n",
    "\n",
    "# Generate validation data\n",
    "epsilon_validation = np.linspace(0, 0.8, 700).reshape(-1, 1).astype(np.float32)\n",
    "sigma_validation = generate_nonlinear_elastic_data(\n",
    "    epsilon_validation, E_modulus, C1, C2, noise_level\n",
    ").astype(np.float32)\n",
    "\n",
    "# Normalize data\n",
    "x_data = (epsilon_validation - x_min) / (x_max - x_min)\n",
    "y_data = (sigma_validation - y_min) / (y_max - y_min)\n",
    "x_tensor = torch.tensor(x_data, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y_data, dtype=torch.float32)\n",
    "dataset = TensorDataset(x_tensor, y_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Process each model\n",
    "for model_name, model in models.items():\n",
    "    for batch_x, batch_y in dataloader:\n",
    "        batch_x.requires_grad_()\n",
    "        pred_energy = model(batch_x)\n",
    "        pred_stress = torch.autograd.grad(pred_energy, batch_x, create_graph=True)[0]\n",
    "\n",
    "        pred_energy = denormalize_energy(pred_energy.detach().numpy(), x_min, x_max, y_min, y_max)\n",
    "        pred_stress = denormalize(pred_stress.detach().numpy(), y_min, y_max)\n",
    "\n",
    "        results[model_name][\"pred_energy\"].append(pred_energy)\n",
    "        results[model_name][\"pred_stress\"].append(pred_stress)\n",
    "\n",
    "# Compute real values (same for all models)\n",
    "for batch_x, batch_y in dataloader:\n",
    "    strain = denormalize(batch_x.detach().numpy(), x_min, x_max)\n",
    "    real_stress = denormalize(batch_y.detach().numpy(), y_min, y_max)\n",
    "    real_energy = 0.5 * E_modulus * strain ** 2 + (C1 / 3) * strain ** 3 + (C2 / 4) * strain ** 4\n",
    "\n",
    "    real_results[\"strain\"].append(strain)\n",
    "    real_results[\"real_energy\"].append(real_energy)\n",
    "    real_results[\"real_stress\"].append(real_stress)\n",
    "\n",
    "# Black-box predictions\n",
    "pred_sigma_test = model_bb(torch.tensor(epsilon_validation)).detach().numpy()\n",
    "\n",
    "# Plot stress\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(np.concatenate(real_results[\"strain\"]), np.concatenate(real_results[\"real_stress\"]), label='Analytical Stress')\n",
    "for model_name, data in results.items():\n",
    "    plt.plot(np.concatenate(real_results[\"strain\"]), np.concatenate(data[\"pred_stress\"]), label=f'{model_name} Predicted Stress')\n",
    "plt.plot(epsilon_validation, pred_sigma_test, label='BB_NN Predicted Stress')\n",
    "plt.axvline(x=0.3, color='black', linestyle='--', label='Training-Unseen Boundary')\n",
    "plt.xlabel('Strain')\n",
    "plt.ylabel('Stress')\n",
    "plt.title('Stress: Analytical vs Predicted')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "Loss_A = r\"\\frac{\\partial \\mathcal{N}\\left(\\varepsilon_i\\right)}{\\partial \\varepsilon} - \\sigma_i\"\n",
    "Loss_B = r\"\\frac{1}{2}\\left(\\frac{\\partial \\mathcal{N}\\left(\\varepsilon_i\\right)}{\\partial \\varepsilon} + \\frac{\\partial \\mathcal{N}\\left(\\varepsilon_{i+1}\\right)}{\\partial \\varepsilon}\\right) - \\frac{1}{2}\\left(\\sigma_i + \\sigma_{i+1}\\right)\"\n",
    "Loss_C = r\"\\frac{1}{2}\\left(\\frac{\\partial \\mathcal{N}\\left(\\varepsilon_i\\right)}{\\partial \\varepsilon} + \\Delta \\varepsilon_i \\frac{\\partial^2 \\mathcal{N}\\left(\\varepsilon_i\\right)}{\\partial \\varepsilon^2}\\right) - \\frac{1}{2}\\sigma_{i+1}\"\n",
    "\n",
    "plt.text(0.0, 400, \"Type A: \" + f\"${Loss_A}$\",\n",
    "         fontsize=14, bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=\"black\", facecolor=\"lightgrey\"))\n",
    "plt.text(0, 300, \"Type B: \" + f\"${Loss_B}$\",\n",
    "         fontsize=14, bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=\"black\", facecolor=\"lightgrey\"))\n",
    "plt.text(0, 200, \"Type C: \" + f\"${Loss_C}$\",\n",
    "         fontsize=14, bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=\"black\", facecolor=\"lightgrey\"))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Plot energy\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(np.concatenate(real_results[\"strain\"]), np.concatenate(real_results[\"real_energy\"]), label='Analytical Elastic Energy')\n",
    "for model_name, data in results.items():\n",
    "    plt.plot(np.concatenate(real_results[\"strain\"]), np.concatenate(data[\"pred_energy\"]), label=f'{model_name} Predicted Energy')\n",
    "plt.axvline(x=0.3, color='black', linestyle='--', label='Training-Unseen Boundary')\n",
    "plt.xlabel('Strain')\n",
    "plt.ylabel('Energy')\n",
    "plt.title('Elastic Energy: Analytical vs Predicted')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "Loss_A = r\"\\frac{\\partial \\mathcal{N}\\left(\\varepsilon_i\\right)}{\\partial \\varepsilon} - \\sigma_i\"\n",
    "Loss_B = r\"\\frac{1}{2}\\left(\\frac{\\partial \\mathcal{N}\\left(\\varepsilon_i\\right)}{\\partial \\varepsilon} + \\frac{\\partial \\mathcal{N}\\left(\\varepsilon_{i+1}\\right)}{\\partial \\varepsilon}\\right) - \\frac{1}{2}\\left(\\sigma_i + \\sigma_{i+1}\\right)\"\n",
    "Loss_C = r\"\\frac{1}{2}\\left(\\frac{\\partial \\mathcal{N}\\left(\\varepsilon_i\\right)}{\\partial \\varepsilon} + \\Delta \\varepsilon_i \\frac{\\partial^2 \\mathcal{N}\\left(\\varepsilon_i\\right)}{\\partial \\varepsilon^2}\\right) - \\frac{1}{2}\\sigma_{i+1}\"\n",
    "\n",
    "plt.text(0, 125, \"Type A: \" + f\"${Loss_A}$\",\n",
    "         fontsize=14, bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=\"black\", facecolor=\"lightgrey\"))\n",
    "plt.text(0, 100, \"Type B: \" + f\"${Loss_B}$\",\n",
    "         fontsize=14, bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=\"black\", facecolor=\"lightgrey\"))\n",
    "plt.text(0, 75, \"Type C: \" + f\"${Loss_C}$\",\n",
    "         fontsize=14, bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=\"black\", facecolor=\"lightgrey\"))\n",
    "plt.show()\n",
    "\n",
    "# Compute and plot stiffness\n",
    "plt.figure(figsize=(12, 6))\n",
    "real_stiffness = np.gradient(np.concatenate(real_results[\"real_stress\"]).flatten(), np.concatenate(real_results[\"strain\"]).flatten())\n",
    "plt.plot(np.concatenate(real_results[\"strain\"]), real_stiffness, label='Analytical Stiffness')\n",
    "for model_name, data in results.items():\n",
    "    pred_stiffness = np.gradient(np.concatenate(data[\"pred_stress\"]).flatten(), np.concatenate(real_results[\"strain\"]).flatten())\n",
    "    plt.plot(np.concatenate(real_results[\"strain\"]), pred_stiffness, label=f'{model_name} Predicted Stiffness')\n",
    "plt.axvline(x=0.3, color='black', linestyle='--', label='Training-Unseen Boundary')\n",
    "plt.xlabel('Strain')\n",
    "plt.ylabel('Stiffness')\n",
    "plt.title('Tangential Stiffness: Analytical vs Predicted')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "Loss_A = r\"\\frac{\\partial \\mathcal{N}\\left(\\varepsilon_i\\right)}{\\partial \\varepsilon} - \\sigma_i\"\n",
    "Loss_B = r\"\\frac{1}{2}\\left(\\frac{\\partial \\mathcal{N}\\left(\\varepsilon_i\\right)}{\\partial \\varepsilon} + \\frac{\\partial \\mathcal{N}\\left(\\varepsilon_{i+1}\\right)}{\\partial \\varepsilon}\\right) - \\frac{1}{2}\\left(\\sigma_i + \\sigma_{i+1}\\right)\"\n",
    "Loss_C = r\"\\frac{1}{2}\\left(\\frac{\\partial \\mathcal{N}\\left(\\varepsilon_i\\right)}{\\partial \\varepsilon} + \\Delta \\varepsilon_i \\frac{\\partial^2 \\mathcal{N}\\left(\\varepsilon_i\\right)}{\\partial \\varepsilon^2}\\right) - \\frac{1}{2}\\sigma_{i+1}\"\n",
    "\n",
    "plt.text(0, 1250, \"Type A: \" + f\"${Loss_A}$\",\n",
    "         fontsize=14, bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=\"black\", facecolor=\"lightgrey\"))\n",
    "plt.text(0, 1000, \"Type B: \" + f\"${Loss_B}$\",\n",
    "         fontsize=14, bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=\"black\", facecolor=\"lightgrey\"))\n",
    "plt.text(0, 750, \"Type C: \" + f\"${Loss_C}$\",\n",
    "         fontsize=14, bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=\"black\", facecolor=\"lightgrey\"))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot normalized error between analytical and predicted stress\n",
    "plt.figure(figsize=(12, 6))\n",
    "for model_name, data in results.items():\n",
    "    error_stress = np.abs(np.concatenate(real_results[\"real_stress\"]) - np.concatenate(data[\"pred_stress\"]))\n",
    "    normalized_error = error_stress / np.abs(np.concatenate(real_results[\"real_stress\"]))\n",
    "    plt.plot(np.concatenate(real_results[\"strain\"]), normalized_error, label=f'{model_name} Normalized Stress Error')\n",
    "\n",
    "# Add black-box error analysis for stress\n",
    "bb_error_stress = np.abs(np.concatenate(real_results[\"real_stress\"]) - pred_sigma_test)\n",
    "bb_normalized_error = bb_error_stress / np.abs(np.concatenate(real_results[\"real_stress\"]))\n",
    "plt.plot(np.concatenate(real_results[\"strain\"]), bb_normalized_error, label='BB_NN Normalized Stress Error')\n",
    "\n",
    "plt.axvline(x=0.3, color='black', linestyle='--', label='Training-Unseen Boundary')\n",
    "plt.xlabel('Strain')\n",
    "plt.ylabel('Normalized Stress Error')\n",
    "plt.title('Normalized Stress Error: Analytical vs Predicted')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "Loss_A = r\"\\frac{\\partial \\mathcal{N}\\left(\\varepsilon_i\\right)}{\\partial \\varepsilon} - \\sigma_i\"\n",
    "Loss_B = r\"\\frac{1}{2}\\left(\\frac{\\partial \\mathcal{N}\\left(\\varepsilon_i\\right)}{\\partial \\varepsilon} + \\frac{\\partial \\mathcal{N}\\left(\\varepsilon_{i+1}\\right)}{\\partial \\varepsilon}\\right) - \\frac{1}{2}\\left(\\sigma_i + \\sigma_{i+1}\\right)\"\n",
    "Loss_C = r\"\\frac{1}{2}\\left(\\frac{\\partial \\mathcal{N}\\left(\\varepsilon_i\\right)}{\\partial \\varepsilon} + \\Delta \\varepsilon_i \\frac{\\partial^2 \\mathcal{N}\\left(\\varepsilon_i\\right)}{\\partial \\varepsilon^2}\\right) - \\frac{1}{2}\\sigma_{i+1}\"\n",
    "\n",
    "plt.text(0, 0.35, \"Type A: \" + f\"${Loss_A}$\",\n",
    "         fontsize=14, bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=\"black\", facecolor=\"lightgrey\"))\n",
    "plt.text(0, 0.28, \"Type B: \" + f\"${Loss_B}$\",\n",
    "         fontsize=14, bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=\"black\", facecolor=\"lightgrey\"))\n",
    "plt.text(0, 0.21, \"Type C: \" + f\"${Loss_C}$\",\n",
    "         fontsize=14, bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=\"black\", facecolor=\"lightgrey\"))\n",
    "plt.show()\n",
    "\n",
    "# Plot normalized error between analytical and predicted energy\n",
    "plt.figure(figsize=(12, 6))\n",
    "for model_name, data in results.items():\n",
    "    error_energy = np.abs(np.concatenate(real_results[\"real_energy\"]) - np.concatenate(data[\"pred_energy\"]))\n",
    "    normalized_error_energy = error_energy / np.abs(np.concatenate(real_results[\"real_energy\"]))\n",
    "    plt.plot(np.concatenate(real_results[\"strain\"]), normalized_error_energy, label=f'{model_name} Normalized Energy Error')\n",
    "\n",
    "plt.axvline(x=0.3, color='black', linestyle='--', label='Training-Unseen Boundary')\n",
    "plt.xlabel('Strain')\n",
    "plt.ylabel('Normalized Energy Error')\n",
    "plt.title('Normalized Energy Error: Analytical vs Predicted')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Plot normalized error between analytical and predicted stiffness\n",
    "plt.figure(figsize=(12, 6))\n",
    "real_stiffness = np.gradient(np.concatenate(real_results[\"real_stress\"]).flatten(), np.concatenate(real_results[\"strain\"]).flatten())\n",
    "for model_name, data in results.items():\n",
    "    pred_stiffness = np.gradient(np.concatenate(data[\"pred_stress\"]).flatten(), np.concatenate(real_results[\"strain\"]).flatten())\n",
    "    error_stiffness = np.abs(real_stiffness - pred_stiffness)\n",
    "    normalized_error_stiffness = error_stiffness / np.abs(real_stiffness)\n",
    "    plt.plot(np.concatenate(real_results[\"strain\"]), normalized_error_stiffness, label=f'{model_name} Normalized Stiffness Error')\n",
    "\n",
    "plt.axvline(x=0.3, color='black', linestyle='--', label='Training-Unseen Boundary')\n",
    "plt.xlabel('Strain')\n",
    "plt.ylabel('Normalized Stiffness Error')\n",
    "plt.title('Normalized Stiffness Error: Analytical vs Predicted')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot normalized error between analytical and predicted stress\n",
    "plt.figure(figsize=(12, 6))\n",
    "for model_name, data in results.items():\n",
    "    error_stress = np.abs(np.concatenate(real_results[\"real_stress\"]) - np.concatenate(data[\"pred_stress\"]))\n",
    "    normalized_error = error_stress / np.abs(np.concatenate(real_results[\"real_stress\"]))\n",
    "    plt.plot(np.concatenate(real_results[\"strain\"]), normalized_error, label=f'{model_name} Normalized Stress Error')\n",
    "\n",
    "# Add black-box error analysis for stress\n",
    "bb_error_stress = np.abs(np.concatenate(real_results[\"real_stress\"]) - pred_sigma_test)\n",
    "bb_normalized_error = bb_error_stress / np.abs(np.concatenate(real_results[\"real_stress\"]))\n",
    "plt.plot(np.concatenate(real_results[\"strain\"]), bb_normalized_error, label='BB_NN Normalized Stress Error')\n",
    "\n",
    "plt.axvline(x=0.3, color='black', linestyle='--', label='Training-Unseen Boundary')\n",
    "plt.yscale('log')  # Use logarithmic scale for better visibility of small errors\n",
    "plt.xlabel('Strain')\n",
    "plt.ylabel('Normalized Stress Error (log scale)')\n",
    "plt.title('Normalized Stress Error: Analytical vs Predicted')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "Loss_A = r\"\\frac{\\partial \\mathcal{N}\\left(\\varepsilon_i\\right)}{\\partial \\varepsilon} - \\sigma_i\"\n",
    "Loss_B = r\"\\frac{1}{2}\\left(\\frac{\\partial \\mathcal{N}\\left(\\varepsilon_i\\right)}{\\partial \\varepsilon} + \\frac{\\partial \\mathcal{N}\\left(\\varepsilon_{i+1}\\right)}{\\partial \\varepsilon}\\right) - \\frac{1}{2}\\left(\\sigma_i + \\sigma_{i+1}\\right)\"\n",
    "Loss_C = r\"\\frac{1}{2}\\left(\\frac{\\partial \\mathcal{N}\\left(\\varepsilon_i\\right)}{\\partial \\varepsilon} + \\Delta \\varepsilon_i \\frac{\\partial^2 \\mathcal{N}\\left(\\varepsilon_i\\right)}{\\partial \\varepsilon^2}\\right) - \\frac{1}{2}\\sigma_{i+1}\"\n",
    "\n",
    "plt.text(0.47, 0.0005, \"Type A: \" + f\"${Loss_A}$\",\n",
    "         fontsize=14, bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=\"black\", facecolor=\"lightgrey\"))\n",
    "plt.text(0.47, 0.0001, \"Type B: \" + f\"${Loss_B}$\",\n",
    "         fontsize=14, bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=\"black\", facecolor=\"lightgrey\"))\n",
    "plt.text(0.47, 0.00002, \"Type C: \" + f\"${Loss_C}$\",\n",
    "         fontsize=14, bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=\"black\", facecolor=\"lightgrey\"))\n",
    "plt.show()\n",
    "\n",
    "# Plot normalized error between analytical and predicted energy\n",
    "plt.figure(figsize=(12, 6))\n",
    "for model_name, data in results.items():\n",
    "    error_energy = np.abs(np.concatenate(real_results[\"real_energy\"]) - np.concatenate(data[\"pred_energy\"]))\n",
    "    normalized_error_energy = error_energy / np.abs(np.concatenate(real_results[\"real_energy\"]))\n",
    "    plt.plot(np.concatenate(real_results[\"strain\"]), normalized_error_energy, label=f'{model_name} Normalized Energy Error')\n",
    "\n",
    "plt.axvline(x=0.3, color='black', linestyle='--', label='Training-Unseen Boundary')\n",
    "plt.yscale('log')  # Use logarithmic scale for better visibility of small errors\n",
    "plt.xlabel('Strain')\n",
    "plt.ylabel('Normalized Energy Error (log scale)')\n",
    "plt.title('Normalized Energy Error: Analytical vs Predicted')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "Loss_A = r\"\\frac{\\partial \\mathcal{N}\\left(\\varepsilon_i\\right)}{\\partial \\varepsilon} - \\sigma_i\"\n",
    "Loss_B = r\"\\frac{1}{2}\\left(\\frac{\\partial \\mathcal{N}\\left(\\varepsilon_i\\right)}{\\partial \\varepsilon} + \\frac{\\partial \\mathcal{N}\\left(\\varepsilon_{i+1}\\right)}{\\partial \\varepsilon}\\right) - \\frac{1}{2}\\left(\\sigma_i + \\sigma_{i+1}\\right)\"\n",
    "Loss_C = r\"\\frac{1}{2}\\left(\\frac{\\partial \\mathcal{N}\\left(\\varepsilon_i\\right)}{\\partial \\varepsilon} + \\Delta \\varepsilon_i \\frac{\\partial^2 \\mathcal{N}\\left(\\varepsilon_i\\right)}{\\partial \\varepsilon^2}\\right) - \\frac{1}{2}\\sigma_{i+1}\"\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Plot normalized error between analytical and predicted stiffness\n",
    "plt.figure(figsize=(12, 6))\n",
    "real_stiffness = np.gradient(np.concatenate(real_results[\"real_stress\"]).flatten(), np.concatenate(real_results[\"strain\"]).flatten())\n",
    "for model_name, data in results.items():\n",
    "    pred_stiffness = np.gradient(np.concatenate(data[\"pred_stress\"]).flatten(), np.concatenate(real_results[\"strain\"]).flatten())\n",
    "    error_stiffness = np.abs(real_stiffness - pred_stiffness)\n",
    "    normalized_error_stiffness = error_stiffness / np.abs(real_stiffness)\n",
    "    plt.plot(np.concatenate(real_results[\"strain\"]), normalized_error_stiffness, label=f'{model_name} Normalized Stiffness Error')\n",
    "\n",
    "\n",
    "plt.axvline(x=0.3, color='black', linestyle='--', label='Training-Unseen Boundary')\n",
    "plt.yscale('log')  # Use logarithmic scale for better visibility of small errors\n",
    "plt.xlabel('Strain')\n",
    "plt.ylabel('Normalized Stiffness Error (log scale)')\n",
    "plt.title('Normalized Stiffness Error: Analytical vs Predicted')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "Loss_A = r\"\\frac{\\partial \\mathcal{N}\\left(\\varepsilon_i\\right)}{\\partial \\varepsilon} - \\sigma_i\"\n",
    "Loss_B = r\"\\frac{1}{2}\\left(\\frac{\\partial \\mathcal{N}\\left(\\varepsilon_i\\right)}{\\partial \\varepsilon} + \\frac{\\partial \\mathcal{N}\\left(\\varepsilon_{i+1}\\right)}{\\partial \\varepsilon}\\right) - \\frac{1}{2}\\left(\\sigma_i + \\sigma_{i+1}\\right)\"\n",
    "Loss_C = r\"\\frac{1}{2}\\left(\\frac{\\partial \\mathcal{N}\\left(\\varepsilon_i\\right)}{\\partial \\varepsilon} + \\Delta \\varepsilon_i \\frac{\\partial^2 \\mathcal{N}\\left(\\varepsilon_i\\right)}{\\partial \\varepsilon^2}\\right) - \\frac{1}{2}\\sigma_{i+1}\"\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
