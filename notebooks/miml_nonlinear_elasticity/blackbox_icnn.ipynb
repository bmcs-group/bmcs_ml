{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Code 2: Generate strain-stress data\n",
    "E_modulus = 200  # Elastic modulus (MPa)\n",
    "C1, C2 = 500, 600  # Nonlinear coefficients\n",
    "noise_level = 0  # Set to zero for clean data\n",
    "\n",
    "def generate_nonlinear_elastic_data(epsilon_values, E, C1, C2, noise_level):\n",
    "    sigma = E * epsilon_values + C1 * epsilon_values ** 2 + C2 * epsilon_values ** 3\n",
    "    noise = noise_level * np.random.randn(*epsilon_values.shape)\n",
    "    return sigma + noise\n",
    "\n",
    "epsilon_train = np.linspace(0, 0.3, 100).reshape(-1, 1).astype(np.float32)\n",
    "sigma_train = generate_nonlinear_elastic_data(epsilon_train, E_modulus, C1, C2, noise_level).astype(np.float32)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "epsilon_train_tensor = torch.tensor(epsilon_train, requires_grad=False)\n",
    "sigma_train_tensor = torch.tensor(sigma_train)\n",
    "\n",
    "# Code 1: Integrate the strain-stress data into the model training\n",
    "# Normalize the data using min-max normalization\n",
    "x_data = epsilon_train_tensor.numpy()\n",
    "y_data = sigma_train_tensor.numpy()\n",
    "\n",
    "x_min, x_max = x_data.min(), x_data.max()\n",
    "y_min, y_max = y_data.min(), y_data.max()\n",
    "\n",
    "x_data = (x_data - x_min) / (x_max - x_min)\n",
    "y_data = (y_data - y_min) / (y_max - y_min)\n",
    "\n",
    "x_tensor = torch.tensor(x_data, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y_data, dtype=torch.float32)\n",
    "\n",
    "# Create DataLoader for shuffling\n",
    "dataset = TensorDataset(x_tensor, y_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Define a Constrained Linear Model\n",
    "class ConstrainedLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(ConstrainedLinear, self).__init__()\n",
    "        self.Q = nn.Parameter(torch.randn(out_features, in_features))\n",
    "        self.alpha = nn.Parameter(torch.tensor(0.1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        alpha_squared = F.softplus(self.alpha) + 1e-6\n",
    "        W = (1 / (alpha_squared ** 2)) * torch.log1p(torch.exp(alpha_squared ** 2 * self.Q))\n",
    "        return F.linear(x, W)\n",
    "\n",
    "# Define a simple neural network model\n",
    "class ICNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ICNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(1, 20)\n",
    "        self.constrained_layer1 = ConstrainedLinear(20, 10)\n",
    "        self.constrained_layer2 = ConstrainedLinear(10, 10)\n",
    "        self.constrained_layer3 = ConstrainedLinear(10, 1)\n",
    "        self.A = nn.Parameter(torch.randn(1, 10))\n",
    "        self.shortcut_layer2 = nn.Linear(1, 10, bias=False)\n",
    "        self.shortcut_layer3 = nn.Linear(1, 10, bias=False)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut2 = self.shortcut_layer2(x)\n",
    "        shortcut3 = self.shortcut_layer3(x)\n",
    "        x = self.activation(self.layer1(x))\n",
    "        x = self.activation(self.constrained_layer1(x) + shortcut2)\n",
    "        x = self.activation(self.constrained_layer2(x) + shortcut3)\n",
    "        quadratic_term = torch.matmul(x, self.A.T)\n",
    "        quadratic_term = torch.matmul(quadratic_term, self.A)\n",
    "        quadratic_output = torch.sum(quadratic_term * x, dim=1, keepdim=True)\n",
    "        x = self.constrained_layer3(x) + quadratic_output\n",
    "        return x\n",
    "\n",
    "# Instantiate the model, define loss and optimizer\n",
    "model = ICNN()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop with gradient clipping\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for batch_x, batch_y in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "y_pred = model(x_tensor).detach().numpy()\n",
    "\n",
    "# Unnormalize for plotting\n",
    "x_data = x_data * (x_max - x_min) + x_min\n",
    "y_data = y_data * (y_max - y_min) + y_min\n",
    "y_pred = y_pred * (y_max - y_min) + y_min\n",
    "\n",
    "# Generate out-of-range strain data for evaluation\n",
    "epsilon_out_of_range = np.linspace(0.3, 0.5, 50).reshape(-1, 1).astype(np.float32)\n",
    "\n",
    "# Normalize the out-of-range data using the same normalization parameters as the training data\n",
    "epsilon_out_of_range_normalized = (epsilon_out_of_range - x_min) / (x_max - x_min)\n",
    "\n",
    "# Convert to PyTorch tensor\n",
    "epsilon_out_of_range_tensor = torch.tensor(epsilon_out_of_range_normalized, dtype=torch.float32)\n",
    "\n",
    "# Predict using the trained model\n",
    "sigma_out_of_range_pred = model(epsilon_out_of_range_tensor).detach().numpy()\n",
    "\n",
    "# Unnormalize the predictions\n",
    "sigma_out_of_range_pred = sigma_out_of_range_pred * (y_max - y_min) + y_min\n",
    "\n",
    "# Analytical comparison for the out-of-range data\n",
    "sigma_out_of_range_analytical = (\n",
    "    E_modulus * epsilon_out_of_range\n",
    "    + C1 * epsilon_out_of_range ** 2\n",
    "    + C2 * epsilon_out_of_range ** 3\n",
    ")\n",
    "\n",
    "# Plot in-range and out-of-range results\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot training range predictions\n",
    "plt.scatter(x_data, y_data, label='True Data (Training Range)', color='blue', s=10)\n",
    "plt.plot(x_data, y_pred, label='Model Prediction (Training Range)', color='red')\n",
    "\n",
    "# Plot out-of-range predictions\n",
    "plt.scatter(epsilon_out_of_range, sigma_out_of_range_analytical, label='True Data (Out of Range)', color='green', s=10)\n",
    "plt.plot(epsilon_out_of_range, sigma_out_of_range_pred, label='Model Prediction (Out of Range)', color='orange')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Strain (ε)')\n",
    "plt.ylabel('Stress (σ)')\n",
    "plt.title('Model Prediction vs True Data (Including Out of Range)')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
