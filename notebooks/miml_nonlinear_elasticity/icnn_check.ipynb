{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data\n",
    "def generate_data(num_samples=1000):\n",
    "    x = np.linspace(-10, 10, num_samples)\n",
    "    y = np.abs(x) + np.sin(x)\n",
    "    return x, y\n",
    "x_data, y_data = generate_data()\n",
    "x_min, x_max = x_data.min(), x_data.max()\n",
    "y_min, y_max = y_data.min(), y_data.max()\n",
    "x_data = (x_data - x_min) / (x_max - x_min)\n",
    "y_data = (y_data - y_min) / (y_max - y_min)\n",
    "x_tensor = torch.tensor(x_data, dtype=torch.float32).unsqueeze(1)\n",
    "y_tensor = torch.tensor(y_data, dtype=torch.float32).unsqueeze(1)\n",
    "dataset = TensorDataset(x_tensor, y_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define SoftplusSquared Activation function\n",
    "class SoftplusSquared(nn.Module):\n",
    "    def __init__(self, beta=1):\n",
    "        super(SoftplusSquared, self).__init__()\n",
    "        self.beta = nn.Parameter(torch.tensor(float(beta)))  # Make beta a trainable parameter\n",
    "    def forward(self, x):\n",
    "        return (1 / (2 * self.beta ** 4)) * (torch.log10(torch.exp(self.beta ** 2 * x))) ** 2\n",
    "\n",
    "# Define a Constrained Linear Model (positive weights)\n",
    "class ConstrainedLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(ConstrainedLinear, self).__init__()\n",
    "        self.raw_weights = nn.Parameter(torch.randn(out_features, in_features)) # Make raw_weights trainable parameter\n",
    "        self.alpha = nn.Parameter(torch.tensor(0.1)) # Make alpha a trainable parameter\n",
    "    def forward(self, x):\n",
    "        positive_weights = (1 / (self.alpha ** 2)) * torch.log10(torch.exp(self.alpha ** 2 * self.raw_weights))\n",
    "        return F.linear(x, positive_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define neural network model\n",
    "class ICNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(ICNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, 20)\n",
    "        self.constrained_layer1 = ConstrainedLinear(20, 10)\n",
    "        self.constrained_layer2 = ConstrainedLinear(10, 10)\n",
    "        self.constrained_layer3 = ConstrainedLinear(10, 1)\n",
    "        self.A = nn.Parameter(torch.randn(input_dim, input_dim))  # Trainable A\n",
    "        self.shortcut_layer2 = nn.Linear(input_dim, 10, bias=False)\n",
    "        self.shortcut_layer3 = nn.Linear(input_dim, 10, bias=False)\n",
    "        self.activation = SoftplusSquared()\n",
    "    def forward(self, x):\n",
    "        x0 = x  # Original input (batch_size, input_dim)\n",
    "        shortcut2 = self.shortcut_layer2(x)  \n",
    "        shortcut3 = self.shortcut_layer3(x)  \n",
    "        x = self.activation(self.layer1(x))  \n",
    "        x = self.activation(self.constrained_layer1(x) + shortcut2) \n",
    "        x = self.activation(self.constrained_layer2(x) + shortcut3)\n",
    "        # Quadratic term computation: f(x0) = x0^T A^T A x0\n",
    "        quadratic_term = torch.matmul(x0, self.A.T)  # (batch_size, input_dim) @ (input_dim, input_dim) -> (batch_size, input_dim)\n",
    "        quadratic_term = torch.matmul(quadratic_term, self.A)  # (batch_size, input_dim) @ (input_dim, input_dim) -> (batch_size, input_dim)\n",
    "        quadratic_output = torch.sum(quadratic_term * x0, dim=1, keepdim=True)  # Scalar per sample, shape: (batch_size, 1)\n",
    "        x = self.constrained_layer3(x) + quadratic_output  # Shape: (batch_size, 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model, define loss and \n",
    "input_dim=1\n",
    "model = ICNN(input_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Reduced learning rate for stability\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for batch_x, batch_y in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        # Clip gradients to prevent exploding gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "y_pred = model(x_tensor).detach().numpy()\n",
    "# Unnormalize x_data, y_data, and y_pred for plotting\n",
    "x_data = x_data * (x_max - x_min) + x_min\n",
    "y_data = y_data * (y_max - y_min) + y_min\n",
    "y_pred = y_pred * (y_max - y_min) + y_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x_data, y_data, label='True Data', color='blue', s=10)\n",
    "plt.plot(x_data, y_pred, label='Predicted Data', color='red')\n",
    "plt.legend()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Model Prediction vs True Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the neural network structure\n",
    "G = nx.DiGraph()\n",
    "# Adding nodes for each layer\n",
    "G.add_node(\"Input Layer (1 neuron)\")\n",
    "G.add_node(\"Hidden Layer 1 (20 neurons)\")\n",
    "G.add_node(\"Hidden Layer 2 (10 neurons)\")\n",
    "G.add_node(\"Hidden Layer 3 (10 neurons)\")\n",
    "G.add_node(\"Output Layer (1 neuron)\")\n",
    "# Adding edges to represent connections\n",
    "G.add_edge(\"Input Layer (1 neuron)\", \"Hidden Layer 1 (20 neurons)\", label=\"Linear + SoftplusSquared\")\n",
    "G.add_edge(\"Input Layer (1 neuron)\", \"Hidden Layer 2 (10 neurons)\", label=\"Shortcut Linear to Hidden Layer 2\")\n",
    "G.add_edge(\"Input Layer (1 neuron)\", \"Hidden Layer 3 (10 neurons)\", label=\"Shortcut Linear to Hidden Layer 3\")  # Add shortcut connection\n",
    "G.add_edge(\"Hidden Layer 1 (20 neurons)\", \"Hidden Layer 2 (10 neurons)\", label=\"Constrained Linear + SoftplusSquared\")\n",
    "G.add_edge(\"Hidden Layer 2 (10 neurons)\", \"Hidden Layer 3 (10 neurons)\", label=\"Constrained Linear + SoftplusSquared + Shortcut\")\n",
    "G.add_edge(\"Hidden Layer 3 (10 neurons)\", \"Output Layer (1 neuron)\", label=\"Constrained Linear + Quadratic Term\")\n",
    "# Draw the graph\n",
    "pos = nx.spring_layout(G)\n",
    "plt.figure(figsize=(12, 8))\n",
    "nx.draw(G, pos, with_labels=True, node_size=3000, node_color='lightblue', font_size=10, font_weight='bold', arrows=True)\n",
    "edges = nx.get_edge_attributes(G, 'label')\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=edges, font_size=9, font_color='red')\n",
    "plt.title(\"Neural Network Structure\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
