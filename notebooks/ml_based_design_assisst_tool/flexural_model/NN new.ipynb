{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction of FFNN based on normalized training space\n",
    "Upon stabilization and convergence of the model training loss curve to a non small number, normalization becomes imperative to homogenize the training space. Here, the training procedure is reiterated on a normalized training space employing two methods, namely min-max and Z-score normalization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import save_model\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "making home directory if it doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = Path().home()\n",
    "ml_data = home_dir / 'ml_data'\n",
    "if not ml_data.exists():\n",
    "    ml_data.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the training space and normalizing \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data which is already generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Design_space = np.load(ml_data / 'Design_space2.npy')\n",
    "moment_capacity = np.load(ml_data / 'Mu2.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization of input data for training a neural network is a crucial preprocessing step that ensures stable and efficient training. It involves scaling the input features to a similar range, typically between 0 and 1 or with zero mean and unit variance. This helps prevent certain features from dominating the learning process and can accelerate convergence during training. Here's how we can normalize input data for training the neural network using min-max normalization and Z-score normalization:\n",
    "1. Min-Max Normalization: Min-max normalization scales the input features to a fixed range, typically between 0 and 1.\n",
    "$$\n",
    "x_{\\text {norm }}=\\frac{x-\\min (x)}{\\max (x)-\\min (x)}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max Normalization\n",
    "Design_space_normalized_min_max = (Design_space - np.min(Design_space, axis=0)) / (np.max(Design_space, axis=0) - np.min(Design_space, axis=0))\n",
    "moment_capacity_normalized_min_max = (moment_capacity - np.min(moment_capacity, axis=0)) / (np.max(moment_capacity, axis=0) - np.min(moment_capacity, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Z-score Normalization: Z-score normalization (also known as standardization) scales the input features to have a mean of 0 and a standard deviation of 1 .\n",
    "$$\n",
    "x_{\\text {norm }}=\\frac{x-\\operatorname{mean}(x)}{\\operatorname{std}(x)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-score Normalization:\n",
    "Design_space_normalized_z_score = (Design_space - np.mean(Design_space, axis=0)) / np.std(Design_space, axis=0)\n",
    "moment_capacity_normalized_z_score = (moment_capacity - np.mean(moment_capacity, axis=0)) / np.std(moment_capacity, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of the admissible design space for defined moment capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(25, 10))\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "ax1.set_xlabel('Width (mm)')\n",
    "ax1.set_ylabel('Height (mm)')\n",
    "ax1.set_zlabel('Moment Capacity')\n",
    "ax1.set_title('Reinforcement Ratio Surface')\n",
    "ax2.set_xlabel('Width (mm)')\n",
    "ax2.set_ylabel('Height (mm)')\n",
    "ax2.set_zlabel('Moment Capacity')\n",
    "ax2.set_title('Reinforcement Ratio Surface')\n",
    "\n",
    "def plot_points_within_tolerance(Design_space_normalized_min_max, moment_capacity_normalized_min_max, target_z_value, tolerance, step_reinforcement, ax1, ax2):\n",
    "    index=0\n",
    "    for i in np.unique(Design_space_normalized_min_max[:, 0])[::step_reinforcement]:\n",
    "        subset = Design_space_normalized_min_max[Design_space_normalized_min_max[:, 0] == i]\n",
    "        z_values = np.array(moment_capacity_normalized_min_max[Design_space_normalized_min_max[:, 0] == i])\n",
    "        for target_z_value in target_z_values:\n",
    "            within_tolerance = np.isclose(z_values, target_z_value, rtol=tolerance)\n",
    "            colors = ['red' if val else 'blue' for val in within_tolerance]\n",
    "            red_indices = np.where(within_tolerance)[0]  # Get indices of red points\n",
    "            # ax1 plots whole design space including inadmissible design space in blue and admissible in red\n",
    "            ax1.scatter(subset[:, 1], subset[:, 2], z_values, label=f\"Set {int(i)}\", color=colors, alpha=0.1, s=5)\n",
    "            # ax2 plots only the admissible design space linked by defined moment capacity in red\n",
    "            ax2.scatter(subset[red_indices, 1], subset[red_indices, 2], z_values[red_indices], label=f\"Set {int(i)}\", color='red', alpha=0.1, s=1)\n",
    "        # index += 1\n",
    "        # if index == 50:\n",
    "        #     break\n",
    "target_z_values = [0.1, 0.25, 0.5, 0.8]\n",
    "tolerance = 0.01\n",
    "plot_step_for_reinforcement_ratio = 1\n",
    "\n",
    "\n",
    "plot_points_within_tolerance(Design_space_normalized_min_max, moment_capacity_normalized_min_max, target_z_values, tolerance, plot_step_for_reinforcement_ratio, ax1, ax2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "X = Design_space_normalized_min_max\n",
    "y = moment_capacity_normalized_min_max\n",
    "\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the neural network model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X.shape[1],)),\n",
    "    Dense(64, activation='relu'),  # First hidden layer\n",
    "    Dense(64, activation='relu'),  # Second hidden layer\n",
    "    Dense(1)  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, validation_split=0.2)\n",
    "\n",
    "model.save('NN2.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('NN2.h5')\n",
    "\n",
    "# Desired moment capacity value and tolerance\n",
    "desired_moment_capacity = 0.5\n",
    "tolerance = 0.01\n",
    "\n",
    "# Initial guess for inputs\n",
    "initial_inputs = tf.Variable(np.random.uniform(low=X.min(axis=0), high=X.max(axis=0), size=(1, X.shape[1])), dtype=tf.float32)\n",
    "\n",
    "# Loss function: difference between the predicted and desired output\n",
    "def loss_function():\n",
    "    predicted_output = model(initial_inputs)\n",
    "    return tf.reduce_mean(tf.square(predicted_output - desired_moment_capacity))\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# Training loop for optimization\n",
    "for step in range(1000):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = loss_function()\n",
    "    grads = tape.gradient(loss, [initial_inputs])\n",
    "    optimizer.apply_gradients(zip(grads, [initial_inputs]))\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        current_loss = loss.numpy()\n",
    "        print(f'Step {step}: Loss = {current_loss}')\n",
    "        if current_loss < tolerance:\n",
    "            break\n",
    "\n",
    "# Admissible inputs\n",
    "admissible_inputs = initial_inputs.numpy()\n",
    "print(f'Admissible inputs: {admissible_inputs}')\n",
    "\n",
    "# Validate admissible inputs by predicting moment capacities\n",
    "validated_output = model.predict(admissible_inputs)\n",
    "print(f'Predicted moment capacity: {validated_output[0][0]}')\n",
    "\n",
    "# Visualize the admissible inputs\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(admissible_inputs[:, 0], admissible_inputs[:, 1], admissible_inputs[:, 2])\n",
    "ax.set_xlabel('Input 1')\n",
    "ax.set_ylabel('Input 2')\n",
    "ax.set_zlabel('Input 3')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
