{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_eps_v_predictor import *\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\10C_0.1A\\Pi_data_10C_0.1A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\10C_0.2A\\Pi_data_10C_0.2A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\10C_0.3A\\Pi_data_10C_0.3A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\10C_0.4A\\Pi_data_10C_0.4A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\10C_0.5A\\Pi_data_10C_0.5A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\10C_0.6A\\Pi_data_10C_0.6A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\10C_0.7A\\Pi_data_10C_0.7A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\10C_0.8A\\Pi_data_10C_0.8A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\10C_0.9A\\Pi_data_10C_0.9A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\10C_1.0A\\Pi_data_10C_1.0A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\10C_1.1A\\Pi_data_10C_1.1A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\10C_1.2A\\Pi_data_10C_1.2A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\10C_1.3A\\Pi_data_10C_1.3A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\10C_1.4A\\Pi_data_10C_1.4A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\10C_1.5A\\Pi_data_10C_1.5A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\10C_1.6A\\Pi_data_10C_1.6A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\10C_1.7A\\Pi_data_10C_1.7A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\10C_1.8A\\Pi_data_10C_1.8A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\10C_1.9A\\Pi_data_10C_1.9A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\10C_2.0A\\Pi_data_10C_2.0A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\1C_0.1A\\Pi_data_1C_0.1A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\1C_0.2A\\Pi_data_1C_0.2A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\1C_0.3A\\Pi_data_1C_0.3A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\1C_0.4A\\Pi_data_1C_0.4A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\1C_0.5A\\Pi_data_1C_0.5A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\1C_0.6A\\Pi_data_1C_0.6A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\1C_0.7A\\Pi_data_1C_0.7A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\1C_0.8A\\Pi_data_1C_0.8A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\1C_0.9A\\Pi_data_1C_0.9A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\1C_1.0A\\Pi_data_1C_1.0A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\1C_1.1A\\Pi_data_1C_1.1A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\1C_1.2A\\Pi_data_1C_1.2A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\1C_1.3A\\Pi_data_1C_1.3A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\1C_1.4A\\Pi_data_1C_1.4A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\1C_1.5A\\Pi_data_1C_1.5A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\1C_1.6A\\Pi_data_1C_1.6A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\1C_1.7A\\Pi_data_1C_1.7A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\1C_1.8A\\Pi_data_1C_1.8A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\1C_1.9A\\Pi_data_1C_1.9A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\1C_2.0A\\Pi_data_1C_2.0A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\2C_0.1A\\Pi_data_2C_0.1A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\2C_0.2A\\Pi_data_2C_0.2A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\2C_0.3A\\Pi_data_2C_0.3A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\2C_0.4A\\Pi_data_2C_0.4A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\2C_0.5A\\Pi_data_2C_0.5A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\2C_0.6A\\Pi_data_2C_0.6A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\2C_0.7A\\Pi_data_2C_0.7A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\2C_0.8A\\Pi_data_2C_0.8A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\2C_0.9A\\Pi_data_2C_0.9A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\2C_1.0A\\Pi_data_2C_1.0A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\2C_1.1A\\Pi_data_2C_1.1A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\2C_1.2A\\Pi_data_2C_1.2A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\2C_1.3A\\Pi_data_2C_1.3A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\2C_1.4A\\Pi_data_2C_1.4A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\2C_1.5A\\Pi_data_2C_1.5A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\2C_1.6A\\Pi_data_2C_1.6A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\2C_1.7A\\Pi_data_2C_1.7A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\2C_1.8A\\Pi_data_2C_1.8A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\2C_1.9A\\Pi_data_2C_1.9A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\2C_2.0A\\Pi_data_2C_2.0A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\3C_0.1A\\Pi_data_3C_0.1A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\3C_0.2A\\Pi_data_3C_0.2A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\3C_0.3A\\Pi_data_3C_0.3A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\3C_0.4A\\Pi_data_3C_0.4A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\3C_0.5A\\Pi_data_3C_0.5A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\3C_0.6A\\Pi_data_3C_0.6A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\3C_0.7A\\Pi_data_3C_0.7A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\3C_0.8A\\Pi_data_3C_0.8A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\3C_0.9A\\Pi_data_3C_0.9A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\3C_1.0A\\Pi_data_3C_1.0A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\3C_1.1A\\Pi_data_3C_1.1A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\3C_1.2A\\Pi_data_3C_1.2A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\3C_1.3A\\Pi_data_3C_1.3A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\3C_1.4A\\Pi_data_3C_1.4A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\3C_1.5A\\Pi_data_3C_1.5A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\3C_1.6A\\Pi_data_3C_1.6A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\3C_1.7A\\Pi_data_3C_1.7A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\3C_1.8A\\Pi_data_3C_1.8A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\3C_1.9A\\Pi_data_3C_1.9A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\3C_2.0A\\Pi_data_3C_2.0A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\4C_0.1A\\Pi_data_4C_0.1A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\4C_0.2A\\Pi_data_4C_0.2A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\4C_0.3A\\Pi_data_4C_0.3A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\4C_0.4A\\Pi_data_4C_0.4A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\4C_0.5A\\Pi_data_4C_0.5A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\4C_0.6A\\Pi_data_4C_0.6A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\4C_0.7A\\Pi_data_4C_0.7A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\4C_0.8A\\Pi_data_4C_0.8A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\4C_0.9A\\Pi_data_4C_0.9A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\4C_1.0A\\Pi_data_4C_1.0A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\4C_1.1A\\Pi_data_4C_1.1A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\4C_1.2A\\Pi_data_4C_1.2A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\4C_1.3A\\Pi_data_4C_1.3A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\4C_1.4A\\Pi_data_4C_1.4A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\4C_1.5A\\Pi_data_4C_1.5A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\4C_1.6A\\Pi_data_4C_1.6A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\4C_1.7A\\Pi_data_4C_1.7A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\4C_1.8A\\Pi_data_4C_1.8A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\4C_1.9A\\Pi_data_4C_1.9A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\4C_2.0A\\Pi_data_4C_2.0A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\5C_0.1A\\Pi_data_5C_0.1A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\5C_0.2A\\Pi_data_5C_0.2A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\5C_0.3A\\Pi_data_5C_0.3A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\5C_0.4A\\Pi_data_5C_0.4A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\5C_0.5A\\Pi_data_5C_0.5A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\5C_0.6A\\Pi_data_5C_0.6A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\5C_0.7A\\Pi_data_5C_0.7A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\5C_0.8A\\Pi_data_5C_0.8A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\5C_0.9A\\Pi_data_5C_0.9A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\5C_1.0A\\Pi_data_5C_1.0A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\5C_1.1A\\Pi_data_5C_1.1A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\5C_1.2A\\Pi_data_5C_1.2A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\5C_1.3A\\Pi_data_5C_1.3A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\5C_1.4A\\Pi_data_5C_1.4A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\5C_1.5A\\Pi_data_5C_1.5A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\5C_1.6A\\Pi_data_5C_1.6A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\5C_1.7A\\Pi_data_5C_1.7A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\5C_1.8A\\Pi_data_5C_1.8A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\5C_1.9A\\Pi_data_5C_1.9A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\5C_2.0A\\Pi_data_5C_2.0A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\6C_0.1A\\Pi_data_6C_0.1A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\6C_0.2A\\Pi_data_6C_0.2A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\6C_0.3A\\Pi_data_6C_0.3A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\6C_0.4A\\Pi_data_6C_0.4A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\6C_0.5A\\Pi_data_6C_0.5A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\6C_0.6A\\Pi_data_6C_0.6A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\6C_0.7A\\Pi_data_6C_0.7A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\6C_0.8A\\Pi_data_6C_0.8A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\6C_0.9A\\Pi_data_6C_0.9A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\6C_1.0A\\Pi_data_6C_1.0A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\6C_1.1A\\Pi_data_6C_1.1A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\6C_1.2A\\Pi_data_6C_1.2A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\6C_1.3A\\Pi_data_6C_1.3A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\6C_1.4A\\Pi_data_6C_1.4A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\6C_1.5A\\Pi_data_6C_1.5A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\6C_1.6A\\Pi_data_6C_1.6A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\6C_1.7A\\Pi_data_6C_1.7A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\6C_1.8A\\Pi_data_6C_1.8A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\6C_1.9A\\Pi_data_6C_1.9A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\6C_2.0A\\Pi_data_6C_2.0A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\7C_0.1A\\Pi_data_7C_0.1A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\7C_0.2A\\Pi_data_7C_0.2A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\7C_0.3A\\Pi_data_7C_0.3A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\7C_0.4A\\Pi_data_7C_0.4A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\7C_0.5A\\Pi_data_7C_0.5A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\7C_0.6A\\Pi_data_7C_0.6A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\7C_0.7A\\Pi_data_7C_0.7A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\7C_0.8A\\Pi_data_7C_0.8A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\7C_0.9A\\Pi_data_7C_0.9A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\7C_1.0A\\Pi_data_7C_1.0A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\7C_1.1A\\Pi_data_7C_1.1A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\7C_1.2A\\Pi_data_7C_1.2A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\7C_1.3A\\Pi_data_7C_1.3A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\7C_1.4A\\Pi_data_7C_1.4A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\7C_1.5A\\Pi_data_7C_1.5A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\7C_1.6A\\Pi_data_7C_1.6A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\7C_1.7A\\Pi_data_7C_1.7A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\7C_1.8A\\Pi_data_7C_1.8A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\7C_1.9A\\Pi_data_7C_1.9A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\7C_2.0A\\Pi_data_7C_2.0A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\8C_0.1A\\Pi_data_8C_0.1A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\8C_0.2A\\Pi_data_8C_0.2A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\8C_0.3A\\Pi_data_8C_0.3A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\8C_0.4A\\Pi_data_8C_0.4A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\8C_0.5A\\Pi_data_8C_0.5A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\8C_0.6A\\Pi_data_8C_0.6A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\8C_0.7A\\Pi_data_8C_0.7A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\8C_0.8A\\Pi_data_8C_0.8A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\8C_0.9A\\Pi_data_8C_0.9A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\8C_1.0A\\Pi_data_8C_1.0A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\8C_1.1A\\Pi_data_8C_1.1A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\8C_1.2A\\Pi_data_8C_1.2A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\8C_1.3A\\Pi_data_8C_1.3A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\8C_1.4A\\Pi_data_8C_1.4A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\8C_1.5A\\Pi_data_8C_1.5A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\8C_1.6A\\Pi_data_8C_1.6A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\8C_1.7A\\Pi_data_8C_1.7A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\8C_1.8A\\Pi_data_8C_1.8A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\8C_1.9A\\Pi_data_8C_1.9A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\8C_2.0A\\Pi_data_8C_2.0A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\9C_0.1A\\Pi_data_9C_0.1A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\9C_0.2A\\Pi_data_9C_0.2A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\9C_0.3A\\Pi_data_9C_0.3A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\9C_0.4A\\Pi_data_9C_0.4A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\9C_0.5A\\Pi_data_9C_0.5A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\9C_0.6A\\Pi_data_9C_0.6A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\9C_0.7A\\Pi_data_9C_0.7A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\9C_0.8A\\Pi_data_9C_0.8A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\9C_0.9A\\Pi_data_9C_0.9A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\9C_1.0A\\Pi_data_9C_1.0A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\9C_1.1A\\Pi_data_9C_1.1A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\9C_1.2A\\Pi_data_9C_1.2A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\9C_1.3A\\Pi_data_9C_1.3A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\9C_1.4A\\Pi_data_9C_1.4A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\9C_1.5A\\Pi_data_9C_1.5A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\9C_1.6A\\Pi_data_9C_1.6A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\9C_1.7A\\Pi_data_9C_1.7A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\9C_1.8A\\Pi_data_9C_1.8A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\9C_1.9A\\Pi_data_9C_1.9A.npy\n",
      "Loading data from: C:\\Users\\adelpasand\\bmcs_training_data\\9C_2.0A\\Pi_data_9C_2.0A.npy\n"
     ]
    }
   ],
   "source": [
    "# construc the dataset from the training data and normalize the data\n",
    "\n",
    "data_root_dir = Path(os.path.expanduser(\"~\")) / \"bmcs_training_data\"\n",
    "dataset = ViscoelasticDataset(data_root_dir, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset shapes: X_data = (400000, 4), y_data = (400000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print the dataset shape and the number of samples\n",
    "print(f\"Final dataset shapes: X_data = {dataset.X_data.shape}, y_data = {dataset.y_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 1, Loss: 0.004031035117805004\n",
      "Epoch 1, Batch 2, Loss: 0.17989638447761536\n",
      "Epoch 1, Batch 3, Loss: 3.5418637708062306e-05\n",
      "Epoch 1, Batch 4, Loss: 0.002816708292812109\n",
      "Epoch 1, Batch 5, Loss: 0.001263097976334393\n",
      "Epoch 1, Batch 6, Loss: 0.00030176949803717434\n",
      "Epoch 1, Batch 7, Loss: 0.0002658147714100778\n",
      "Epoch 1, Batch 8, Loss: 5.956393215456046e-05\n",
      "Epoch 1, Batch 9, Loss: 3.9818933146307245e-05\n",
      "Epoch 1, Batch 10, Loss: 0.00012240666546858847\n",
      "Epoch 1, Batch 11, Loss: 7.629496394656599e-07\n",
      "Epoch 1, Batch 12, Loss: 0.00011945332516916096\n",
      "Epoch 1, Batch 13, Loss: 1.4793315131100826e-05\n",
      "Epoch 1, Batch 14, Loss: 5.8718105719890445e-05\n",
      "Epoch 1, Batch 15, Loss: 4.332570097176358e-05\n",
      "Epoch 1, Batch 16, Loss: 4.619085302692838e-06\n",
      "Epoch 1, Batch 17, Loss: 1.601690200914163e-05\n",
      "Epoch 1, Batch 18, Loss: 5.0041826398228295e-06\n",
      "Epoch 1, Batch 19, Loss: 1.249160777661018e-05\n",
      "Epoch 1, Batch 20, Loss: 5.8253049246559385e-06\n",
      "Epoch 1, Batch 21, Loss: 3.817617198365042e-06\n",
      "Epoch 1, Batch 22, Loss: 8.918786079448182e-06\n",
      "Epoch 1, Batch 23, Loss: 1.5177383829723112e-06\n",
      "Epoch 1, Batch 24, Loss: 1.6286398022202775e-05\n",
      "Epoch 1, Batch 25, Loss: 1.2063064787071198e-06\n",
      "Epoch 1, Batch 26, Loss: 3.991087396570947e-06\n",
      "Epoch 1, Batch 27, Loss: 5.265532763587544e-06\n",
      "Epoch 1, Batch 28, Loss: 2.8804779503843747e-06\n",
      "Epoch 1, Batch 29, Loss: 8.335252459801268e-06\n",
      "Epoch 1, Batch 30, Loss: 7.31200771042495e-07\n",
      "Epoch 1, Batch 31, Loss: 5.830718691868242e-06\n",
      "Epoch 1, Batch 32, Loss: 1.5725071307315375e-06\n",
      "Epoch 1, Batch 33, Loss: 4.881905169895617e-06\n",
      "Epoch 1, Batch 34, Loss: 3.164390363963321e-06\n",
      "Epoch 1, Batch 35, Loss: 9.649388630350586e-07\n",
      "Epoch 1, Batch 36, Loss: 2.827962816809304e-06\n",
      "Epoch 1, Batch 37, Loss: 1.230447281841407e-07\n",
      "Epoch 1, Batch 38, Loss: 3.9212250158016104e-06\n",
      "Epoch 1, Batch 39, Loss: 3.92494143852673e-07\n",
      "Epoch 1, Batch 40, Loss: 8.458576985503896e-07\n",
      "Epoch 1, Batch 41, Loss: 9.987724070015247e-07\n",
      "Epoch 1, Batch 42, Loss: 1.8002698709551623e-07\n",
      "Epoch 1, Batch 43, Loss: 1.4577193496734253e-06\n",
      "Epoch 1, Batch 44, Loss: 5.961887268313149e-07\n",
      "Epoch 1, Batch 45, Loss: 2.733613655436784e-07\n",
      "Epoch 1, Batch 46, Loss: 1.026493237077375e-06\n",
      "Epoch 1, Batch 47, Loss: 8.678770200276631e-07\n",
      "Epoch 1, Batch 48, Loss: 1.269124823011225e-07\n",
      "Epoch 1, Batch 49, Loss: 1.569194125750073e-07\n",
      "Epoch 1, Batch 50, Loss: 4.6878705006747623e-07\n",
      "Epoch 1, Batch 51, Loss: 3.3577782687643776e-07\n",
      "Epoch 1, Batch 52, Loss: 3.226465139505308e-07\n",
      "Epoch 1, Batch 53, Loss: 2.72041631887987e-07\n",
      "Epoch 1, Batch 54, Loss: 1.8768844256555894e-07\n",
      "Epoch 1, Batch 55, Loss: 1.1281789369377293e-07\n",
      "Epoch 1, Batch 56, Loss: 3.6282742144067015e-08\n",
      "Epoch 1, Batch 57, Loss: 1.3661657760621893e-07\n",
      "Epoch 1, Batch 58, Loss: 2.69132328867272e-07\n",
      "Epoch 1, Batch 59, Loss: 2.5119277324847644e-07\n",
      "Epoch 1, Batch 60, Loss: 1.9116190230761276e-07\n",
      "Epoch 1, Batch 61, Loss: 1.861387914914303e-07\n",
      "Epoch 1, Batch 62, Loss: 2.9328422357366435e-08\n",
      "Epoch 1, Batch 63, Loss: 2.9868670026189648e-06\n",
      "Epoch 1, Batch 64, Loss: 1.1067881132476032e-05\n",
      "Epoch 1, Batch 65, Loss: 7.296987860172521e-06\n",
      "Epoch 1, Batch 66, Loss: 1.5134564819163643e-05\n",
      "Epoch 1, Batch 67, Loss: 7.413171988446265e-05\n",
      "Epoch 1, Batch 68, Loss: 0.00031125295208767056\n",
      "Epoch 1, Batch 69, Loss: 0.0004329250077717006\n",
      "Epoch 1, Batch 70, Loss: 6.92220710334368e-05\n",
      "Epoch 1, Batch 71, Loss: 0.0003404962772037834\n",
      "Epoch 1, Batch 72, Loss: 1.9835715647786856e-06\n",
      "Epoch 1, Batch 73, Loss: 0.00015839726256672293\n",
      "Epoch 1, Batch 74, Loss: 5.669214078807272e-05\n",
      "Epoch 1, Batch 75, Loss: 4.9548401875654235e-05\n",
      "Epoch 1, Batch 76, Loss: 0.0001444191875634715\n",
      "Epoch 1, Batch 77, Loss: 8.6968757386785e-06\n",
      "Epoch 1, Batch 78, Loss: 5.184019755688496e-05\n",
      "Epoch 1, Batch 79, Loss: 6.330524774966761e-05\n",
      "Epoch 1, Batch 80, Loss: 2.155257590175097e-07\n",
      "Epoch 1, Batch 81, Loss: 3.140839180559851e-05\n",
      "Epoch 1, Batch 82, Loss: 5.005939328839304e-06\n",
      "Epoch 1, Batch 83, Loss: 2.5234772692783736e-05\n",
      "Epoch 1, Batch 84, Loss: 4.290542710805312e-05\n",
      "Epoch 1, Batch 85, Loss: 1.9707395040313713e-06\n",
      "Epoch 1, Batch 86, Loss: 2.7185433282284066e-05\n",
      "Epoch 1, Batch 87, Loss: 3.3681888453429565e-05\n",
      "Epoch 1, Batch 88, Loss: 1.5803659607627196e-06\n",
      "Epoch 1, Batch 89, Loss: 5.7465722420602106e-06\n",
      "Epoch 1, Batch 90, Loss: 2.1229741378192557e-06\n",
      "Epoch 1, Batch 91, Loss: 7.06739865563577e-06\n",
      "Epoch 1, Batch 92, Loss: 3.3785252071538707e-06\n",
      "Epoch 1, Batch 93, Loss: 5.449619493447244e-06\n",
      "Epoch 1, Batch 94, Loss: 2.348374437133316e-05\n",
      "Epoch 1, Batch 95, Loss: 1.327534846495837e-05\n",
      "Epoch 1, Batch 96, Loss: 1.5192624687188072e-06\n",
      "Epoch 1, Batch 97, Loss: 3.8791768020018935e-06\n",
      "Epoch 1, Batch 98, Loss: 3.996771283709677e-06\n",
      "Epoch 1, Batch 99, Loss: 6.920820396771887e-07\n",
      "Epoch 1, Batch 100, Loss: 1.258544202187295e-08\n",
      "Epoch 1, Batch 101, Loss: 2.4340470190509222e-06\n",
      "Epoch 1, Batch 102, Loss: 1.9173865439370275e-05\n",
      "Epoch 1, Batch 103, Loss: 2.743733421084471e-05\n",
      "Epoch 1, Batch 104, Loss: 2.025942649197532e-06\n",
      "Epoch 1, Batch 105, Loss: 2.8449891033233143e-05\n",
      "Epoch 1, Batch 106, Loss: 4.3263702536933124e-05\n",
      "Epoch 1, Batch 107, Loss: 7.761233973724302e-06\n",
      "Epoch 1, Batch 108, Loss: 2.9720824841206195e-06\n",
      "Epoch 1, Batch 109, Loss: 3.6263422771298792e-06\n",
      "Epoch 1, Batch 110, Loss: 4.301362878322834e-06\n",
      "Epoch 1, Batch 111, Loss: 5.201932708587265e-06\n",
      "Epoch 1, Batch 112, Loss: 4.616729825102084e-07\n",
      "Epoch 1, Batch 113, Loss: 1.7149099221569486e-05\n",
      "Epoch 1, Batch 114, Loss: 4.5496297389036044e-05\n",
      "Epoch 1, Batch 115, Loss: 5.064907600171864e-05\n",
      "Epoch 1, Batch 116, Loss: 8.709555004315916e-06\n",
      "Epoch 1, Batch 117, Loss: 2.7238607799517922e-05\n",
      "Epoch 1, Batch 118, Loss: 5.7449866289971396e-05\n",
      "Epoch 1, Batch 119, Loss: 1.771056849975139e-05\n",
      "Epoch 1, Batch 120, Loss: 1.570810127304867e-06\n",
      "Epoch 1, Batch 121, Loss: 4.4851858547190204e-06\n",
      "Epoch 1, Batch 122, Loss: 1.7210048099514097e-05\n",
      "Epoch 1, Batch 123, Loss: 2.592588498373516e-05\n",
      "Epoch 1, Batch 124, Loss: 8.718428034626413e-06\n",
      "Epoch 1, Batch 125, Loss: 1.4973174074839335e-05\n",
      "Epoch 1, Batch 126, Loss: 9.676275112724397e-06\n",
      "Epoch 1, Batch 127, Loss: 0.00010476922034285963\n",
      "Epoch 1, Batch 128, Loss: 0.00012741897080559283\n",
      "Epoch 1, Batch 129, Loss: 0.00025325940805487335\n",
      "Epoch 1, Batch 130, Loss: 0.0004192625929135829\n",
      "Epoch 1, Batch 131, Loss: 5.1024715503444895e-05\n",
      "Epoch 1, Batch 132, Loss: 0.00032438867492601275\n",
      "Epoch 1, Batch 133, Loss: 7.374404231086373e-05\n",
      "Epoch 1, Batch 134, Loss: 2.4964709155028686e-05\n",
      "Epoch 1, Batch 135, Loss: 3.706332790898159e-05\n",
      "Epoch 1, Batch 136, Loss: 3.848761843983084e-05\n",
      "Epoch 1, Batch 137, Loss: 0.00010631995974108577\n",
      "Epoch 1, Batch 138, Loss: 8.824202814139426e-05\n",
      "Epoch 1, Batch 139, Loss: 5.837579010403715e-06\n",
      "Epoch 1, Batch 140, Loss: 0.0005704376962967217\n",
      "Epoch 1, Batch 141, Loss: 0.000746508885640651\n",
      "Epoch 1, Batch 142, Loss: 0.00015968903608154505\n",
      "Epoch 1, Batch 143, Loss: 0.00017237065185327083\n",
      "Epoch 1, Batch 144, Loss: 0.0006872334633953869\n",
      "Epoch 1, Batch 145, Loss: 0.0006568111130036414\n",
      "Epoch 1, Batch 146, Loss: 0.0002779866335913539\n",
      "Epoch 1, Batch 147, Loss: 0.00010337168350815773\n",
      "Epoch 1, Batch 148, Loss: 0.00014161106082610786\n",
      "Epoch 1, Batch 149, Loss: 0.00014889350859448314\n",
      "Epoch 1, Batch 150, Loss: 0.0009004524326883256\n",
      "Epoch 1, Batch 151, Loss: 0.00040025499765761197\n",
      "Epoch 1, Batch 152, Loss: 0.00040535119478590786\n",
      "Epoch 1, Batch 153, Loss: 0.0003786675806622952\n",
      "Epoch 1, Batch 154, Loss: 0.007420790381729603\n",
      "Epoch 1, Batch 155, Loss: 0.004453916102647781\n",
      "Epoch 1, Batch 156, Loss: 0.0001394703722326085\n",
      "Epoch 1, Batch 157, Loss: 0.0034181196242570877\n",
      "Epoch 1, Batch 158, Loss: 0.004997840151190758\n",
      "Epoch 1, Batch 159, Loss: 0.004997174255549908\n",
      "Epoch 1, Batch 160, Loss: 0.005575781222432852\n",
      "Epoch 1, Batch 161, Loss: 0.006064319983124733\n",
      "Epoch 1, Batch 162, Loss: 0.004423895850777626\n",
      "Epoch 1, Batch 163, Loss: 0.0027511355001479387\n",
      "Epoch 1, Batch 164, Loss: 0.0013816911960020661\n",
      "Epoch 1, Batch 165, Loss: 0.00033243518555536866\n",
      "Epoch 1, Batch 166, Loss: 2.6963673008140177e-05\n",
      "Epoch 1, Batch 167, Loss: 0.0006436863914132118\n",
      "Epoch 1, Batch 168, Loss: 0.0011739770416170359\n",
      "Epoch 1, Batch 169, Loss: 0.002661613281816244\n",
      "Epoch 1, Batch 170, Loss: 0.003256023395806551\n",
      "Epoch 1, Batch 171, Loss: 0.0018546157516539097\n",
      "Epoch 1, Batch 172, Loss: 0.00033774320036172867\n",
      "Epoch 1, Batch 173, Loss: 1.127649284171639e-06\n",
      "Epoch 1, Batch 174, Loss: 8.10002165962942e-05\n",
      "Epoch 1, Batch 175, Loss: 0.00021412144997157156\n",
      "Epoch 1, Batch 176, Loss: 0.00032284000189974904\n",
      "Epoch 1, Batch 177, Loss: 0.00037550326669588685\n",
      "Epoch 1, Batch 178, Loss: 0.0003846556937787682\n",
      "Epoch 1, Batch 179, Loss: 0.0003506215289235115\n",
      "Epoch 1, Batch 180, Loss: 0.00028832763200625777\n",
      "Epoch 1, Batch 181, Loss: 0.00021785781427752227\n",
      "Epoch 1, Batch 182, Loss: 0.0001475874742027372\n",
      "Epoch 1, Batch 183, Loss: 0.00010336730338167399\n",
      "Epoch 1, Batch 184, Loss: 7.617467053933069e-05\n",
      "Epoch 1, Batch 185, Loss: 1.9727222024812363e-05\n",
      "Epoch 1, Batch 186, Loss: 1.507996501004527e-07\n",
      "Epoch 1, Batch 187, Loss: 4.839293978875503e-06\n",
      "Epoch 1, Batch 188, Loss: 1.839656033553183e-05\n",
      "Epoch 1, Batch 189, Loss: 3.4693253837758675e-05\n",
      "Epoch 1, Batch 190, Loss: 2.5413761250092648e-05\n",
      "Epoch 1, Batch 191, Loss: 0.000924493360798806\n",
      "Epoch 1, Batch 192, Loss: 7.445326627930626e-05\n",
      "Epoch 1, Batch 193, Loss: 0.00012276280904188752\n",
      "Epoch 1, Batch 194, Loss: 0.00014141041901893914\n",
      "Epoch 1, Batch 195, Loss: 0.00014789406850468367\n",
      "Epoch 1, Batch 196, Loss: 0.0001287140476051718\n",
      "Epoch 1, Batch 197, Loss: 0.00010479271440999582\n",
      "Epoch 1, Batch 198, Loss: 8.974863158073276e-05\n",
      "Epoch 1, Batch 199, Loss: 6.727854633936659e-05\n",
      "Epoch 1, Batch 200, Loss: 2.5825833290582523e-05\n",
      "Epoch 1, Batch 201, Loss: 3.6131261822447414e-06\n",
      "Epoch 1, Batch 202, Loss: 2.0517832126643043e-06\n",
      "Epoch 1, Batch 203, Loss: 1.9801402686425718e-06\n",
      "Epoch 1, Batch 204, Loss: 1.7602542357053608e-06\n",
      "Epoch 1, Batch 205, Loss: 6.940829422319439e-08\n",
      "Epoch 1, Batch 206, Loss: 4.1131454509013565e-07\n",
      "Epoch 1, Batch 207, Loss: 1.806726140785031e-05\n",
      "Epoch 1, Batch 208, Loss: 0.00010131309682037681\n",
      "Epoch 1, Batch 209, Loss: 9.406748176843394e-06\n",
      "Epoch 1, Batch 210, Loss: 3.9746591937728226e-05\n",
      "Epoch 1, Batch 211, Loss: 1.7495443898951635e-05\n",
      "Epoch 1, Batch 212, Loss: 4.747058937937254e-06\n",
      "Epoch 1, Batch 213, Loss: 1.3479625522450078e-06\n",
      "Epoch 1, Batch 214, Loss: 1.2712350780930137e-06\n",
      "Epoch 1, Batch 215, Loss: 1.5606437955284491e-06\n",
      "Epoch 1, Batch 216, Loss: 9.62451281338872e-07\n",
      "Epoch 1, Batch 217, Loss: 3.754985016257706e-07\n",
      "Epoch 1, Batch 218, Loss: 2.321871406252285e-08\n",
      "Epoch 1, Batch 219, Loss: 1.3244971341919154e-07\n",
      "Epoch 1, Batch 220, Loss: 5.680071240021789e-07\n",
      "Epoch 1, Batch 221, Loss: 2.578093472038745e-06\n",
      "Epoch 1, Batch 222, Loss: 2.247860720672179e-06\n",
      "Epoch 1, Batch 223, Loss: 5.567148946283851e-06\n",
      "Epoch 1, Batch 224, Loss: 1.3801002751279157e-05\n",
      "Epoch 1, Batch 225, Loss: 7.166039267758606e-06\n",
      "Epoch 1, Batch 226, Loss: 4.045555215270724e-06\n",
      "Epoch 1, Batch 227, Loss: 1.327943664364284e-06\n",
      "Epoch 1, Batch 228, Loss: 8.854253330525808e-09\n",
      "Epoch 1, Batch 229, Loss: 3.746686161321122e-07\n",
      "Epoch 1, Batch 230, Loss: 1.3704137700187857e-06\n",
      "Epoch 1, Batch 231, Loss: 2.4718062832107535e-06\n",
      "Epoch 1, Batch 232, Loss: 3.041443051188253e-06\n",
      "Epoch 1, Batch 233, Loss: 5.567363587033469e-06\n",
      "Epoch 1, Batch 234, Loss: 1.048055764840683e-05\n",
      "Epoch 1, Batch 235, Loss: 6.669919912383193e-06\n",
      "Epoch 1, Batch 236, Loss: 5.00395856306568e-07\n",
      "Epoch 1, Batch 237, Loss: 5.644701417395481e-08\n",
      "Epoch 1, Batch 238, Loss: 4.786954832525225e-07\n",
      "Epoch 1, Batch 239, Loss: 9.839551466939156e-07\n",
      "Epoch 1, Batch 240, Loss: 1.2659120329772122e-06\n",
      "Epoch 1, Batch 241, Loss: 1.2307752967899432e-06\n",
      "Epoch 1, Batch 242, Loss: 9.767708206709358e-07\n",
      "Epoch 1, Batch 243, Loss: 6.662273790425388e-07\n",
      "Epoch 1, Batch 244, Loss: 4.148553216509754e-07\n",
      "Epoch 1, Batch 245, Loss: 2.4887521021810244e-07\n",
      "Epoch 1, Batch 246, Loss: 9.153006175210976e-08\n",
      "Epoch 1, Batch 247, Loss: 4.250783547377068e-08\n",
      "Epoch 1, Batch 248, Loss: 4.3262829763079935e-08\n",
      "Epoch 1, Batch 249, Loss: 3.02465750223746e-08\n",
      "Epoch 1, Batch 250, Loss: 2.7355870901857315e-09\n",
      "Epoch 1, Batch 251, Loss: 1.1089042573075858e-07\n",
      "Epoch 1, Batch 252, Loss: 2.776823180283827e-07\n",
      "Epoch 1, Batch 253, Loss: 4.5426426709127554e-07\n",
      "Epoch 1, Batch 254, Loss: 2.4969804712782206e-07\n",
      "Epoch 1, Batch 255, Loss: 3.7914711015218927e-07\n",
      "Epoch 1, Batch 256, Loss: 2.0534871225663665e-07\n",
      "Epoch 1, Batch 257, Loss: 1.611720961136598e-07\n",
      "Epoch 1, Batch 258, Loss: 1.1861579451988291e-07\n",
      "Epoch 1, Batch 259, Loss: 1.2398268154356629e-06\n",
      "Epoch 1, Batch 260, Loss: 7.85145317649949e-08\n",
      "Epoch 1, Batch 261, Loss: 5.348737772692402e-07\n",
      "Epoch 1, Batch 262, Loss: 3.7245277439978963e-07\n",
      "Epoch 1, Batch 263, Loss: 2.1292751739565574e-07\n",
      "Epoch 1, Batch 264, Loss: 3.2967243157600024e-08\n",
      "Epoch 1, Batch 265, Loss: 8.130601081290934e-09\n",
      "Epoch 1, Batch 266, Loss: 1.614079359057996e-08\n",
      "Epoch 1, Batch 267, Loss: 9.782788623624583e-08\n",
      "Epoch 1, Batch 268, Loss: 6.004081001265149e-07\n",
      "Epoch 1, Batch 269, Loss: 5.37817470558366e-07\n",
      "Epoch 1, Batch 270, Loss: 3.2277932859869907e-07\n",
      "Epoch 1, Batch 271, Loss: 4.0380902532888285e-07\n",
      "Epoch 1, Batch 272, Loss: 4.4465743087585e-08\n",
      "Epoch 1, Batch 273, Loss: 2.57857024621444e-08\n",
      "Epoch 1, Batch 274, Loss: 4.473276362659817e-07\n",
      "Epoch 1, Batch 275, Loss: 7.006777309470635e-07\n",
      "Epoch 1, Batch 276, Loss: 6.168702384456992e-07\n",
      "Epoch 1, Batch 277, Loss: 7.0397141449518585e-09\n",
      "Epoch 1, Batch 278, Loss: 8.319996140926378e-07\n",
      "Epoch 1, Batch 279, Loss: 2.9125762921466958e-06\n",
      "Epoch 1, Batch 280, Loss: 1.1485341246952885e-06\n",
      "Epoch 1, Batch 281, Loss: 6.198794721967715e-08\n",
      "Epoch 1, Batch 282, Loss: 1.6378074008116528e-07\n",
      "Epoch 1, Batch 283, Loss: 7.428652679664083e-07\n",
      "Epoch 1, Batch 284, Loss: 2.3458752718141795e-09\n",
      "Epoch 1, Batch 285, Loss: 1.807230660233472e-06\n",
      "Epoch 1, Batch 286, Loss: 1.3164913070795592e-07\n",
      "Epoch 1, Batch 287, Loss: 1.2459913989459892e-07\n",
      "Epoch 1, Batch 288, Loss: 4.750549749132915e-07\n",
      "Epoch 1, Batch 289, Loss: 6.867658157716505e-07\n",
      "Epoch 1, Batch 290, Loss: 6.957860023248941e-06\n",
      "Epoch 1, Batch 291, Loss: 3.138088118248561e-07\n",
      "Epoch 1, Batch 292, Loss: 2.631465179092629e-07\n",
      "Epoch 1, Batch 293, Loss: 1.4028270811650145e-07\n",
      "Epoch 1, Batch 294, Loss: 8.028525400050057e-08\n",
      "Epoch 1, Batch 295, Loss: 1.2563716289548665e-08\n",
      "Epoch 1, Batch 296, Loss: 9.752370999649429e-08\n",
      "Epoch 1, Batch 297, Loss: 1.2016943173875916e-07\n",
      "Epoch 1, Batch 298, Loss: 1.5188039981239854e-07\n",
      "Epoch 1, Batch 299, Loss: 8.984139867607155e-07\n",
      "Epoch 1, Batch 300, Loss: 1.1033698683604598e-06\n",
      "Epoch 1, Batch 301, Loss: 1.0081035952680395e-06\n",
      "Epoch 1, Batch 302, Loss: 6.764872182429826e-07\n",
      "Epoch 1, Batch 303, Loss: 2.97750688105225e-07\n",
      "Epoch 1, Batch 304, Loss: 5.352135090674892e-08\n",
      "Epoch 1, Batch 305, Loss: 5.5222750816597e-09\n",
      "Epoch 1, Batch 306, Loss: 8.209239155121395e-08\n",
      "Epoch 1, Batch 307, Loss: 1.5913342110707163e-07\n",
      "Epoch 1, Batch 308, Loss: 2.028149879151897e-07\n",
      "Epoch 1, Batch 309, Loss: 7.232445113913855e-07\n",
      "Epoch 1, Batch 310, Loss: 4.777147069034982e-07\n",
      "Epoch 1, Batch 311, Loss: 2.1836019215015767e-08\n",
      "Epoch 1, Batch 312, Loss: 5.274333503280104e-08\n",
      "Epoch 1, Batch 313, Loss: 4.195887726154979e-08\n",
      "Epoch 1, Batch 314, Loss: 1.045591613291208e-09\n",
      "Epoch 1, Batch 315, Loss: 1.8480102781381902e-08\n",
      "Epoch 1, Batch 316, Loss: 7.848682059830026e-08\n",
      "Epoch 1, Batch 317, Loss: 1.6866140128968254e-07\n",
      "Epoch 1, Batch 318, Loss: 2.2535125765443809e-07\n",
      "Epoch 1, Batch 319, Loss: 1.7102878757668805e-07\n",
      "Epoch 1, Batch 320, Loss: 7.371265553501871e-08\n",
      "Epoch 1, Batch 321, Loss: 5.53883161558133e-09\n",
      "Epoch 1, Batch 322, Loss: 1.0049209322460229e-06\n",
      "Epoch 1, Batch 323, Loss: 2.126224707410529e-08\n",
      "Epoch 1, Batch 324, Loss: 2.476908775861375e-07\n",
      "Epoch 1, Batch 325, Loss: 9.41563271794621e-09\n",
      "Epoch 1, Batch 326, Loss: 4.5361410627720034e-08\n",
      "Epoch 1, Batch 327, Loss: 7.159498238706874e-08\n",
      "Epoch 1, Batch 328, Loss: 3.0766873493348612e-09\n",
      "Epoch 1, Batch 329, Loss: 2.5464257191742945e-07\n",
      "Epoch 1, Batch 330, Loss: 2.9810312440758935e-08\n",
      "Epoch 1, Batch 331, Loss: 1.012242705655808e-06\n",
      "Epoch 1, Batch 332, Loss: 1.227351886790018e-09\n",
      "Epoch 1, Batch 333, Loss: 7.147760783254853e-08\n",
      "Epoch 1, Batch 334, Loss: 7.392541192530189e-07\n",
      "Epoch 1, Batch 335, Loss: 5.219865073513574e-08\n",
      "Epoch 1, Batch 336, Loss: 4.449380810456205e-07\n",
      "Epoch 1, Batch 337, Loss: 6.199362019287946e-07\n",
      "Epoch 1, Batch 338, Loss: 5.819896955472359e-07\n",
      "Epoch 1, Batch 339, Loss: 4.341510475569521e-07\n",
      "Epoch 1, Batch 340, Loss: 2.0145790813330677e-07\n",
      "Epoch 1, Batch 341, Loss: 2.1632224900258734e-08\n",
      "Epoch 1, Batch 342, Loss: 2.968400281133654e-08\n",
      "Epoch 1, Batch 343, Loss: 1.6096225863293512e-07\n",
      "Epoch 1, Batch 344, Loss: 2.712978073304839e-07\n",
      "Epoch 1, Batch 345, Loss: 2.610841534078645e-07\n",
      "Epoch 1, Batch 346, Loss: 1.4766615663575067e-07\n",
      "Epoch 1, Batch 347, Loss: 1.717654640742694e-06\n",
      "Epoch 1, Batch 348, Loss: 1.6386129573220387e-06\n",
      "Epoch 1, Batch 349, Loss: 6.206748366821557e-05\n",
      "Epoch 1, Batch 350, Loss: 7.70221618040523e-07\n",
      "Epoch 1, Batch 351, Loss: 1.448795501346467e-07\n",
      "Epoch 1, Batch 352, Loss: 2.749869736362598e-07\n",
      "Epoch 1, Batch 353, Loss: 1.2130968798373942e-06\n",
      "Epoch 1, Batch 354, Loss: 1.0373011036790558e-06\n",
      "Epoch 1, Batch 355, Loss: 8.595006306677533e-07\n",
      "Epoch 1, Batch 356, Loss: 7.392089287350245e-07\n",
      "Epoch 1, Batch 357, Loss: 5.465386152536666e-07\n",
      "Epoch 1, Batch 358, Loss: 4.1309328935312806e-07\n",
      "Epoch 1, Batch 359, Loss: 4.273531430953881e-07\n",
      "Epoch 1, Batch 360, Loss: 4.429236923897406e-07\n",
      "Epoch 1, Batch 361, Loss: 5.479609654912565e-08\n",
      "Epoch 1, Batch 362, Loss: 1.6310877981595695e-08\n",
      "Epoch 1, Batch 363, Loss: 2.185668535048535e-08\n",
      "Epoch 1, Batch 364, Loss: 3.420813499133146e-08\n",
      "Epoch 1, Batch 365, Loss: 1.0645588410795881e-08\n",
      "Epoch 1, Batch 366, Loss: 1.7221448445070564e-07\n",
      "Epoch 1, Batch 367, Loss: 4.783357212545525e-07\n",
      "Epoch 1, Batch 368, Loss: 7.547794780293771e-07\n",
      "Epoch 1, Batch 369, Loss: 8.223056511269533e-07\n",
      "Epoch 1, Batch 370, Loss: 6.331754889288277e-07\n",
      "Epoch 1, Batch 371, Loss: 3.1149502888183633e-07\n",
      "Epoch 1, Batch 372, Loss: 6.042091627023183e-08\n",
      "Epoch 1, Batch 373, Loss: 4.990410928940037e-08\n",
      "Epoch 1, Batch 374, Loss: 3.7682175957343134e-07\n",
      "Epoch 1, Batch 375, Loss: 1.3662450726315e-07\n",
      "Epoch 1, Batch 376, Loss: 2.1627277746461004e-08\n",
      "Epoch 1, Batch 377, Loss: 4.44202932214921e-08\n",
      "Epoch 1, Batch 378, Loss: 7.733005347176913e-09\n",
      "Epoch 1, Batch 379, Loss: 1.5839797029570946e-08\n",
      "Epoch 1, Batch 380, Loss: 6.733013435678004e-08\n",
      "Epoch 1, Batch 381, Loss: 9.759264685271773e-08\n",
      "Epoch 1, Batch 382, Loss: 6.010304076653483e-08\n",
      "Epoch 1, Batch 383, Loss: 1.8027938608611294e-07\n",
      "Epoch 1, Batch 384, Loss: 2.8161128540205027e-08\n",
      "Epoch 1, Batch 385, Loss: 1.5838628542041988e-07\n",
      "Epoch 1, Batch 386, Loss: 2.2407370181554143e-08\n",
      "Epoch 1, Batch 387, Loss: 5.7209885717668385e-09\n",
      "Epoch 1, Batch 388, Loss: 8.561843145571402e-08\n",
      "Epoch 1, Batch 389, Loss: 4.2039522440973087e-07\n",
      "Epoch 1, Batch 390, Loss: 2.6310709699828294e-07\n",
      "Epoch 1, Batch 391, Loss: 5.2986671050803125e-08\n",
      "Epoch 1, Batch 392, Loss: 7.882178465479228e-09\n",
      "Epoch 1, Batch 393, Loss: 8.907471027441716e-08\n",
      "Epoch 1, Batch 394, Loss: 1.625238184033151e-07\n",
      "Epoch 1, Batch 395, Loss: 1.376544673803437e-07\n",
      "Epoch 1, Batch 396, Loss: 4.831516875469788e-08\n",
      "Epoch 1, Batch 397, Loss: 4.6883048554491324e-09\n",
      "Epoch 1, Batch 398, Loss: 3.110346469270553e-08\n",
      "Epoch 1, Batch 399, Loss: 1.3198243209444627e-07\n",
      "Epoch 1, Batch 400, Loss: 6.006056452179109e-08\n",
      "Epoch 1, Batch 401, Loss: 4.0146986179934174e-08\n",
      "Epoch 1, Batch 402, Loss: 2.438139858895738e-07\n",
      "Epoch 1, Batch 403, Loss: 1.249263874569806e-07\n",
      "Epoch 1, Batch 404, Loss: 1.5629099792136003e-08\n",
      "Epoch 1, Batch 405, Loss: 1.3020732936297463e-08\n",
      "Epoch 1, Batch 406, Loss: 5.522147006331579e-08\n",
      "Epoch 1, Batch 407, Loss: 5.8890343268558354e-08\n",
      "Epoch 1, Batch 408, Loss: 1.8097217946433375e-08\n",
      "Epoch 1, Batch 409, Loss: 9.684256063735575e-09\n",
      "Epoch 1, Batch 410, Loss: 9.795427047265548e-08\n",
      "Epoch 1, Batch 411, Loss: 2.1133741867629396e-08\n",
      "Epoch 1, Batch 412, Loss: 1.9739966106158136e-08\n",
      "Epoch 1, Batch 413, Loss: 1.051133224905243e-08\n",
      "Epoch 1, Batch 414, Loss: 2.240610363912765e-08\n",
      "Epoch 1, Batch 415, Loss: 1.786619492349928e-07\n",
      "Epoch 1, Batch 416, Loss: 5.8264589597456506e-08\n",
      "Epoch 1, Batch 417, Loss: 3.1919134002578176e-09\n",
      "Epoch 1, Batch 418, Loss: 4.259499064573902e-08\n",
      "Epoch 1, Batch 419, Loss: 8.005333995697583e-08\n",
      "Epoch 1, Batch 420, Loss: 5.493820154356399e-08\n",
      "Epoch 1, Batch 421, Loss: 7.635321708221454e-09\n",
      "Epoch 1, Batch 422, Loss: 2.9591555872343633e-08\n",
      "Epoch 1, Batch 423, Loss: 6.528500762215117e-08\n",
      "Epoch 1, Batch 424, Loss: 9.617250995574977e-09\n",
      "Epoch 1, Batch 425, Loss: 2.1452288834211686e-08\n",
      "Epoch 1, Batch 426, Loss: 1.2757953804509725e-08\n",
      "Epoch 1, Batch 427, Loss: 4.8051136403159944e-09\n",
      "Epoch 1, Batch 428, Loss: 8.618970781526514e-08\n",
      "Epoch 1, Batch 429, Loss: 1.1651748010876872e-08\n",
      "Epoch 1, Batch 430, Loss: 2.437311685810073e-08\n",
      "Epoch 1, Batch 431, Loss: 5.1307580406501074e-09\n",
      "Epoch 1, Batch 432, Loss: 6.650806483321503e-08\n",
      "Epoch 1, Batch 433, Loss: 4.797338970519149e-09\n",
      "Epoch 1, Batch 434, Loss: 1.8621307162902667e-08\n",
      "Epoch 1, Batch 435, Loss: 1.0707904607443197e-07\n",
      "Epoch 1, Batch 436, Loss: 1.2207683752762932e-08\n",
      "Epoch 1, Batch 437, Loss: 7.342411834088125e-08\n",
      "Epoch 1, Batch 438, Loss: 5.541829040112134e-08\n",
      "Epoch 1, Batch 439, Loss: 7.00370833328634e-07\n",
      "Epoch 1, Batch 440, Loss: 3.337993632612779e-07\n",
      "Epoch 1, Batch 441, Loss: 3.864094466621282e-08\n",
      "Epoch 1, Batch 442, Loss: 9.22998566466049e-09\n",
      "Epoch 1, Batch 443, Loss: 2.541961805491155e-07\n",
      "Epoch 1, Batch 444, Loss: 3.2752873835306673e-07\n",
      "Epoch 1, Batch 445, Loss: 2.2740631777651288e-07\n",
      "Epoch 1, Batch 446, Loss: 5.339059327980067e-08\n",
      "Epoch 1, Batch 447, Loss: 5.153185433925955e-09\n",
      "Epoch 1, Batch 448, Loss: 8.104125015506725e-08\n",
      "Epoch 1, Batch 449, Loss: 1.9493089098432392e-07\n",
      "Epoch 1, Batch 450, Loss: 3.635095140452904e-07\n",
      "Epoch 1, Batch 451, Loss: 2.711106219521753e-07\n",
      "Epoch 1, Batch 452, Loss: 5.1452357041625874e-08\n",
      "Epoch 1, Batch 453, Loss: 8.137097751159672e-08\n",
      "Epoch 1, Batch 454, Loss: 2.0732542793666653e-08\n",
      "Epoch 1, Batch 455, Loss: 2.193991477383861e-08\n",
      "Epoch 1, Batch 456, Loss: 9.293779612562503e-08\n",
      "Epoch 1, Batch 457, Loss: 1.0601882394212225e-07\n",
      "Epoch 1, Batch 458, Loss: 4.261381647552298e-08\n",
      "Epoch 1, Batch 459, Loss: 4.812114262620071e-09\n",
      "Epoch 1, Batch 460, Loss: 4.9602629559331035e-08\n",
      "Epoch 1, Batch 461, Loss: 6.289451626173559e-09\n",
      "Epoch 1, Batch 462, Loss: 1.704373708832918e-08\n",
      "Epoch 1, Batch 463, Loss: 2.3320698261386497e-08\n",
      "Epoch 1, Batch 464, Loss: 4.800959185757847e-09\n",
      "Epoch 1, Batch 465, Loss: 5.825672744208532e-08\n",
      "Epoch 1, Batch 466, Loss: 4.1359175639854584e-08\n",
      "Epoch 1, Batch 467, Loss: 1.1028030044712978e-08\n",
      "Epoch 1, Batch 468, Loss: 8.486439639909804e-08\n",
      "Epoch 1, Batch 469, Loss: 1.3247375818536966e-07\n",
      "Epoch 1, Batch 470, Loss: 8.44863663473916e-08\n",
      "Epoch 1, Batch 471, Loss: 2.7128795210273893e-08\n",
      "Epoch 1, Batch 472, Loss: 1.475465296607581e-07\n",
      "Epoch 1, Batch 473, Loss: 8.175736532223254e-09\n",
      "Epoch 1, Batch 474, Loss: 1.3428224754363782e-08\n",
      "Epoch 1, Batch 475, Loss: 6.651366390997282e-08\n",
      "Epoch 1, Batch 476, Loss: 6.872197388929635e-08\n",
      "Epoch 1, Batch 477, Loss: 5.9272089458772825e-08\n",
      "Epoch 1, Batch 478, Loss: 2.914079857418983e-07\n",
      "Epoch 1, Batch 479, Loss: 9.782866783325517e-08\n",
      "Epoch 1, Batch 480, Loss: 3.5063114633970827e-09\n",
      "Epoch 1, Batch 481, Loss: 2.465176152099957e-08\n",
      "Epoch 1, Batch 482, Loss: 4.239399942207456e-08\n",
      "Epoch 1, Batch 483, Loss: 1.551040185177044e-08\n",
      "Epoch 1, Batch 484, Loss: 1.136110849841998e-08\n",
      "Epoch 1, Batch 485, Loss: 7.101193943981343e-08\n",
      "Epoch 1, Batch 486, Loss: 3.154944749894639e-08\n",
      "Epoch 1, Batch 487, Loss: 1.779740976814992e-08\n",
      "Epoch 1, Batch 488, Loss: 2.4698076472873254e-08\n",
      "Epoch 1, Batch 489, Loss: 5.21988923196659e-08\n",
      "Epoch 1, Batch 490, Loss: 3.864268194320175e-08\n",
      "Epoch 1, Batch 491, Loss: 5.5681283583908225e-08\n",
      "Epoch 1, Batch 492, Loss: 3.988360308682104e-09\n",
      "Epoch 1, Batch 493, Loss: 2.8105949567702737e-08\n",
      "Epoch 1, Batch 494, Loss: 4.713034940095895e-08\n",
      "Epoch 1, Batch 495, Loss: 1.8717315697358572e-08\n",
      "Epoch 1, Batch 496, Loss: 8.518823868541858e-09\n",
      "Epoch 1, Batch 497, Loss: 1.1721729720193252e-07\n",
      "Epoch 1, Batch 498, Loss: 8.642034288186551e-08\n",
      "Epoch 1, Batch 499, Loss: 8.232375670047531e-09\n",
      "Epoch 1, Batch 500, Loss: 2.610487115362048e-08\n",
      "Epoch 1, Batch 501, Loss: 2.44492838419319e-07\n",
      "Epoch 1, Batch 502, Loss: 2.3673601390328258e-07\n",
      "Epoch 1, Batch 503, Loss: 8.521053018739622e-08\n",
      "Epoch 1, Batch 504, Loss: 3.265224179926918e-08\n",
      "Epoch 1, Batch 505, Loss: 1.1758227458358306e-07\n",
      "Epoch 1, Batch 506, Loss: 1.575053545366245e-07\n",
      "Epoch 1, Batch 507, Loss: 9.012030943722493e-08\n",
      "Epoch 1, Batch 508, Loss: 6.222252935117467e-09\n",
      "Epoch 1, Batch 509, Loss: 2.430472711978382e-08\n",
      "Epoch 1, Batch 510, Loss: 1.0323937971179475e-07\n",
      "Epoch 1, Batch 511, Loss: 1.5477120030027436e-07\n",
      "Epoch 1, Batch 512, Loss: 3.5234231177128095e-07\n",
      "Epoch 1, Batch 513, Loss: 4.1067943357120384e-07\n",
      "Epoch 1, Batch 514, Loss: 3.570400224361947e-07\n",
      "Epoch 1, Batch 515, Loss: 4.837597202822508e-07\n",
      "Epoch 1, Batch 516, Loss: 2.465338866386446e-07\n",
      "Epoch 1, Batch 517, Loss: 1.0969899655322024e-08\n",
      "Epoch 1, Batch 518, Loss: 6.59818368831111e-08\n",
      "Epoch 1, Batch 519, Loss: 1.8933194212422677e-07\n",
      "Epoch 1, Batch 520, Loss: 1.899852009046299e-07\n",
      "Epoch 1, Batch 521, Loss: 4.913785573990026e-07\n",
      "Epoch 1, Batch 522, Loss: 3.476553729342413e-07\n",
      "Epoch 1, Batch 523, Loss: 6.899081483879854e-08\n",
      "Epoch 1, Batch 524, Loss: 1.3689101407976523e-08\n",
      "Epoch 1, Batch 525, Loss: 9.110332044315328e-09\n",
      "Epoch 1, Batch 526, Loss: 1.5332471292595073e-08\n",
      "Epoch 1, Batch 527, Loss: 2.801258114359939e-09\n",
      "Epoch 1, Batch 528, Loss: 1.0868140520869929e-07\n",
      "Epoch 1, Batch 529, Loss: 1.265674427486374e-07\n",
      "Epoch 1, Batch 530, Loss: 1.3003721655024947e-08\n",
      "Epoch 1, Batch 531, Loss: 3.998401165716814e-09\n",
      "Epoch 1, Batch 532, Loss: 6.3197966859718235e-09\n",
      "Epoch 1, Batch 533, Loss: 5.419452886457066e-09\n",
      "Epoch 1, Batch 534, Loss: 5.106676326249726e-08\n",
      "Epoch 1, Batch 535, Loss: 3.929854486273143e-08\n",
      "Epoch 1, Batch 536, Loss: 1.977353614179833e-09\n",
      "Epoch 1, Batch 537, Loss: 1.6660649748700962e-08\n",
      "Epoch 1, Batch 538, Loss: 1.7166174259841682e-08\n",
      "Epoch 1, Batch 539, Loss: 6.7264029901537015e-09\n",
      "Epoch 1, Batch 540, Loss: 4.962041444400711e-08\n",
      "Epoch 1, Batch 541, Loss: 4.7649713508235436e-08\n",
      "Epoch 1, Batch 542, Loss: 4.971249634166952e-09\n",
      "Epoch 1, Batch 543, Loss: 5.3925603538118594e-08\n",
      "Epoch 1, Batch 544, Loss: 9.643007814474913e-08\n",
      "Epoch 1, Batch 545, Loss: 5.38507762826157e-08\n",
      "Epoch 1, Batch 546, Loss: 4.756008475936824e-09\n",
      "Epoch 1, Batch 547, Loss: 2.3385769765127407e-08\n",
      "Epoch 1, Batch 548, Loss: 1.3628755013428417e-08\n",
      "Epoch 1, Batch 549, Loss: 3.030744544219033e-09\n",
      "Epoch 1, Batch 550, Loss: 2.138041921284639e-08\n",
      "Epoch 1, Batch 551, Loss: 2.0792459309859623e-08\n",
      "Epoch 1, Batch 552, Loss: 5.058771623822622e-09\n",
      "Epoch 1, Batch 553, Loss: 5.1127351241575525e-08\n",
      "Epoch 1, Batch 554, Loss: 9.7825008538166e-08\n",
      "Epoch 1, Batch 555, Loss: 4.824256105706581e-09\n",
      "Epoch 1, Batch 556, Loss: 1.7576414990116973e-08\n",
      "Epoch 1, Batch 557, Loss: 2.36384884999552e-08\n",
      "Epoch 1, Batch 558, Loss: 3.598299214147005e-09\n",
      "Epoch 1, Batch 559, Loss: 1.3876840121440637e-08\n",
      "Epoch 1, Batch 560, Loss: 1.3839101420387578e-08\n",
      "Epoch 1, Batch 561, Loss: 1.0566010288926009e-08\n",
      "Epoch 1, Batch 562, Loss: 3.724798913751215e-09\n",
      "Epoch 1, Batch 563, Loss: 4.760163108130655e-08\n",
      "Epoch 1, Batch 564, Loss: 1.0252473714444932e-07\n",
      "Epoch 1, Batch 565, Loss: 4.160885396231606e-07\n",
      "Epoch 1, Batch 566, Loss: 1.6372571565170801e-07\n",
      "Epoch 1, Batch 567, Loss: 5.8853409257153544e-08\n",
      "Epoch 1, Batch 568, Loss: 1.2998307852285507e-07\n",
      "Epoch 1, Batch 569, Loss: 1.0062219502060543e-07\n",
      "Epoch 1, Batch 570, Loss: 1.550302819453009e-08\n",
      "Epoch 1, Batch 571, Loss: 2.4058978809193832e-08\n",
      "Epoch 1, Batch 572, Loss: 4.0183209648603224e-07\n",
      "Epoch 1, Batch 573, Loss: 2.667779313014762e-07\n",
      "Epoch 1, Batch 574, Loss: 1.5808078046575247e-07\n",
      "Epoch 1, Batch 575, Loss: 4.6605876491412346e-07\n",
      "Epoch 1, Batch 576, Loss: 6.810242894061957e-07\n",
      "Epoch 1, Batch 577, Loss: 1.2000002413969924e-07\n",
      "Epoch 1, Batch 578, Loss: 5.866041874469374e-08\n",
      "Epoch 1, Batch 579, Loss: 7.910156085699782e-08\n",
      "Epoch 1, Batch 580, Loss: 1.4394107239468212e-08\n",
      "Epoch 1, Batch 581, Loss: 1.20495073474558e-07\n",
      "Epoch 1, Batch 582, Loss: 1.649060692443527e-07\n",
      "Epoch 1, Batch 583, Loss: 7.974967530799404e-08\n",
      "Epoch 1, Batch 584, Loss: 7.85773579536908e-09\n",
      "Epoch 1, Batch 585, Loss: 5.783446255236413e-08\n",
      "Epoch 1, Batch 586, Loss: 2.033495007935926e-07\n",
      "Epoch 1, Batch 587, Loss: 8.365497450313342e-08\n",
      "Epoch 1, Batch 588, Loss: 2.3743926824693062e-09\n",
      "Epoch 1, Batch 589, Loss: 3.7157790178099503e-09\n",
      "Epoch 1, Batch 590, Loss: 1.1056826565436495e-07\n",
      "Epoch 1, Batch 591, Loss: 2.0950665202690288e-07\n",
      "Epoch 1, Batch 592, Loss: 2.417778333096976e-08\n",
      "Epoch 1, Batch 593, Loss: 1.4673402048970274e-08\n",
      "Epoch 1, Batch 594, Loss: 4.531945663188708e-08\n",
      "Epoch 1, Batch 595, Loss: 2.17228439680639e-08\n",
      "Epoch 1, Batch 596, Loss: 1.2478713173891265e-08\n",
      "Epoch 1, Batch 597, Loss: 1.5637164096915512e-07\n",
      "Epoch 1, Batch 598, Loss: 1.063169818849019e-07\n",
      "Epoch 1, Batch 599, Loss: 1.6600669283661773e-08\n",
      "Epoch 1, Batch 600, Loss: 8.88978934909801e-09\n",
      "Epoch 1, Batch 601, Loss: 7.404787893960929e-09\n",
      "Epoch 1, Batch 602, Loss: 5.1503916687067886e-09\n",
      "Epoch 1, Batch 603, Loss: 8.801346496056794e-08\n",
      "Epoch 1, Batch 604, Loss: 2.0705147818489422e-08\n",
      "Epoch 1, Batch 605, Loss: 4.295762323636154e-08\n",
      "Epoch 1, Batch 606, Loss: 1.4554947824763076e-07\n",
      "Epoch 1, Batch 607, Loss: 1.4687969951410196e-07\n",
      "Epoch 1, Batch 608, Loss: 4.482192039745314e-08\n",
      "Epoch 1, Batch 609, Loss: 1.91511375646769e-08\n",
      "Epoch 1, Batch 610, Loss: 1.3464531889439968e-07\n",
      "Epoch 1, Batch 611, Loss: 1.8756761477334294e-08\n",
      "Epoch 1, Batch 612, Loss: 4.031825096006969e-09\n",
      "Epoch 1, Batch 613, Loss: 3.4434208373568254e-08\n",
      "Epoch 1, Batch 614, Loss: 7.940057500377407e-09\n",
      "Epoch 1, Batch 615, Loss: 1.0064605149295858e-08\n",
      "Epoch 1, Batch 616, Loss: 1.4596800212984817e-07\n",
      "Epoch 1, Batch 617, Loss: 1.1197132110396524e-08\n",
      "Epoch 1, Batch 618, Loss: 3.7544872100170323e-08\n",
      "Epoch 1, Batch 619, Loss: 8.732476430850511e-08\n",
      "Epoch 1, Batch 620, Loss: 5.094972266306286e-08\n",
      "Epoch 1, Batch 621, Loss: 5.821413129325492e-09\n",
      "Epoch 1, Batch 622, Loss: 1.1392086918249333e-07\n",
      "Epoch 1, Batch 623, Loss: 5.70549971712353e-08\n",
      "Epoch 1, Batch 624, Loss: 1.4485731725244477e-08\n",
      "Epoch 1, Batch 625, Loss: 1.104055158407391e-08\n",
      "Epoch 1, Batch 626, Loss: 3.902602543348621e-07\n",
      "Epoch 1, Batch 627, Loss: 6.604016107303323e-07\n",
      "Epoch 1, Batch 628, Loss: 3.2015120154937904e-07\n",
      "Epoch 1, Batch 629, Loss: 2.0050013205263895e-08\n",
      "Epoch 1, Batch 630, Loss: 7.648165478713054e-08\n",
      "Epoch 1, Batch 631, Loss: 9.335266781818063e-08\n",
      "Epoch 1, Batch 632, Loss: 2.7976765792914193e-08\n",
      "Epoch 1, Batch 633, Loss: 2.4840002055270816e-08\n",
      "Epoch 1, Batch 634, Loss: 3.134500445867161e-07\n",
      "Epoch 1, Batch 635, Loss: 7.581803060929815e-07\n",
      "Epoch 1, Batch 636, Loss: 2.3219023148612905e-07\n",
      "Epoch 1, Batch 637, Loss: 3.546110178831441e-07\n",
      "Epoch 1, Batch 638, Loss: 5.186232101550559e-07\n",
      "Epoch 1, Batch 639, Loss: 2.4411841081928287e-07\n",
      "Epoch 1, Batch 640, Loss: 1.5590566704304365e-07\n",
      "Epoch 1, Batch 641, Loss: 1.1312693715126443e-07\n",
      "Epoch 1, Batch 642, Loss: 3.818182037207407e-08\n",
      "Epoch 1, Batch 643, Loss: 3.142675382150628e-07\n",
      "Epoch 1, Batch 644, Loss: 5.379145591177803e-07\n",
      "Epoch 1, Batch 645, Loss: 4.482908479985781e-07\n",
      "Epoch 1, Batch 646, Loss: 1.605580308705612e-07\n",
      "Epoch 1, Batch 647, Loss: 4.2786393095184394e-08\n",
      "Epoch 1, Batch 648, Loss: 2.6732061542134034e-07\n",
      "Epoch 1, Batch 649, Loss: 2.6487555260246154e-08\n",
      "Epoch 1, Batch 650, Loss: 1.3980987034756254e-08\n",
      "Epoch 1, Batch 651, Loss: 4.923043661619886e-08\n",
      "Epoch 1, Batch 652, Loss: 1.9436921405713292e-08\n",
      "Epoch 1, Batch 653, Loss: 2.734963686634728e-07\n",
      "Epoch 1, Batch 654, Loss: 2.0978865222787135e-07\n",
      "Epoch 1, Batch 655, Loss: 1.962186146897693e-08\n",
      "Epoch 1, Batch 656, Loss: 9.460725536314385e-09\n",
      "Epoch 1, Batch 657, Loss: 1.813872785305648e-08\n",
      "Epoch 1, Batch 658, Loss: 4.687859878060863e-09\n",
      "Epoch 1, Batch 659, Loss: 8.874412316117741e-08\n",
      "Epoch 1, Batch 660, Loss: 9.19677702881927e-08\n",
      "Epoch 1, Batch 661, Loss: 1.9050126809361245e-08\n",
      "Epoch 1, Batch 662, Loss: 8.158743014519132e-09\n",
      "Epoch 1, Batch 663, Loss: 3.246376722998434e-09\n",
      "Epoch 1, Batch 664, Loss: 4.408877707362535e-09\n",
      "Epoch 1, Batch 665, Loss: 8.332372658514942e-08\n",
      "Epoch 1, Batch 666, Loss: 8.150842489840215e-08\n",
      "Epoch 1, Batch 667, Loss: 8.804058815314875e-09\n",
      "Epoch 1, Batch 668, Loss: 5.173172468175835e-08\n",
      "Epoch 1, Batch 669, Loss: 9.928452016083611e-08\n",
      "Epoch 1, Batch 670, Loss: 4.667081654474714e-08\n",
      "Epoch 1, Batch 671, Loss: 1.0814968476324793e-08\n",
      "Epoch 1, Batch 672, Loss: 9.559833813455043e-08\n",
      "Epoch 1, Batch 673, Loss: 3.199865261649393e-08\n",
      "Epoch 1, Batch 674, Loss: 6.607433533645235e-08\n",
      "Epoch 1, Batch 675, Loss: 5.965794969142735e-08\n",
      "Epoch 1, Batch 676, Loss: 4.759949234767191e-08\n",
      "Epoch 1, Batch 677, Loss: 8.286605179819162e-09\n",
      "Epoch 1, Batch 678, Loss: 6.685593945121582e-08\n",
      "Epoch 1, Batch 679, Loss: 8.475699075916054e-08\n",
      "Epoch 1, Batch 680, Loss: 8.657747407880834e-09\n",
      "Epoch 1, Batch 681, Loss: 7.195357198952479e-08\n",
      "Epoch 1, Batch 682, Loss: 8.114844973761137e-08\n",
      "Epoch 1, Batch 683, Loss: 1.6314482209622838e-08\n",
      "Epoch 1, Batch 684, Loss: 5.031759187090756e-08\n",
      "Epoch 1, Batch 685, Loss: 9.858909066906563e-08\n",
      "Epoch 1, Batch 686, Loss: 3.856907682120436e-08\n",
      "Epoch 1, Batch 687, Loss: 2.890771177987972e-09\n",
      "Epoch 1, Batch 688, Loss: 1.333041836915072e-07\n",
      "Epoch 1, Batch 689, Loss: 2.3098778001440223e-07\n",
      "Epoch 1, Batch 690, Loss: 4.643826230221748e-07\n",
      "Epoch 1, Batch 691, Loss: 1.6509450517787627e-07\n",
      "Epoch 1, Batch 692, Loss: 1.8451007832709365e-08\n",
      "Epoch 1, Batch 693, Loss: 1.1835094682055569e-08\n",
      "Epoch 1, Batch 694, Loss: 8.212272746277449e-07\n",
      "Epoch 1, Batch 695, Loss: 1.5601113290131252e-08\n",
      "Epoch 1, Batch 696, Loss: 2.7037204475277576e-08\n",
      "Epoch 1, Batch 697, Loss: 4.5019490357844916e-08\n",
      "Epoch 1, Batch 698, Loss: 9.842735693155191e-08\n",
      "Epoch 1, Batch 699, Loss: 1.1209352557273178e-08\n",
      "Epoch 1, Batch 700, Loss: 7.425833246088587e-07\n",
      "Epoch 1, Batch 701, Loss: 7.579159522208556e-09\n",
      "Epoch 1, Batch 702, Loss: 2.0859398830452847e-07\n",
      "Epoch 1, Batch 703, Loss: 3.731002777840331e-07\n",
      "Epoch 1, Batch 704, Loss: 1.085629719455028e-07\n",
      "Epoch 1, Batch 705, Loss: 1.4278116466925894e-08\n",
      "Epoch 1, Batch 706, Loss: 1.923587511498681e-08\n",
      "Epoch 1, Batch 707, Loss: 1.4041631857253378e-07\n",
      "Epoch 1, Batch 708, Loss: 3.999618911620928e-07\n",
      "Epoch 1, Batch 709, Loss: 8.073051844803558e-07\n",
      "Epoch 1, Batch 710, Loss: 5.745401949752704e-07\n",
      "Epoch 1, Batch 711, Loss: 1.147053126260289e-06\n",
      "Epoch 1, Batch 712, Loss: 9.165518122244976e-07\n",
      "Epoch 1, Batch 713, Loss: 3.3358179507558816e-07\n",
      "Epoch 1, Batch 714, Loss: 6.459718981943752e-09\n",
      "Epoch 1, Batch 715, Loss: 2.956545017696044e-07\n",
      "Epoch 1, Batch 716, Loss: 1.6152945647718298e-07\n",
      "Epoch 1, Batch 717, Loss: 6.550726538989693e-07\n",
      "Epoch 1, Batch 718, Loss: 1.2478679991545505e-06\n",
      "Epoch 1, Batch 719, Loss: 1.3532342109101592e-06\n",
      "Epoch 1, Batch 720, Loss: 8.603839205534314e-07\n",
      "Epoch 1, Batch 721, Loss: 2.1547909057062498e-07\n",
      "Epoch 1, Batch 722, Loss: 2.640715024426754e-08\n",
      "Epoch 1, Batch 723, Loss: 1.9652119931379275e-08\n",
      "Epoch 1, Batch 724, Loss: 1.2575764873901107e-09\n",
      "Epoch 1, Batch 725, Loss: 1.8907206822404987e-07\n",
      "Epoch 1, Batch 726, Loss: 3.401570438654744e-07\n",
      "Epoch 1, Batch 727, Loss: 2.7850833816955856e-07\n",
      "Epoch 1, Batch 728, Loss: 8.457533340333612e-07\n",
      "Epoch 1, Batch 729, Loss: 5.906373417019495e-07\n",
      "Epoch 1, Batch 730, Loss: 1.0787655924104911e-07\n",
      "Epoch 1, Batch 731, Loss: 1.0538059314058046e-09\n",
      "Epoch 1, Batch 732, Loss: 2.1601087141220887e-08\n",
      "Epoch 1, Batch 733, Loss: 1.072203570373631e-08\n",
      "Epoch 1, Batch 734, Loss: 3.522110958442681e-08\n",
      "Epoch 1, Batch 735, Loss: 7.55355955561754e-08\n",
      "Epoch 1, Batch 736, Loss: 2.868605406547431e-07\n",
      "Epoch 1, Batch 737, Loss: 3.4780555324687157e-07\n",
      "Epoch 1, Batch 738, Loss: 1.3693781397705607e-07\n",
      "Epoch 1, Batch 739, Loss: 8.154299990792424e-08\n",
      "Epoch 1, Batch 740, Loss: 4.226215821745427e-07\n",
      "Epoch 1, Batch 741, Loss: 1.3729697911912808e-07\n",
      "Epoch 1, Batch 742, Loss: 2.4241595397711535e-08\n",
      "Epoch 1, Batch 743, Loss: 9.309582438277175e-09\n",
      "Epoch 1, Batch 744, Loss: 1.4712994378385247e-08\n",
      "Epoch 1, Batch 745, Loss: 3.20227266925599e-09\n",
      "Epoch 1, Batch 746, Loss: 1.1890460882568732e-07\n",
      "Epoch 1, Batch 747, Loss: 5.163534524399438e-07\n",
      "Epoch 1, Batch 748, Loss: 3.0192398980943835e-07\n",
      "Epoch 1, Batch 749, Loss: 1.934274429515881e-08\n",
      "Epoch 1, Batch 750, Loss: 2.447880262934632e-07\n",
      "Epoch 1, Batch 751, Loss: 9.674106848933661e-08\n",
      "Epoch 1, Batch 752, Loss: 4.0687226032787294e-08\n",
      "Epoch 1, Batch 753, Loss: 1.2194284408906242e-06\n",
      "Epoch 1, Batch 754, Loss: 5.162220872989565e-07\n",
      "Epoch 1, Batch 755, Loss: 7.725964223936899e-07\n",
      "Epoch 1, Batch 756, Loss: 8.867438054949162e-07\n",
      "Epoch 1, Batch 757, Loss: 5.519863179870299e-07\n",
      "Epoch 1, Batch 758, Loss: 9.652038102103688e-08\n",
      "Epoch 1, Batch 759, Loss: 3.855360120041951e-08\n",
      "Epoch 1, Batch 760, Loss: 1.4835582362593414e-07\n",
      "Epoch 1, Batch 761, Loss: 9.280267931899289e-08\n",
      "Epoch 1, Batch 762, Loss: 4.826754320674809e-07\n",
      "Epoch 1, Batch 763, Loss: 1.5134687600948382e-06\n",
      "Epoch 1, Batch 764, Loss: 1.4990561112426803e-06\n",
      "Epoch 1, Batch 765, Loss: 1.871631383210115e-07\n",
      "Epoch 1, Batch 766, Loss: 7.878032874941709e-07\n",
      "Epoch 1, Batch 767, Loss: 6.898994797666091e-07\n",
      "Epoch 1, Batch 768, Loss: 8.267194573363668e-08\n",
      "Epoch 1, Batch 769, Loss: 5.985057338619981e-09\n",
      "Epoch 1, Batch 770, Loss: 9.099539788337552e-09\n",
      "Epoch 1, Batch 771, Loss: 7.777282462484436e-08\n",
      "Epoch 1, Batch 772, Loss: 3.115400772912835e-07\n",
      "Epoch 1, Batch 773, Loss: 9.087528241025211e-08\n",
      "Epoch 1, Batch 774, Loss: 3.9128678963606944e-07\n",
      "Epoch 1, Batch 775, Loss: 7.416711156338351e-08\n",
      "Epoch 1, Batch 776, Loss: 4.893424687679726e-08\n",
      "Epoch 1, Batch 777, Loss: 1.3404812193584803e-07\n",
      "Epoch 1, Batch 778, Loss: 7.573060401000475e-08\n",
      "Epoch 1, Batch 779, Loss: 1.678351502221176e-08\n",
      "Epoch 1, Batch 780, Loss: 9.374966225550452e-08\n",
      "Epoch 1, Batch 781, Loss: 2.3799699988558132e-07\n",
      "Epoch 1, Batch 782, Loss: 1.9689981911596988e-07\n",
      "Epoch 1, Batch 783, Loss: 3.421943617354373e-08\n",
      "Epoch 1, Batch 784, Loss: 8.529175232752095e-08\n",
      "Epoch 1, Batch 785, Loss: 5.253822337181191e-07\n",
      "Epoch 1, Batch 786, Loss: 6.133159899945895e-07\n",
      "Epoch 1, Batch 787, Loss: 1.2092382348782849e-06\n",
      "Epoch 1, Batch 788, Loss: 1.0005604735852103e-06\n",
      "Epoch 1, Batch 789, Loss: 2.3695186257555179e-07\n",
      "Epoch 1, Batch 790, Loss: 5.026136591368413e-07\n",
      "Epoch 1, Batch 791, Loss: 8.231691595028678e-08\n",
      "Epoch 1, Batch 792, Loss: 6.116150643720175e-07\n",
      "Epoch 1, Batch 793, Loss: 1.2251480256963987e-06\n",
      "Epoch 1, Batch 794, Loss: 1.3382884844759246e-06\n",
      "Epoch 1, Batch 795, Loss: 9.979961532735615e-07\n",
      "Epoch 1, Batch 796, Loss: 1.7033710264513502e-07\n",
      "Epoch 1, Batch 797, Loss: 1.287016715423306e-07\n",
      "Epoch 1, Batch 798, Loss: 9.394547078045434e-07\n",
      "Epoch 1, Batch 799, Loss: 2.795740670080704e-07\n",
      "Epoch 1, Batch 800, Loss: 4.1442734755037236e-07\n",
      "Epoch 1, Batch 801, Loss: 2.0800512174901087e-06\n",
      "Epoch 1, Batch 802, Loss: 2.294016439918778e-06\n",
      "Epoch 1, Batch 803, Loss: 4.78621359434328e-07\n",
      "Epoch 1, Batch 804, Loss: 2.232300175819546e-06\n",
      "Epoch 1, Batch 805, Loss: 2.1324495946828392e-07\n",
      "Epoch 1, Batch 806, Loss: 2.819657538566389e-07\n",
      "Epoch 1, Batch 807, Loss: 2.0936612088462425e-07\n",
      "Epoch 1, Batch 808, Loss: 2.455600167650118e-07\n",
      "Epoch 1, Batch 809, Loss: 0.0001200724218506366\n",
      "Epoch 1, Batch 810, Loss: 1.0290845239069313e-05\n",
      "Epoch 1, Batch 811, Loss: 1.5087714928085916e-05\n",
      "Epoch 1, Batch 812, Loss: 9.751707693794742e-06\n",
      "Epoch 1, Batch 813, Loss: 6.901524102431722e-06\n",
      "Epoch 1, Batch 814, Loss: 5.049075298302341e-06\n",
      "Epoch 1, Batch 815, Loss: 2.518982228139066e-06\n",
      "Epoch 1, Batch 816, Loss: 3.3389715099474415e-06\n",
      "Epoch 1, Batch 817, Loss: 3.5574535104387905e-06\n",
      "Epoch 1, Batch 818, Loss: 2.493897909516818e-06\n",
      "Epoch 1, Batch 819, Loss: 9.193230994242185e-07\n",
      "Epoch 1, Batch 820, Loss: 1.0679660711332417e-08\n",
      "Epoch 1, Batch 821, Loss: 8.757390332903014e-07\n",
      "Epoch 1, Batch 822, Loss: 4.706864729087101e-06\n",
      "Epoch 1, Batch 823, Loss: 9.636514005251229e-05\n",
      "Epoch 1, Batch 824, Loss: 8.340952263097279e-06\n",
      "Epoch 1, Batch 825, Loss: 1.231498481502058e-05\n",
      "Epoch 1, Batch 826, Loss: 0.00017532953643240035\n",
      "Epoch 1, Batch 827, Loss: 0.00012140264880144969\n",
      "Epoch 1, Batch 828, Loss: 1.3728059457207564e-05\n",
      "Epoch 1, Batch 829, Loss: 9.344639124719833e-07\n",
      "Epoch 1, Batch 830, Loss: 2.7996027711196803e-05\n",
      "Epoch 1, Batch 831, Loss: 2.197520814206655e-07\n",
      "Epoch 1, Batch 832, Loss: 7.303726192731119e-07\n",
      "Epoch 1, Batch 833, Loss: 2.1765604287793394e-06\n",
      "Epoch 1, Batch 834, Loss: 5.982262337056454e-06\n",
      "Epoch 1, Batch 835, Loss: 5.0391331569699105e-06\n",
      "Epoch 1, Batch 836, Loss: 2.30261266551679e-05\n",
      "Epoch 1, Batch 837, Loss: 0.00013772725651506335\n",
      "Epoch 1, Batch 838, Loss: 7.068354079819983e-06\n",
      "Epoch 1, Batch 839, Loss: 2.1681145881302655e-05\n",
      "Epoch 1, Batch 840, Loss: 7.949161613396427e-07\n",
      "Epoch 1, Batch 841, Loss: 1.1049380645999918e-06\n",
      "Epoch 1, Batch 842, Loss: 2.350661361560924e-06\n",
      "Epoch 1, Batch 843, Loss: 6.004389433655888e-06\n",
      "Epoch 1, Batch 844, Loss: 6.118927558418363e-05\n",
      "Epoch 1, Batch 845, Loss: 0.0004805161734111607\n",
      "Epoch 1, Batch 846, Loss: 7.26970611140132e-05\n",
      "Epoch 1, Batch 847, Loss: 0.00032757275039330125\n",
      "Epoch 1, Batch 848, Loss: 0.0001452493161195889\n",
      "Epoch 1, Batch 849, Loss: 4.222412098897621e-05\n",
      "Epoch 1, Batch 850, Loss: 3.345816730870865e-05\n",
      "Epoch 1, Batch 851, Loss: 2.7441210477263667e-05\n",
      "Epoch 1, Batch 852, Loss: 1.4958929568820167e-05\n",
      "Epoch 1, Batch 853, Loss: 3.69231838703854e-06\n",
      "Epoch 1, Batch 854, Loss: 7.672220192489476e-08\n",
      "Epoch 1, Batch 855, Loss: 2.702553047129186e-06\n",
      "Epoch 1, Batch 856, Loss: 2.356505865463987e-05\n",
      "Epoch 1, Batch 857, Loss: 4.97999026265461e-05\n",
      "Epoch 1, Batch 858, Loss: 0.00013714772649109364\n",
      "Epoch 1, Batch 859, Loss: 3.426833063713275e-05\n",
      "Epoch 1, Batch 860, Loss: 8.511323358106893e-06\n",
      "Epoch 1, Batch 861, Loss: 1.036191861203406e-07\n",
      "Epoch 1, Batch 862, Loss: 3.0910632631275803e-06\n",
      "Epoch 1, Batch 863, Loss: 3.7506513308471767e-06\n",
      "Epoch 1, Batch 864, Loss: 8.551312930649146e-06\n",
      "Epoch 1, Batch 865, Loss: 4.254059149388922e-06\n",
      "Epoch 1, Batch 866, Loss: 1.3424931921690586e-06\n",
      "Epoch 1, Batch 867, Loss: 6.691983435302973e-05\n",
      "Epoch 1, Batch 868, Loss: 3.4993951203432516e-07\n",
      "Epoch 1, Batch 869, Loss: 9.424631571164355e-06\n",
      "Epoch 1, Batch 870, Loss: 5.998312531119154e-07\n",
      "Epoch 1, Batch 871, Loss: 7.922834583951044e-07\n",
      "Epoch 1, Batch 872, Loss: 4.430235094332602e-06\n",
      "Epoch 1, Batch 873, Loss: 7.274564723047661e-06\n",
      "Epoch 1, Batch 874, Loss: 4.429651198734064e-06\n",
      "Epoch 1, Batch 875, Loss: 2.168885885112104e-06\n",
      "Epoch 1, Batch 876, Loss: 3.0046385290916078e-06\n",
      "Epoch 1, Batch 877, Loss: 1.8060552520182682e-06\n",
      "Epoch 1, Batch 878, Loss: 1.1230102927584085e-06\n",
      "Epoch 1, Batch 879, Loss: 6.647691179750836e-07\n",
      "Epoch 1, Batch 880, Loss: 5.358521661946725e-07\n",
      "Epoch 1, Batch 881, Loss: 2.392087480984628e-06\n",
      "Epoch 1, Batch 882, Loss: 2.107269028783776e-05\n",
      "Epoch 1, Batch 883, Loss: 2.711157549128984e-06\n",
      "Epoch 1, Batch 884, Loss: 1.4604976286136662e-06\n",
      "Epoch 1, Batch 885, Loss: 2.271920038765529e-06\n",
      "Epoch 1, Batch 886, Loss: 3.221311317247455e-06\n",
      "Epoch 1, Batch 887, Loss: 3.005590315297013e-06\n",
      "Epoch 1, Batch 888, Loss: 1.8291354990651598e-06\n",
      "Epoch 1, Batch 889, Loss: 4.5884434030085686e-07\n",
      "Epoch 1, Batch 890, Loss: 5.3529340959812544e-08\n",
      "Epoch 1, Batch 891, Loss: 1.2550261772048543e-06\n",
      "Epoch 1, Batch 892, Loss: 3.551059762685327e-06\n",
      "Epoch 1, Batch 893, Loss: 5.474073077493813e-06\n",
      "Epoch 1, Batch 894, Loss: 5.233380306890467e-06\n",
      "Epoch 1, Batch 895, Loss: 4.1469243114988785e-06\n",
      "Epoch 1, Batch 896, Loss: 2.8881638627353823e-06\n",
      "Epoch 1, Batch 897, Loss: 3.3175638236571103e-06\n",
      "Epoch 1, Batch 898, Loss: 2.4901805772969965e-07\n",
      "Epoch 1, Batch 899, Loss: 2.65082258010807e-06\n",
      "Epoch 1, Batch 900, Loss: 4.738370989798568e-06\n",
      "Epoch 1, Batch 901, Loss: 5.197002337808954e-06\n",
      "Epoch 1, Batch 902, Loss: 3.834699327853741e-06\n",
      "Epoch 1, Batch 903, Loss: 1.752464299897838e-06\n",
      "Epoch 1, Batch 904, Loss: 3.0435279541052296e-07\n",
      "Epoch 1, Batch 905, Loss: 4.76341170951855e-08\n",
      "Epoch 1, Batch 906, Loss: 5.156057909516676e-07\n",
      "Epoch 1, Batch 907, Loss: 8.584549391343899e-07\n",
      "Epoch 1, Batch 908, Loss: 6.628617370552092e-07\n",
      "Epoch 1, Batch 909, Loss: 2.0781750720288983e-07\n",
      "Epoch 1, Batch 910, Loss: 2.2468821470056355e-08\n",
      "Epoch 1, Batch 911, Loss: 2.7324298912390077e-07\n",
      "Epoch 1, Batch 912, Loss: 6.107215426709445e-07\n",
      "Epoch 1, Batch 913, Loss: 5.965670766272524e-07\n",
      "Epoch 1, Batch 914, Loss: 2.3256689019035548e-07\n",
      "Epoch 1, Batch 915, Loss: 1.5667628971982595e-08\n",
      "Epoch 1, Batch 916, Loss: 4.320415882830275e-07\n",
      "Epoch 1, Batch 917, Loss: 1.3904249271945446e-06\n",
      "Epoch 1, Batch 918, Loss: 2.193273530792794e-06\n",
      "Epoch 1, Batch 919, Loss: 2.1394625946413726e-06\n",
      "Epoch 1, Batch 920, Loss: 1.220467879647913e-06\n",
      "Epoch 1, Batch 921, Loss: 2.296498564646754e-07\n",
      "Epoch 1, Batch 922, Loss: 1.1737410687828742e-07\n",
      "Epoch 1, Batch 923, Loss: 1.1347925692462013e-06\n",
      "Epoch 1, Batch 924, Loss: 2.548458041928825e-06\n",
      "Epoch 1, Batch 925, Loss: 3.2255161386274267e-06\n",
      "Epoch 1, Batch 926, Loss: 2.60345836977649e-06\n",
      "Epoch 1, Batch 927, Loss: 1.1887748314620694e-06\n",
      "Epoch 1, Batch 928, Loss: 1.299345910865668e-07\n",
      "Epoch 1, Batch 929, Loss: 2.3235904222929094e-07\n",
      "Epoch 1, Batch 930, Loss: 1.2829883644371876e-06\n",
      "Epoch 1, Batch 931, Loss: 2.274093958476442e-06\n",
      "Epoch 1, Batch 932, Loss: 2.3110983420338016e-06\n",
      "Epoch 1, Batch 933, Loss: 1.38547477490647e-06\n",
      "Epoch 1, Batch 934, Loss: 3.3291948398073146e-07\n",
      "Epoch 1, Batch 935, Loss: 4.36622400457054e-08\n",
      "Epoch 1, Batch 936, Loss: 6.621161787734309e-07\n",
      "Epoch 1, Batch 937, Loss: 1.5002098052718793e-06\n",
      "Epoch 1, Batch 938, Loss: 9.881297273750533e-07\n",
      "Epoch 1, Batch 939, Loss: 8.505569581984673e-08\n",
      "Epoch 1, Batch 940, Loss: 3.696804284913924e-08\n",
      "Epoch 1, Batch 941, Loss: 4.770997747982619e-07\n",
      "Epoch 1, Batch 942, Loss: 1.3019914604228688e-06\n",
      "Epoch 1, Batch 943, Loss: 1.8845294107450172e-06\n",
      "Epoch 1, Batch 944, Loss: 1.6536795328647713e-06\n",
      "Epoch 1, Batch 945, Loss: 7.47196281736251e-07\n",
      "Epoch 1, Batch 946, Loss: 4.457877977870339e-08\n",
      "Epoch 1, Batch 947, Loss: 4.417457262206881e-07\n",
      "Epoch 1, Batch 948, Loss: 1.9801641428784933e-06\n",
      "Epoch 1, Batch 949, Loss: 3.66115409633494e-06\n",
      "Epoch 1, Batch 950, Loss: 4.204842753097182e-06\n",
      "Epoch 1, Batch 951, Loss: 3.144280299238744e-06\n",
      "Epoch 1, Batch 952, Loss: 1.2859098887929576e-06\n",
      "Epoch 1, Batch 953, Loss: 8.503913306867616e-08\n",
      "Epoch 1, Batch 954, Loss: 4.4118536379755824e-07\n",
      "Epoch 1, Batch 955, Loss: 1.951085096152383e-06\n",
      "Epoch 1, Batch 956, Loss: 3.2722718970035203e-06\n",
      "Epoch 1, Batch 957, Loss: 3.2788680073281284e-06\n",
      "Epoch 1, Batch 958, Loss: 1.999156438614591e-06\n",
      "Epoch 1, Batch 959, Loss: 5.294642733133514e-07\n",
      "Epoch 1, Batch 960, Loss: 3.3625624951127975e-08\n",
      "Epoch 1, Batch 961, Loss: 7.385288540717738e-07\n",
      "Epoch 1, Batch 962, Loss: 1.80939832716831e-06\n",
      "Epoch 1, Batch 963, Loss: 2.1724777070630807e-06\n",
      "Epoch 1, Batch 964, Loss: 1.4999835684648133e-06\n",
      "Epoch 1, Batch 965, Loss: 4.574012564262375e-07\n",
      "Epoch 1, Batch 966, Loss: 2.2661955867420147e-08\n",
      "Epoch 1, Batch 967, Loss: 5.481229550241551e-07\n",
      "Epoch 1, Batch 968, Loss: 1.4513046835418209e-06\n",
      "Epoch 1, Batch 969, Loss: 1.8061904256683192e-06\n",
      "Epoch 1, Batch 970, Loss: 1.2528503248177003e-06\n",
      "Epoch 1, Batch 971, Loss: 3.5103172990602616e-07\n",
      "Epoch 1, Batch 972, Loss: 3.955191374416245e-08\n",
      "Epoch 1, Batch 973, Loss: 7.176644203354954e-07\n",
      "Epoch 1, Batch 974, Loss: 1.8299490420758957e-06\n",
      "Epoch 1, Batch 975, Loss: 2.365388354519382e-06\n",
      "Epoch 1, Batch 976, Loss: 1.8134697938876343e-06\n",
      "Epoch 1, Batch 977, Loss: 6.742814662175078e-07\n",
      "Epoch 1, Batch 978, Loss: 2.4258181241521015e-08\n",
      "Epoch 1, Batch 979, Loss: 5.228728241490899e-07\n",
      "Epoch 1, Batch 980, Loss: 1.7809800283430377e-06\n",
      "Epoch 1, Batch 981, Loss: 2.6909522148343967e-06\n",
      "Epoch 1, Batch 982, Loss: 2.4318221676367102e-06\n",
      "Epoch 1, Batch 983, Loss: 1.229815325132222e-06\n",
      "Epoch 1, Batch 984, Loss: 1.673805911650561e-07\n",
      "Epoch 1, Batch 985, Loss: 2.0405721556926437e-07\n",
      "Epoch 1, Batch 986, Loss: 1.3016315278946422e-06\n",
      "Epoch 1, Batch 987, Loss: 2.457747541484423e-06\n",
      "Epoch 1, Batch 988, Loss: 2.6206510028714547e-06\n",
      "Epoch 1, Batch 989, Loss: 1.6466904071421595e-06\n",
      "Epoch 1, Batch 990, Loss: 4.224543204145448e-07\n",
      "Epoch 1, Batch 991, Loss: 4.409218234968648e-08\n",
      "Epoch 1, Batch 992, Loss: 8.139552392094629e-07\n",
      "Epoch 1, Batch 993, Loss: 1.977477495529456e-06\n",
      "Epoch 1, Batch 994, Loss: 2.4347293674509274e-06\n",
      "Epoch 1, Batch 995, Loss: 1.761195449034858e-06\n",
      "Epoch 1, Batch 996, Loss: 5.92375613450713e-07\n",
      "Epoch 1, Batch 997, Loss: 2.1600643052011037e-08\n",
      "Epoch 1, Batch 998, Loss: 5.766256094830169e-07\n",
      "Epoch 1, Batch 999, Loss: 1.7292398979407153e-06\n",
      "Epoch 1, Batch 1000, Loss: 2.3932691419759067e-06\n",
      "Epoch 1, Batch 1001, Loss: 2.821973055233684e-07\n",
      "Epoch 1, Batch 1002, Loss: 2.4689217781315165e-08\n",
      "Epoch 1, Batch 1003, Loss: 2.4204527449001034e-07\n",
      "Epoch 1, Batch 1004, Loss: 1.1493193596834317e-06\n",
      "Epoch 1, Batch 1005, Loss: 2.1987805212120293e-06\n",
      "Epoch 1, Batch 1006, Loss: 2.484576953065698e-06\n",
      "Epoch 1, Batch 1007, Loss: 1.78086065716343e-06\n",
      "Epoch 1, Batch 1008, Loss: 4.4924337316842866e-07\n",
      "Epoch 1, Batch 1009, Loss: 6.255710616187571e-08\n",
      "Epoch 1, Batch 1010, Loss: 1.2177616781627876e-06\n",
      "Epoch 1, Batch 1011, Loss: 3.30447210217244e-06\n",
      "Epoch 1, Batch 1012, Loss: 4.789712875208352e-06\n",
      "Epoch 1, Batch 1013, Loss: 4.480141342355637e-06\n",
      "Epoch 1, Batch 1014, Loss: 2.5823410396697e-06\n",
      "Epoch 1, Batch 1015, Loss: 5.94938626363728e-07\n",
      "Epoch 1, Batch 1016, Loss: 7.60489911044715e-08\n",
      "Epoch 1, Batch 1017, Loss: 1.3371793556871125e-06\n",
      "Epoch 1, Batch 1018, Loss: 3.201424306098488e-06\n",
      "Epoch 1, Batch 1019, Loss: 4.035932306578616e-06\n",
      "Epoch 1, Batch 1020, Loss: 3.1493723327002954e-06\n",
      "Epoch 1, Batch 1021, Loss: 1.3347421372600365e-06\n",
      "Epoch 1, Batch 1022, Loss: 1.1008050648797507e-07\n",
      "Epoch 1, Batch 1023, Loss: 3.6671508496510796e-07\n",
      "Epoch 1, Batch 1024, Loss: 1.637688683331362e-06\n",
      "Epoch 1, Batch 1025, Loss: 2.6073953449667897e-06\n",
      "Epoch 1, Batch 1026, Loss: 2.3493605567637132e-06\n",
      "Epoch 1, Batch 1027, Loss: 1.141146299232787e-06\n",
      "Epoch 1, Batch 1028, Loss: 1.339540602884881e-07\n",
      "Epoch 1, Batch 1029, Loss: 2.3120458081393735e-07\n",
      "Epoch 1, Batch 1030, Loss: 1.2479182487368234e-06\n",
      "Epoch 1, Batch 1031, Loss: 2.12772670238337e-06\n",
      "Epoch 1, Batch 1032, Loss: 1.9840751974697923e-06\n",
      "Epoch 1, Batch 1033, Loss: 9.611960649635876e-07\n",
      "Epoch 1, Batch 1034, Loss: 9.436818260155633e-08\n",
      "Epoch 1, Batch 1035, Loss: 3.0511708359881595e-07\n",
      "Epoch 1, Batch 1036, Loss: 1.4919816067049396e-06\n",
      "Epoch 1, Batch 1037, Loss: 2.5931694835890085e-06\n",
      "Epoch 1, Batch 1038, Loss: 2.5792448923311895e-06\n",
      "Epoch 1, Batch 1039, Loss: 1.4447693956753938e-06\n",
      "Epoch 1, Batch 1040, Loss: 2.516176209610421e-07\n",
      "Epoch 1, Batch 1041, Loss: 1.5921318663458806e-07\n",
      "Epoch 1, Batch 1042, Loss: 1.3342287275008857e-06\n",
      "Epoch 1, Batch 1043, Loss: 2.76298283097276e-06\n",
      "Epoch 1, Batch 1044, Loss: 3.1621177640772657e-06\n",
      "Epoch 1, Batch 1045, Loss: 2.160680651286384e-06\n",
      "Epoch 1, Batch 1046, Loss: 6.6055241632057e-07\n",
      "Epoch 1, Batch 1047, Loss: 2.812427624121483e-08\n",
      "Epoch 1, Batch 1048, Loss: 8.476546327074175e-07\n",
      "Epoch 1, Batch 1049, Loss: 2.3807961042621173e-06\n",
      "Epoch 1, Batch 1050, Loss: 3.2359091619582614e-06\n",
      "Epoch 1, Batch 1051, Loss: 2.6379657356301323e-06\n",
      "Epoch 1, Batch 1052, Loss: 1.1331286486893077e-06\n",
      "Epoch 1, Batch 1053, Loss: 8.14663039250263e-08\n",
      "Epoch 1, Batch 1054, Loss: 4.082945395111892e-07\n",
      "Epoch 1, Batch 1055, Loss: 1.7649185792834032e-06\n",
      "Epoch 1, Batch 1056, Loss: 2.8663655484706396e-06\n",
      "Epoch 1, Batch 1057, Loss: 2.6856400836550165e-06\n",
      "Epoch 1, Batch 1058, Loss: 1.3975555930301198e-06\n",
      "Epoch 1, Batch 1059, Loss: 2.0346637086277042e-07\n",
      "Epoch 1, Batch 1060, Loss: 2.069236302304489e-07\n",
      "Epoch 1, Batch 1061, Loss: 1.3879882772016572e-06\n",
      "Epoch 1, Batch 1062, Loss: 2.628667061799206e-06\n",
      "Epoch 1, Batch 1063, Loss: 1.6631007611067616e-06\n",
      "Epoch 1, Batch 1064, Loss: 1.8470588258878706e-07\n",
      "Epoch 1, Batch 1065, Loss: 3.054661590340402e-08\n",
      "Epoch 1, Batch 1066, Loss: 6.921753197275393e-07\n",
      "Epoch 1, Batch 1067, Loss: 1.9524566141626565e-06\n",
      "Epoch 1, Batch 1068, Loss: 2.852499164873734e-06\n",
      "Epoch 1, Batch 1069, Loss: 2.533720362407621e-06\n",
      "Epoch 1, Batch 1070, Loss: 1.1904639904969372e-06\n",
      "Epoch 1, Batch 1071, Loss: 9.087347052627592e-08\n",
      "Epoch 1, Batch 1072, Loss: 5.194328309698903e-07\n",
      "Epoch 1, Batch 1073, Loss: 2.543401478760643e-06\n",
      "Epoch 1, Batch 1074, Loss: 4.774829449161189e-06\n",
      "Epoch 1, Batch 1075, Loss: 5.458669420477236e-06\n",
      "Epoch 1, Batch 1076, Loss: 4.149157575739082e-06\n",
      "Epoch 1, Batch 1077, Loss: 1.7174114645968075e-06\n",
      "Epoch 1, Batch 1078, Loss: 4.36123670510824e-08\n",
      "Epoch 1, Batch 1079, Loss: 7.756736977171386e-07\n",
      "Epoch 1, Batch 1080, Loss: 2.9900006666139234e-06\n",
      "Epoch 1, Batch 1081, Loss: 4.7585804168193135e-06\n",
      "Epoch 1, Batch 1082, Loss: 4.585061560646864e-06\n",
      "Epoch 1, Batch 1083, Loss: 2.654080162756145e-06\n",
      "Epoch 1, Batch 1084, Loss: 6.106141086092975e-07\n",
      "Epoch 1, Batch 1085, Loss: 8.102315263158744e-08\n",
      "Epoch 1, Batch 1086, Loss: 1.2743065553877386e-06\n",
      "Epoch 1, Batch 1087, Loss: 2.8912952529935865e-06\n",
      "Epoch 1, Batch 1088, Loss: 3.3693477234919555e-06\n",
      "Epoch 1, Batch 1089, Loss: 1.7518703998575802e-06\n",
      "Epoch 1, Batch 1090, Loss: 1.0046564057120122e-05\n",
      "Epoch 1, Batch 1091, Loss: 1.0713435472098354e-07\n",
      "Epoch 1, Batch 1092, Loss: 2.9829919867552235e-08\n",
      "Epoch 1, Batch 1093, Loss: 2.1318447807061602e-07\n",
      "Epoch 1, Batch 1094, Loss: 2.781348200642242e-07\n",
      "Epoch 1, Batch 1095, Loss: 8.522447814129919e-08\n",
      "Epoch 1, Batch 1096, Loss: 6.71523494588655e-08\n",
      "Epoch 1, Batch 1097, Loss: 7.434047688548162e-07\n",
      "Epoch 1, Batch 1098, Loss: 2.0131401470280252e-06\n",
      "Epoch 1, Batch 1099, Loss: 2.998546960952808e-06\n",
      "Epoch 1, Batch 1100, Loss: 2.7953403787250863e-06\n",
      "Epoch 1, Batch 1101, Loss: 1.453373442927841e-06\n",
      "Epoch 1, Batch 1102, Loss: 1.7237226757060853e-07\n",
      "Epoch 1, Batch 1103, Loss: 3.6710244444293494e-07\n",
      "Epoch 1, Batch 1104, Loss: 2.353484433115227e-06\n",
      "Epoch 1, Batch 1105, Loss: 4.875080321653513e-06\n",
      "Epoch 1, Batch 1106, Loss: 6.020322416588897e-06\n",
      "Epoch 1, Batch 1107, Loss: 4.830274519918021e-06\n",
      "Epoch 1, Batch 1108, Loss: 2.2012638964952203e-06\n",
      "Epoch 1, Batch 1109, Loss: 2.266706502496163e-07\n",
      "Epoch 1, Batch 1110, Loss: 4.7285934101637395e-07\n",
      "Epoch 1, Batch 1111, Loss: 2.656828200997552e-06\n",
      "Epoch 1, Batch 1112, Loss: 4.888437615591101e-06\n",
      "Epoch 1, Batch 1113, Loss: 5.284588951326441e-06\n",
      "Epoch 1, Batch 1114, Loss: 3.5518460208550096e-06\n",
      "Epoch 1, Batch 1115, Loss: 1.1659616347969859e-06\n",
      "Epoch 1, Batch 1116, Loss: 3.0226807723465754e-08\n",
      "Epoch 1, Batch 1117, Loss: 8.335222787536622e-07\n",
      "Epoch 1, Batch 1118, Loss: 2.5514850676700007e-06\n",
      "Epoch 1, Batch 1119, Loss: 3.4701452023000456e-06\n",
      "Epoch 1, Batch 1120, Loss: 2.749470695562195e-06\n",
      "Epoch 1, Batch 1121, Loss: 1.1085919595643645e-06\n",
      "Epoch 1, Batch 1122, Loss: 6.401258900723406e-08\n",
      "Epoch 1, Batch 1123, Loss: 4.836724656342994e-07\n",
      "Epoch 1, Batch 1124, Loss: 1.8145206013286952e-06\n",
      "Epoch 1, Batch 1125, Loss: 2.6735062874649884e-06\n",
      "Epoch 1, Batch 1126, Loss: 2.637867453358922e-07\n",
      "Epoch 1, Batch 1127, Loss: 1.893628898130828e-08\n",
      "Epoch 1, Batch 1128, Loss: 3.412176567962888e-07\n",
      "Epoch 1, Batch 1129, Loss: 1.4508942740576458e-06\n",
      "Epoch 1, Batch 1130, Loss: 2.6469858767086407e-06\n",
      "Epoch 1, Batch 1131, Loss: 2.8594436116691213e-06\n",
      "Epoch 1, Batch 1132, Loss: 1.7678241874818923e-06\n",
      "Epoch 1, Batch 1133, Loss: 3.5316156754561234e-07\n",
      "Epoch 1, Batch 1134, Loss: 1.910061939724983e-07\n",
      "Epoch 1, Batch 1135, Loss: 1.977842202904867e-06\n",
      "Epoch 1, Batch 1136, Loss: 4.782454197993502e-06\n",
      "Epoch 1, Batch 1137, Loss: 6.473960638686549e-06\n",
      "Epoch 1, Batch 1138, Loss: 5.673171926900977e-06\n",
      "Epoch 1, Batch 1139, Loss: 2.9471527795976726e-06\n",
      "Epoch 1, Batch 1140, Loss: 4.802215585186786e-07\n",
      "Epoch 1, Batch 1141, Loss: 2.821180942191859e-07\n",
      "Epoch 1, Batch 1142, Loss: 2.479692739143502e-06\n",
      "Epoch 1, Batch 1143, Loss: 5.1938586693722755e-06\n",
      "Epoch 1, Batch 1144, Loss: 6.134338946139906e-06\n",
      "Epoch 1, Batch 1145, Loss: 4.537853783403989e-06\n",
      "Epoch 1, Batch 1146, Loss: 1.7713765601001796e-06\n",
      "Epoch 1, Batch 1147, Loss: 1.0485234724910697e-07\n",
      "Epoch 1, Batch 1148, Loss: 6.925293405402044e-07\n",
      "Epoch 1, Batch 1149, Loss: 2.7872238206327893e-06\n",
      "Epoch 1, Batch 1150, Loss: 4.287729097995907e-06\n",
      "Epoch 1, Batch 1151, Loss: 3.843606918962905e-06\n",
      "Epoch 1, Batch 1152, Loss: 1.917059535117005e-06\n",
      "Epoch 1, Batch 1153, Loss: 2.637916907133331e-07\n",
      "Epoch 1, Batch 1154, Loss: 2.627327546633751e-07\n",
      "Epoch 1, Batch 1155, Loss: 1.6844550145833637e-06\n",
      "Epoch 1, Batch 1156, Loss: 3.0027017601241823e-06\n",
      "Epoch 1, Batch 1157, Loss: 2.893650162150152e-06\n",
      "Epoch 1, Batch 1158, Loss: 1.4841161828371696e-06\n",
      "Epoch 1, Batch 1159, Loss: 1.8672768931082828e-07\n",
      "Epoch 1, Batch 1160, Loss: 3.0938639383748523e-07\n",
      "Epoch 1, Batch 1161, Loss: 1.7809998098528013e-06\n",
      "Epoch 1, Batch 1162, Loss: 3.206654128007358e-06\n",
      "Epoch 1, Batch 1163, Loss: 3.2098364499688614e-06\n",
      "Epoch 1, Batch 1164, Loss: 1.7713782654027455e-06\n",
      "Epoch 1, Batch 1165, Loss: 2.825189540089923e-07\n",
      "Epoch 1, Batch 1166, Loss: 2.4022074285312556e-07\n",
      "Epoch 1, Batch 1167, Loss: 1.8097592828780762e-06\n",
      "Epoch 1, Batch 1168, Loss: 3.6213668863638304e-06\n",
      "Epoch 1, Batch 1169, Loss: 4.019459538540104e-06\n",
      "Epoch 1, Batch 1170, Loss: 2.6166489988099784e-06\n",
      "Epoch 1, Batch 1171, Loss: 6.972928190407401e-07\n",
      "Epoch 1, Batch 1172, Loss: 6.488094328460647e-08\n",
      "Epoch 1, Batch 1173, Loss: 1.3750797052125563e-06\n",
      "Epoch 1, Batch 1174, Loss: 3.4990371204912663e-06\n",
      "Epoch 1, Batch 1175, Loss: 4.5310462155612186e-06\n",
      "Epoch 1, Batch 1176, Loss: 3.531997663230868e-06\n",
      "Epoch 1, Batch 1177, Loss: 1.4016604836797342e-06\n",
      "Epoch 1, Batch 1178, Loss: 6.557301901466417e-08\n",
      "Epoch 1, Batch 1179, Loss: 7.180157126640552e-07\n",
      "Epoch 1, Batch 1180, Loss: 2.7349901756679174e-06\n",
      "Epoch 1, Batch 1181, Loss: 4.253419774613576e-06\n",
      "Epoch 1, Batch 1182, Loss: 3.880942585965386e-06\n",
      "Epoch 1, Batch 1183, Loss: 1.96579867406399e-06\n",
      "Epoch 1, Batch 1184, Loss: 2.6432991262481664e-07\n",
      "Epoch 1, Batch 1185, Loss: 3.172567346609867e-07\n",
      "Epoch 1, Batch 1186, Loss: 2.033772943832446e-06\n",
      "Epoch 1, Batch 1187, Loss: 3.789725496972096e-06\n",
      "Epoch 1, Batch 1188, Loss: 2.438627916490077e-06\n",
      "Epoch 1, Batch 1189, Loss: 3.3445462577219587e-07\n",
      "Epoch 1, Batch 1190, Loss: 3.329093090087554e-08\n",
      "Epoch 1, Batch 1191, Loss: 8.172049206223164e-07\n",
      "Epoch 1, Batch 1192, Loss: 2.4396310891461326e-06\n",
      "Epoch 1, Batch 1193, Loss: 3.609456143749412e-06\n",
      "Epoch 1, Batch 1194, Loss: 3.193351858499227e-06\n",
      "Epoch 1, Batch 1195, Loss: 1.4643258055002661e-06\n",
      "Epoch 1, Batch 1196, Loss: 9.517241750245375e-08\n",
      "Epoch 1, Batch 1197, Loss: 2.710937110350642e-07\n",
      "Epoch 1, Batch 1198, Loss: 2.160403482776019e-06\n",
      "Epoch 1, Batch 1199, Loss: 7.618696145073045e-06\n",
      "Epoch 1, Batch 1200, Loss: 9.074353329197038e-06\n",
      "Epoch 1, Batch 1201, Loss: 7.009583441686118e-06\n",
      "Epoch 1, Batch 1202, Loss: 3.0579678877984406e-06\n",
      "Epoch 1, Batch 1203, Loss: 2.8647900762734935e-07\n",
      "Epoch 1, Batch 1204, Loss: 6.43888029117079e-07\n",
      "Epoch 1, Batch 1205, Loss: 3.4133083772758255e-06\n",
      "Epoch 1, Batch 1206, Loss: 5.956560926279053e-06\n",
      "Epoch 1, Batch 1207, Loss: 6.036879767634673e-06\n",
      "Epoch 1, Batch 1208, Loss: 3.671222202683566e-06\n",
      "Epoch 1, Batch 1209, Loss: 1.4006509445607662e-06\n",
      "Epoch 1, Batch 1210, Loss: 1.7877911204777774e-06\n",
      "Epoch 1, Batch 1211, Loss: 1.5737988405817305e-06\n",
      "Epoch 1, Batch 1212, Loss: 4.754849669552641e-06\n",
      "Epoch 1, Batch 1213, Loss: 5.945106295257574e-06\n",
      "Epoch 1, Batch 1214, Loss: 4.49115668743616e-06\n",
      "Epoch 1, Batch 1215, Loss: 1.7844204194261692e-06\n",
      "Epoch 1, Batch 1216, Loss: 1.131698610379317e-07\n",
      "Epoch 1, Batch 1217, Loss: 5.655983841279522e-07\n",
      "Epoch 1, Batch 1218, Loss: 2.20779406845395e-06\n",
      "Epoch 1, Batch 1219, Loss: 3.162503617204493e-06\n",
      "Epoch 1, Batch 1220, Loss: 2.453860588502721e-06\n",
      "Epoch 1, Batch 1221, Loss: 8.59573447087314e-07\n",
      "Epoch 1, Batch 1222, Loss: 3.414544380575535e-08\n",
      "Epoch 1, Batch 1223, Loss: 8.276064704659802e-07\n",
      "Epoch 1, Batch 1224, Loss: 2.44307966568158e-06\n",
      "Epoch 1, Batch 1225, Loss: 3.2449224818265066e-06\n",
      "Epoch 1, Batch 1226, Loss: 2.4038026822381653e-06\n",
      "Epoch 1, Batch 1227, Loss: 7.592412885060185e-07\n",
      "Epoch 1, Batch 1228, Loss: 3.885483224053132e-08\n",
      "Epoch 1, Batch 1229, Loss: 1.166457764156803e-06\n",
      "Epoch 1, Batch 1230, Loss: 3.293301688245265e-06\n",
      "Epoch 1, Batch 1231, Loss: 4.522643848758889e-06\n",
      "Epoch 1, Batch 1232, Loss: 3.690070343509433e-06\n",
      "Epoch 1, Batch 1233, Loss: 1.5283339962479658e-06\n",
      "Epoch 1, Batch 1234, Loss: 7.59951461759556e-08\n",
      "Epoch 1, Batch 1235, Loss: 8.154868851306674e-07\n",
      "Epoch 1, Batch 1236, Loss: 3.261407755417167e-06\n",
      "Epoch 1, Batch 1237, Loss: 5.310455890139565e-06\n",
      "Epoch 1, Batch 1238, Loss: 5.140500434208661e-06\n",
      "Epoch 1, Batch 1239, Loss: 2.8824488254031166e-06\n",
      "Epoch 1, Batch 1240, Loss: 5.4394973858507e-07\n",
      "Epoch 1, Batch 1241, Loss: 2.1309044484496553e-07\n",
      "Epoch 1, Batch 1242, Loss: 2.171133246520185e-06\n",
      "Epoch 1, Batch 1243, Loss: 4.636920948541956e-06\n",
      "Epoch 1, Batch 1244, Loss: 5.380228230933426e-06\n",
      "Epoch 1, Batch 1245, Loss: 3.7376109958131565e-06\n",
      "Epoch 1, Batch 1246, Loss: 1.1984766388195567e-06\n",
      "Epoch 1, Batch 1247, Loss: 3.0113842086620934e-08\n",
      "Epoch 1, Batch 1248, Loss: 1.2167029126430862e-06\n",
      "Epoch 1, Batch 1249, Loss: 3.608255610743072e-06\n",
      "Epoch 1, Batch 1250, Loss: 4.9344303079124074e-06\n",
      "Epoch 1, Batch 1251, Loss: 9.535774552205112e-07\n",
      "Epoch 1, Batch 1252, Loss: 4.990143906979938e-07\n",
      "Epoch 1, Batch 1253, Loss: 1.4879788068355992e-07\n",
      "Epoch 1, Batch 1254, Loss: 2.905786944396027e-09\n",
      "Epoch 1, Batch 1255, Loss: 6.377358374720643e-08\n",
      "Epoch 1, Batch 1256, Loss: 2.532555640755163e-07\n",
      "Epoch 1, Batch 1257, Loss: 4.583160375659645e-07\n",
      "Epoch 1, Batch 1258, Loss: 5.819301236442698e-07\n",
      "Epoch 1, Batch 1259, Loss: 5.781401455351443e-07\n",
      "Epoch 1, Batch 1260, Loss: 4.6045516910453443e-07\n",
      "Epoch 1, Batch 1261, Loss: 2.852868021818722e-07\n",
      "Epoch 1, Batch 1262, Loss: 1.2162512064151088e-07\n",
      "Epoch 1, Batch 1263, Loss: 2.1454605203530264e-08\n",
      "Epoch 1, Batch 1264, Loss: 2.457316128356979e-09\n",
      "Epoch 1, Batch 1265, Loss: 4.757305305247428e-08\n",
      "Epoch 1, Batch 1266, Loss: 1.1845586556091803e-07\n",
      "Epoch 1, Batch 1267, Loss: 1.748752680441612e-07\n",
      "Epoch 1, Batch 1268, Loss: 1.9119228511499387e-07\n",
      "Epoch 1, Batch 1269, Loss: 1.6384420575832337e-07\n",
      "Epoch 1, Batch 1270, Loss: 1.0850443032950352e-07\n",
      "Epoch 1, Batch 1271, Loss: 4.999830949259376e-08\n",
      "Epoch 1, Batch 1272, Loss: 1.0402077421645117e-08\n",
      "Epoch 1, Batch 1273, Loss: 4.689237886879027e-10\n",
      "Epoch 1, Batch 1274, Loss: 1.7232739679684528e-08\n",
      "Epoch 1, Batch 1275, Loss: 4.760467930964296e-08\n",
      "Epoch 1, Batch 1276, Loss: 7.540874236156014e-08\n",
      "Epoch 1, Batch 1277, Loss: 8.839234055812994e-08\n",
      "Epoch 1, Batch 1278, Loss: 8.240105131562814e-08\n",
      "Epoch 1, Batch 1279, Loss: 6.156501797249803e-08\n",
      "Epoch 1, Batch 1280, Loss: 3.5151145993950195e-08\n",
      "Epoch 1, Batch 1281, Loss: 1.2954254557939748e-08\n",
      "Epoch 1, Batch 1282, Loss: 1.3321956870981921e-09\n",
      "Epoch 1, Batch 1283, Loss: 1.353543388482592e-09\n",
      "Epoch 1, Batch 1284, Loss: 9.401379230666862e-09\n",
      "Epoch 1, Batch 1285, Loss: 1.9531418260498867e-08\n",
      "Epoch 1, Batch 1286, Loss: 2.630606665832147e-08\n",
      "Epoch 1, Batch 1287, Loss: 2.6873129499449533e-08\n",
      "Epoch 1, Batch 1288, Loss: 2.1595136345808896e-08\n",
      "Epoch 1, Batch 1289, Loss: 1.3249881192223256e-08\n",
      "Epoch 1, Batch 1290, Loss: 5.403960390282236e-09\n",
      "Epoch 1, Batch 1291, Loss: 7.781614241864077e-10\n",
      "Epoch 1, Batch 1292, Loss: 2.7709851080359726e-10\n",
      "Epoch 1, Batch 1293, Loss: 2.9534155121524464e-09\n",
      "Epoch 1, Batch 1294, Loss: 6.745319414136475e-09\n",
      "Epoch 1, Batch 1295, Loss: 9.540277012831666e-09\n",
      "Epoch 1, Batch 1296, Loss: 1.0064413302757202e-08\n",
      "Epoch 1, Batch 1297, Loss: 8.264554374193267e-09\n",
      "Epoch 1, Batch 1298, Loss: 5.116634671509246e-09\n",
      "Epoch 1, Batch 1299, Loss: 2.040539293091115e-09\n",
      "Epoch 1, Batch 1300, Loss: 2.3432206175399983e-10\n",
      "Epoch 1, Batch 1301, Loss: 2.119433933911452e-10\n",
      "Epoch 1, Batch 1302, Loss: 1.6993317863978064e-09\n",
      "Epoch 1, Batch 1303, Loss: 3.8671634783327136e-09\n",
      "Epoch 1, Batch 1304, Loss: 5.746814579765669e-09\n",
      "Epoch 1, Batch 1305, Loss: 6.629372606425932e-09\n",
      "Epoch 1, Batch 1306, Loss: 6.290669318786968e-09\n",
      "Epoch 1, Batch 1307, Loss: 4.984404444741131e-09\n",
      "Epoch 1, Batch 1308, Loss: 3.251409141924455e-09\n",
      "Epoch 1, Batch 1309, Loss: 1.6561851889917989e-09\n",
      "Epoch 1, Batch 1310, Loss: 5.706723982257245e-10\n",
      "Epoch 1, Batch 1311, Loss: 8.235057080696606e-11\n",
      "Epoch 1, Batch 1312, Loss: 3.7870779429072243e-11\n",
      "Epoch 1, Batch 1313, Loss: 1.25703877529304e-07\n",
      "Epoch 1, Batch 1314, Loss: 2.0320287319464114e-07\n",
      "Epoch 1, Batch 1315, Loss: 1.2371015145618003e-07\n",
      "Epoch 1, Batch 1316, Loss: 4.826809529845377e-08\n",
      "Epoch 1, Batch 1317, Loss: 5.273963488150457e-09\n",
      "Epoch 1, Batch 1318, Loss: 5.188907081787875e-09\n",
      "Epoch 1, Batch 1319, Loss: 3.918858482165888e-08\n",
      "Epoch 1, Batch 1320, Loss: 8.604472867546065e-08\n",
      "Epoch 1, Batch 1321, Loss: 1.2289625317407626e-07\n",
      "Epoch 1, Batch 1322, Loss: 1.347689106978578e-07\n",
      "Epoch 1, Batch 1323, Loss: 1.1917035891428895e-07\n",
      "Epoch 1, Batch 1324, Loss: 8.479542401573781e-08\n",
      "Epoch 1, Batch 1325, Loss: 4.595514724314853e-08\n",
      "Epoch 1, Batch 1326, Loss: 1.580812636348128e-08\n",
      "Epoch 1, Batch 1327, Loss: 1.3782950336604927e-09\n",
      "Epoch 1, Batch 1328, Loss: 2.052170433586298e-09\n",
      "Epoch 1, Batch 1329, Loss: 1.1501477104047808e-08\n",
      "Epoch 1, Batch 1330, Loss: 2.1564479979474527e-08\n",
      "Epoch 1, Batch 1331, Loss: 2.608750904187218e-08\n",
      "Epoch 1, Batch 1332, Loss: 2.3127975978809445e-08\n",
      "Epoch 1, Batch 1333, Loss: 1.4905968015455073e-08\n",
      "Epoch 1, Batch 1334, Loss: 5.962529137093497e-09\n",
      "Epoch 1, Batch 1335, Loss: 6.501251204049652e-10\n",
      "Epoch 1, Batch 1336, Loss: 1.1578926706334869e-09\n",
      "Epoch 1, Batch 1337, Loss: 6.823122511434576e-09\n",
      "Epoch 1, Batch 1338, Loss: 1.4798322567344258e-08\n",
      "Epoch 1, Batch 1339, Loss: 2.1554850349048138e-08\n",
      "Epoch 1, Batch 1340, Loss: 2.444372526611005e-08\n",
      "Epoch 1, Batch 1341, Loss: 2.2646762687372757e-08\n",
      "Epoch 1, Batch 1342, Loss: 1.7223625192741565e-08\n",
      "Epoch 1, Batch 1343, Loss: 1.039016161996642e-08\n",
      "Epoch 1, Batch 1344, Loss: 4.460115388127406e-09\n",
      "Epoch 1, Batch 1345, Loss: 9.397898015350847e-10\n",
      "Epoch 1, Batch 1346, Loss: 1.1744184791329104e-10\n",
      "Epoch 1, Batch 1347, Loss: 1.2193889231681965e-09\n",
      "Epoch 1, Batch 1348, Loss: 2.9582496452462692e-09\n",
      "Epoch 1, Batch 1349, Loss: 4.170150891269486e-09\n",
      "Epoch 1, Batch 1350, Loss: 4.260670483091644e-09\n",
      "Epoch 1, Batch 1351, Loss: 3.31334160108554e-09\n",
      "Epoch 1, Batch 1352, Loss: 1.8868842044383882e-09\n",
      "Epoch 1, Batch 1353, Loss: 6.522723472457415e-10\n",
      "Epoch 1, Batch 1354, Loss: 5.963248644880181e-11\n",
      "Epoch 1, Batch 1355, Loss: 1.74662354024413e-10\n",
      "Epoch 1, Batch 1356, Loss: 7.223230347186416e-10\n",
      "Epoch 1, Batch 1357, Loss: 1.2789992398509753e-09\n",
      "Epoch 1, Batch 1358, Loss: 1.4999699260442867e-09\n",
      "Epoch 1, Batch 1359, Loss: 1.2732256360337146e-09\n",
      "Epoch 1, Batch 1360, Loss: 7.436893878498552e-10\n",
      "Epoch 1, Batch 1361, Loss: 2.1645288339477986e-10\n",
      "Epoch 1, Batch 1362, Loss: 1.7823246947334254e-13\n",
      "Epoch 1, Batch 1363, Loss: 2.6799229502216804e-10\n",
      "Epoch 1, Batch 1364, Loss: 9.92311122161027e-10\n",
      "Epoch 1, Batch 1365, Loss: 1.9710586496302085e-09\n",
      "Epoch 1, Batch 1366, Loss: 2.9202875673206563e-09\n",
      "Epoch 1, Batch 1367, Loss: 3.586285712842141e-09\n",
      "Epoch 1, Batch 1368, Loss: 3.828914074688328e-09\n",
      "Epoch 1, Batch 1369, Loss: 3.6492084909411915e-09\n",
      "Epoch 1, Batch 1370, Loss: 3.1617912732428977e-09\n",
      "Epoch 1, Batch 1371, Loss: 2.5332873576644488e-09\n",
      "Epoch 1, Batch 1372, Loss: 1.9190486977294086e-09\n",
      "Epoch 1, Batch 1373, Loss: 1.4217848010034118e-09\n",
      "Epoch 1, Batch 1374, Loss: 1.0830761842939296e-09\n",
      "Epoch 1, Batch 1375, Loss: 8.982000698765091e-10\n",
      "Epoch 1, Batch 1376, Loss: 1.0759014230643515e-06\n",
      "Epoch 1, Batch 1377, Loss: 7.756920012980117e-07\n",
      "Epoch 1, Batch 1378, Loss: 3.992517179085553e-07\n",
      "Epoch 1, Batch 1379, Loss: 1.080108802398172e-07\n",
      "Epoch 1, Batch 1380, Loss: 1.6855701556739433e-10\n",
      "Epoch 1, Batch 1381, Loss: 7.901279275301931e-08\n",
      "Epoch 1, Batch 1382, Loss: 2.6807518338500813e-07\n",
      "Epoch 1, Batch 1383, Loss: 4.578323569148779e-07\n",
      "Epoch 1, Batch 1384, Loss: 5.580444621955394e-07\n",
      "Epoch 1, Batch 1385, Loss: 5.323144023350324e-07\n",
      "Epoch 1, Batch 1386, Loss: 4.0345051388612774e-07\n",
      "Epoch 1, Batch 1387, Loss: 2.328004171658904e-07\n",
      "Epoch 1, Batch 1388, Loss: 8.719410971025354e-08\n",
      "Epoch 1, Batch 1389, Loss: 9.8875991838554e-09\n",
      "Epoch 1, Batch 1390, Loss: 7.149020042618304e-09\n",
      "Epoch 1, Batch 1391, Loss: 5.326177543452104e-08\n",
      "Epoch 1, Batch 1392, Loss: 1.0828835428355887e-07\n",
      "Epoch 1, Batch 1393, Loss: 1.3845722435235075e-07\n",
      "Epoch 1, Batch 1394, Loss: 1.2979434416138247e-07\n",
      "Epoch 1, Batch 1395, Loss: 9.031078462840014e-08\n",
      "Epoch 1, Batch 1396, Loss: 4.1968956310256544e-08\n",
      "Epoch 1, Batch 1397, Loss: 7.907873467161153e-09\n",
      "Epoch 1, Batch 1398, Loss: 1.4813503756982982e-09\n",
      "Epoch 1, Batch 1399, Loss: 2.164271961646591e-08\n",
      "Epoch 1, Batch 1400, Loss: 5.55803687518619e-08\n",
      "Epoch 1, Batch 1401, Loss: 8.614389912509068e-08\n",
      "Epoch 1, Batch 1402, Loss: 9.995464722578618e-08\n",
      "Epoch 1, Batch 1403, Loss: 9.253186306068528e-08\n",
      "Epoch 1, Batch 1404, Loss: 6.872642188682221e-08\n",
      "Epoch 1, Batch 1405, Loss: 3.910650292482387e-08\n",
      "Epoch 1, Batch 1406, Loss: 1.4564636607872217e-08\n",
      "Epoch 1, Batch 1407, Loss: 1.7868266866116755e-09\n",
      "Epoch 1, Batch 1408, Loss: 1.3552149402684677e-09\n",
      "Epoch 1, Batch 1409, Loss: 8.803728412942746e-09\n",
      "Epoch 1, Batch 1410, Loss: 1.760106904669101e-08\n",
      "Epoch 1, Batch 1411, Loss: 2.239691987426795e-08\n",
      "Epoch 1, Batch 1412, Loss: 2.107259433614672e-08\n",
      "Epoch 1, Batch 1413, Loss: 1.4938757786353563e-08\n",
      "Epoch 1, Batch 1414, Loss: 7.3701214020616135e-09\n",
      "Epoch 1, Batch 1415, Loss: 1.797455295715622e-09\n",
      "Epoch 1, Batch 1416, Loss: 8.542383467258219e-11\n",
      "Epoch 1, Batch 1417, Loss: 1.9535515427548944e-09\n",
      "Epoch 1, Batch 1418, Loss: 5.501999300605576e-09\n",
      "Epoch 1, Batch 1419, Loss: 8.395742767675074e-09\n",
      "Epoch 1, Batch 1420, Loss: 9.045042936861591e-09\n",
      "Epoch 1, Batch 1421, Loss: 7.243468935769215e-09\n",
      "Epoch 1, Batch 1422, Loss: 4.062369995949666e-09\n",
      "Epoch 1, Batch 1423, Loss: 1.1740073357913161e-09\n",
      "Epoch 1, Batch 1424, Loss: 6.418593954948815e-13\n",
      "Epoch 1, Batch 1425, Loss: 1.0975558240033934e-09\n",
      "Epoch 1, Batch 1426, Loss: 4.0065031292613185e-09\n",
      "Epoch 1, Batch 1427, Loss: 7.568050186534947e-09\n",
      "Epoch 1, Batch 1428, Loss: 1.0482406942458056e-08\n",
      "Epoch 1, Batch 1429, Loss: 1.1838896973870305e-08\n",
      "Epoch 1, Batch 1430, Loss: 1.1395269616798487e-08\n",
      "Epoch 1, Batch 1431, Loss: 9.539741441244587e-09\n",
      "Epoch 1, Batch 1432, Loss: 7.01361502208897e-09\n",
      "Epoch 1, Batch 1433, Loss: 4.560888999805002e-09\n",
      "Epoch 1, Batch 1434, Loss: 2.6676580944240413e-09\n",
      "Epoch 1, Batch 1435, Loss: 1.4786842861269633e-09\n",
      "Epoch 1, Batch 1436, Loss: 8.826971376052484e-10\n",
      "Epoch 1, Batch 1437, Loss: 6.831911703031324e-10\n",
      "Epoch 1, Batch 1438, Loss: 1.2231245136717916e-06\n",
      "Epoch 1, Batch 1439, Loss: 2.0238996967236744e-06\n",
      "Epoch 1, Batch 1440, Loss: 1.2443865671230014e-06\n",
      "Epoch 1, Batch 1441, Loss: 4.847852892453375e-07\n",
      "Epoch 1, Batch 1442, Loss: 5.146949533241241e-08\n",
      "Epoch 1, Batch 1443, Loss: 5.347334308680729e-08\n",
      "Epoch 1, Batch 1444, Loss: 3.883146462158038e-07\n",
      "Epoch 1, Batch 1445, Loss: 8.252781640294415e-07\n",
      "Epoch 1, Batch 1446, Loss: 1.1305342013656627e-06\n",
      "Epoch 1, Batch 1447, Loss: 1.1705587894539349e-06\n",
      "Epoch 1, Batch 1448, Loss: 9.521370998299972e-07\n",
      "Epoch 1, Batch 1449, Loss: 5.931689770477533e-07\n",
      "Epoch 1, Batch 1450, Loss: 2.500935067928367e-07\n",
      "Epoch 1, Batch 1451, Loss: 4.2112102249802774e-08\n",
      "Epoch 1, Batch 1452, Loss: 6.379860639782464e-09\n",
      "Epoch 1, Batch 1453, Loss: 9.828744396145339e-08\n",
      "Epoch 1, Batch 1454, Loss: 2.2822153766810516e-07\n",
      "Epoch 1, Batch 1455, Loss: 3.113705702162406e-07\n",
      "Epoch 1, Batch 1456, Loss: 3.055387480799254e-07\n",
      "Epoch 1, Batch 1457, Loss: 2.2202520710834506e-07\n",
      "Epoch 1, Batch 1458, Loss: 1.0966692798319855e-07\n",
      "Epoch 1, Batch 1459, Loss: 2.446451929927207e-08\n",
      "Epoch 1, Batch 1460, Loss: 1.466713861475455e-09\n",
      "Epoch 1, Batch 1461, Loss: 4.1466062583594976e-08\n",
      "Epoch 1, Batch 1462, Loss: 1.1593731841230692e-07\n",
      "Epoch 1, Batch 1463, Loss: 1.8465998152805696e-07\n",
      "Epoch 1, Batch 1464, Loss: 2.1571918296103831e-07\n",
      "Epoch 1, Batch 1465, Loss: 1.9838080334011465e-07\n",
      "Epoch 1, Batch 1466, Loss: 1.4428169947677816e-07\n",
      "Epoch 1, Batch 1467, Loss: 7.848197469684237e-08\n",
      "Epoch 1, Batch 1468, Loss: 2.6196429914193686e-08\n",
      "Epoch 1, Batch 1469, Loss: 1.923223580391209e-09\n",
      "Epoch 1, Batch 1470, Loss: 5.364302779753416e-09\n",
      "Epoch 1, Batch 1471, Loss: 2.4682375254769795e-08\n",
      "Epoch 1, Batch 1472, Loss: 4.4225281214949064e-08\n",
      "Epoch 1, Batch 1473, Loss: 5.236686817511327e-08\n",
      "Epoch 1, Batch 1474, Loss: 4.589164603885365e-08\n",
      "Epoch 1, Batch 1475, Loss: 2.960643463723045e-08\n",
      "Epoch 1, Batch 1476, Loss: 1.2316849762328275e-08\n",
      "Epoch 1, Batch 1477, Loss: 1.7509286243111433e-09\n",
      "Epoch 1, Batch 1478, Loss: 1.0064753475091948e-09\n",
      "Epoch 1, Batch 1479, Loss: 7.896090004066991e-09\n",
      "Epoch 1, Batch 1480, Loss: 1.694822060471779e-08\n",
      "Epoch 1, Batch 1481, Loss: 2.2628462659213255e-08\n",
      "Epoch 1, Batch 1482, Loss: 2.2037196956148364e-08\n",
      "Epoch 1, Batch 1483, Loss: 1.5899679794983967e-08\n",
      "Epoch 1, Batch 1484, Loss: 7.67392460687688e-09\n",
      "Epoch 1, Batch 1485, Loss: 1.5087887605957917e-09\n",
      "Epoch 1, Batch 1486, Loss: 1.9024098962816538e-10\n",
      "Epoch 1, Batch 1487, Loss: 4.028554378976423e-09\n",
      "Epoch 1, Batch 1488, Loss: 1.1039053227079876e-08\n",
      "Epoch 1, Batch 1489, Loss: 1.811929450923344e-08\n",
      "Epoch 1, Batch 1490, Loss: 2.2525368237324983e-08\n",
      "Epoch 1, Batch 1491, Loss: 2.2938356991630826e-08\n",
      "Epoch 1, Batch 1492, Loss: 1.972659546822797e-08\n",
      "Epoch 1, Batch 1493, Loss: 1.4449075713685033e-08\n",
      "Epoch 1, Batch 1494, Loss: 8.97188900950141e-09\n",
      "Epoch 1, Batch 1495, Loss: 4.66956340261504e-09\n",
      "Epoch 1, Batch 1496, Loss: 2.046586455861643e-09\n",
      "Epoch 1, Batch 1497, Loss: 8.471013890343215e-10\n",
      "Epoch 1, Batch 1498, Loss: 4.828213384655555e-10\n",
      "Epoch 1, Batch 1499, Loss: 4.938712772073472e-10\n",
      "Epoch 1, Batch 1500, Loss: 7.975058946563252e-10\n",
      "Epoch 1, Batch 1501, Loss: 4.2255610424035694e-06\n",
      "Epoch 1, Batch 1502, Loss: 3.029297658940777e-06\n",
      "Epoch 1, Batch 1503, Loss: 1.5072179166963906e-06\n",
      "Epoch 1, Batch 1504, Loss: 3.620207564836164e-07\n",
      "Epoch 1, Batch 1505, Loss: 2.3339596921800876e-09\n",
      "Epoch 1, Batch 1506, Loss: 4.035497624954587e-07\n",
      "Epoch 1, Batch 1507, Loss: 1.1970231525992858e-06\n",
      "Epoch 1, Batch 1508, Loss: 1.902263875308563e-06\n",
      "Epoch 1, Batch 1509, Loss: 2.1674450181308202e-06\n",
      "Epoch 1, Batch 1510, Loss: 1.9060607883147895e-06\n",
      "Epoch 1, Batch 1511, Loss: 1.2867030818597414e-06\n",
      "Epoch 1, Batch 1512, Loss: 6.083047878746584e-07\n",
      "Epoch 1, Batch 1513, Loss: 1.3932265119365184e-07\n",
      "Epoch 1, Batch 1514, Loss: 1.4511393198191058e-09\n",
      "Epoch 1, Batch 1515, Loss: 1.4319380170491058e-07\n",
      "Epoch 1, Batch 1516, Loss: 3.988276944255631e-07\n",
      "Epoch 1, Batch 1517, Loss: 5.892930516893102e-07\n",
      "Epoch 1, Batch 1518, Loss: 6.097131404203537e-07\n",
      "Epoch 1, Batch 1519, Loss: 4.646607294489513e-07\n",
      "Epoch 1, Batch 1520, Loss: 2.4422428168691113e-07\n",
      "Epoch 1, Batch 1521, Loss: 6.344067315922075e-08\n",
      "Epoch 1, Batch 1522, Loss: 9.282229429530275e-10\n",
      "Epoch 1, Batch 1523, Loss: 6.62240964288685e-08\n",
      "Epoch 1, Batch 1524, Loss: 2.0614552909137274e-07\n",
      "Epoch 1, Batch 1525, Loss: 3.400401737962966e-07\n",
      "Epoch 1, Batch 1526, Loss: 4.020290020889661e-07\n",
      "Epoch 1, Batch 1527, Loss: 3.69086535556562e-07\n",
      "Epoch 1, Batch 1528, Loss: 2.6432871891302057e-07\n",
      "Epoch 1, Batch 1529, Loss: 1.38425477302917e-07\n",
      "Epoch 1, Batch 1530, Loss: 4.1716461396390514e-08\n",
      "Epoch 1, Batch 1531, Loss: 1.6542591740886792e-09\n",
      "Epoch 1, Batch 1532, Loss: 1.5064605562997713e-08\n",
      "Epoch 1, Batch 1533, Loss: 5.602375452440356e-08\n",
      "Epoch 1, Batch 1534, Loss: 9.269872691675118e-08\n",
      "Epoch 1, Batch 1535, Loss: 1.0350921542112701e-07\n",
      "Epoch 1, Batch 1536, Loss: 8.511962334978307e-08\n",
      "Epoch 1, Batch 1537, Loss: 5.0065118273323606e-08\n",
      "Epoch 1, Batch 1538, Loss: 1.7210956215762963e-08\n",
      "Epoch 1, Batch 1539, Loss: 1.033668817207456e-09\n",
      "Epoch 1, Batch 1540, Loss: 5.1623336716488666e-09\n",
      "Epoch 1, Batch 1541, Loss: 2.2501845720057645e-08\n",
      "Epoch 1, Batch 1542, Loss: 4.0645730337018904e-08\n",
      "Epoch 1, Batch 1543, Loss: 4.896401506471193e-08\n",
      "Epoch 1, Batch 1544, Loss: 4.360007821446743e-08\n",
      "Epoch 1, Batch 1545, Loss: 2.83099481634963e-08\n",
      "Epoch 1, Batch 1546, Loss: 1.14435696474402e-08\n",
      "Epoch 1, Batch 1547, Loss: 1.1828418244874683e-09\n",
      "Epoch 1, Batch 1548, Loss: 1.6123787860422567e-09\n",
      "Epoch 1, Batch 1549, Loss: 1.1359141183220345e-08\n",
      "Epoch 1, Batch 1550, Loss: 2.5011399173990867e-08\n",
      "Epoch 1, Batch 1551, Loss: 3.617252630760959e-08\n",
      "Epoch 1, Batch 1552, Loss: 4.043594969971309e-08\n",
      "Epoch 1, Batch 1553, Loss: 3.692406025379569e-08\n",
      "Epoch 1, Batch 1554, Loss: 2.7951339021115018e-08\n",
      "Epoch 1, Batch 1555, Loss: 1.734833432465166e-08\n",
      "Epoch 1, Batch 1556, Loss: 8.49592574070357e-09\n",
      "Epoch 1, Batch 1557, Loss: 3.043870933083781e-09\n",
      "Epoch 1, Batch 1558, Loss: 7.582836025754602e-10\n",
      "Epoch 1, Batch 1559, Loss: 3.055706798704705e-10\n",
      "Epoch 1, Batch 1560, Loss: 3.65789537548622e-10\n",
      "Epoch 1, Batch 1561, Loss: 4.3479289613124195e-10\n",
      "Epoch 1, Batch 1562, Loss: 9.605787276711908e-10\n",
      "Epoch 1, Batch 1563, Loss: 3.4212685022794176e-06\n",
      "Epoch 1, Batch 1564, Loss: 5.704978320864029e-06\n",
      "Epoch 1, Batch 1565, Loss: 3.4568290629977128e-06\n",
      "Epoch 1, Batch 1566, Loss: 1.271464043384185e-06\n",
      "Epoch 1, Batch 1567, Loss: 9.608559992102528e-08\n",
      "Epoch 1, Batch 1568, Loss: 2.2886619888140558e-07\n",
      "Epoch 1, Batch 1569, Loss: 1.291778175982472e-06\n",
      "Epoch 1, Batch 1570, Loss: 2.5348492727061966e-06\n",
      "Epoch 1, Batch 1571, Loss: 3.2614664178254316e-06\n",
      "Epoch 1, Batch 1572, Loss: 3.148411906295223e-06\n",
      "Epoch 1, Batch 1573, Loss: 2.3287771000468638e-06\n",
      "Epoch 1, Batch 1574, Loss: 1.2433043821147294e-06\n",
      "Epoch 1, Batch 1575, Loss: 3.740687475328741e-07\n",
      "Epoch 1, Batch 1576, Loss: 8.889050384652819e-09\n",
      "Epoch 1, Batch 1577, Loss: 1.4312041685116128e-07\n",
      "Epoch 1, Batch 1578, Loss: 5.405862566476571e-07\n",
      "Epoch 1, Batch 1579, Loss: 8.947517926571891e-07\n",
      "Epoch 1, Batch 1580, Loss: 9.930569149219082e-07\n",
      "Epoch 1, Batch 1581, Loss: 8.032399705371063e-07\n",
      "Epoch 1, Batch 1582, Loss: 4.537163533768762e-07\n",
      "Epoch 1, Batch 1583, Loss: 1.3760204353729932e-07\n",
      "Epoch 1, Batch 1584, Loss: 2.317926295347661e-09\n",
      "Epoch 1, Batch 1585, Loss: 8.219915770268926e-08\n",
      "Epoch 1, Batch 1586, Loss: 2.9950808766443515e-07\n",
      "Epoch 1, Batch 1587, Loss: 5.207844537835626e-07\n",
      "Epoch 1, Batch 1588, Loss: 6.308324032033852e-07\n",
      "Epoch 1, Batch 1589, Loss: 5.850544084751164e-07\n",
      "Epoch 1, Batch 1590, Loss: 4.1862486455102044e-07\n",
      "Epoch 1, Batch 1591, Loss: 2.15840501027742e-07\n",
      "Epoch 1, Batch 1592, Loss: 6.16062649783089e-08\n",
      "Epoch 1, Batch 1593, Loss: 1.6568372229741613e-09\n",
      "Epoch 1, Batch 1594, Loss: 2.903041718127497e-08\n",
      "Epoch 1, Batch 1595, Loss: 9.840479719969153e-08\n",
      "Epoch 1, Batch 1596, Loss: 1.5604044278916263e-07\n",
      "Epoch 1, Batch 1597, Loss: 1.6773400091096846e-07\n",
      "Epoch 1, Batch 1598, Loss: 1.3145684363280452e-07\n",
      "Epoch 1, Batch 1599, Loss: 7.144427627281402e-08\n",
      "Epoch 1, Batch 1600, Loss: 2.0312942439204562e-08\n",
      "Epoch 1, Batch 1601, Loss: 4.888647819889513e-10\n",
      "Epoch 1, Batch 1602, Loss: 1.4411821958049131e-08\n",
      "Epoch 1, Batch 1603, Loss: 4.6787228313860396e-08\n",
      "Epoch 1, Batch 1604, Loss: 7.550398350986143e-08\n",
      "Epoch 1, Batch 1605, Loss: 8.412443719407747e-08\n",
      "Epoch 1, Batch 1606, Loss: 6.935942309382881e-08\n",
      "Epoch 1, Batch 1607, Loss: 4.064802539005541e-08\n",
      "Epoch 1, Batch 1608, Loss: 1.3406110888070089e-08\n",
      "Epoch 1, Batch 1609, Loss: 3.876680920722464e-10\n",
      "Epoch 1, Batch 1610, Loss: 5.761166654849603e-09\n",
      "Epoch 1, Batch 1611, Loss: 2.435940693601424e-08\n",
      "Epoch 1, Batch 1612, Loss: 4.5579039209542316e-08\n",
      "Epoch 1, Batch 1613, Loss: 5.9216116454763323e-08\n",
      "Epoch 1, Batch 1614, Loss: 6.006656150248091e-08\n",
      "Epoch 1, Batch 1615, Loss: 4.930850394657682e-08\n",
      "Epoch 1, Batch 1616, Loss: 3.2631934487881153e-08\n",
      "Epoch 1, Batch 1617, Loss: 1.6682230707942836e-08\n",
      "Epoch 1, Batch 1618, Loss: 5.877971887002786e-09\n",
      "Epoch 1, Batch 1619, Loss: 1.0775029757326138e-09\n",
      "Epoch 1, Batch 1620, Loss: 3.246946045365462e-10\n",
      "Epoch 1, Batch 1621, Loss: 8.240418902794033e-10\n",
      "Epoch 1, Batch 1622, Loss: 8.454426603243803e-10\n",
      "Epoch 1, Batch 1623, Loss: 5.608101205645255e-10\n",
      "Epoch 1, Batch 1624, Loss: 1.5688010890357873e-09\n",
      "Epoch 1, Batch 1625, Loss: 5.577981188054082e-09\n",
      "Epoch 1, Batch 1626, Loss: 9.864678759186063e-06\n",
      "Epoch 1, Batch 1627, Loss: 7.0129099185578525e-06\n",
      "Epoch 1, Batch 1628, Loss: 3.35209824697813e-06\n",
      "Epoch 1, Batch 1629, Loss: 6.93884544489265e-07\n",
      "Epoch 1, Batch 1630, Loss: 3.68676822404268e-08\n",
      "Epoch 1, Batch 1631, Loss: 1.2119112398067955e-06\n",
      "Epoch 1, Batch 1632, Loss: 3.1802858302398818e-06\n",
      "Epoch 1, Batch 1633, Loss: 4.7075127440621145e-06\n",
      "Epoch 1, Batch 1634, Loss: 5.006162609788589e-06\n",
      "Epoch 1, Batch 1635, Loss: 4.037487997265998e-06\n",
      "Epoch 1, Batch 1636, Loss: 2.3894401692814426e-06\n",
      "Epoch 1, Batch 1637, Loss: 8.707600045454456e-07\n",
      "Epoch 1, Batch 1638, Loss: 7.326043771627155e-08\n",
      "Epoch 1, Batch 1639, Loss: 1.2363055645892018e-07\n",
      "Epoch 1, Batch 1640, Loss: 7.129729056032375e-07\n",
      "Epoch 1, Batch 1641, Loss: 1.33838352667226e-06\n",
      "Epoch 1, Batch 1642, Loss: 1.5960463315423112e-06\n",
      "Epoch 1, Batch 1643, Loss: 1.367656636830361e-06\n",
      "Epoch 1, Batch 1644, Loss: 8.249516554315051e-07\n",
      "Epoch 1, Batch 1645, Loss: 2.840307331553049e-07\n",
      "Epoch 1, Batch 1646, Loss: 1.2483825528875059e-08\n",
      "Epoch 1, Batch 1647, Loss: 9.708953996323544e-08\n",
      "Epoch 1, Batch 1648, Loss: 4.2851758053075173e-07\n",
      "Epoch 1, Batch 1649, Loss: 7.891388804637245e-07\n",
      "Epoch 1, Batch 1650, Loss: 9.80478830570064e-07\n",
      "Epoch 1, Batch 1651, Loss: 9.187900786855607e-07\n",
      "Epoch 1, Batch 1652, Loss: 6.563770398315683e-07\n",
      "Epoch 1, Batch 1653, Loss: 1.9862768851908186e-07\n",
      "Epoch 1, Batch 1654, Loss: 8.498959402913897e-08\n",
      "Epoch 1, Batch 1655, Loss: 4.677841669575855e-09\n",
      "Epoch 1, Batch 1656, Loss: 1.6573212633375078e-06\n",
      "Epoch 1, Batch 1657, Loss: 6.087048518566007e-07\n",
      "Epoch 1, Batch 1658, Loss: 3.158264689773205e-07\n",
      "Epoch 1, Batch 1659, Loss: 2.808318981806224e-07\n",
      "Epoch 1, Batch 1660, Loss: 2.4815830101942993e-07\n",
      "Epoch 1, Batch 1661, Loss: 1.5578882539557526e-07\n",
      "Epoch 1, Batch 1662, Loss: 5.868048447155161e-08\n",
      "Epoch 1, Batch 1663, Loss: 4.95943774936336e-09\n",
      "Epoch 1, Batch 1664, Loss: 1.1431103175141288e-08\n",
      "Epoch 1, Batch 1665, Loss: 6.020503207082584e-08\n",
      "Epoch 1, Batch 1666, Loss: 1.142221748295924e-07\n",
      "Epoch 1, Batch 1667, Loss: 1.4010797144692333e-07\n"
     ]
    }
   ],
   "source": [
    "model= train_nn(dataset, epochs=2000, batch_size=32, initial_lr=0.01, lr_decay=0.99, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
